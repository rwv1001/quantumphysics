\section{Evaluating Kent's Interpretation}
In this section I will consider how well Kent's interpretation allows for peaceful coexistence between standard quantum physics and special relativity. I'll begin by showing that Kent's interpretation is consistent with standard quantum theory. I'll then show that Kent's interpretation is Lorentz invariant. The problems of outcomes will be addressed in a subsection that considers how Kent's interpretation ties in with decoherence theory and d'Espagnat's objection about improper mixtures. I'll then consider PI in Kent's interpretation and the consistency of Kent's interpretation with Colbeck and Renner's theorem. Finally, I will raise some issues about the nature of Kent's beables.

\subsection{The Empirical Adequacy of Kent's interpretation\textsuperscript{*}}
\renewcommand{\thefootnote}{\fnsymbol{footnote}}
\footnotetext[1]{As mentioned in the introduction on page \pageref{asteriskmeaning}, sections marked with an asterisk may be challenging to readers who do not have a mathematics or physics background.}\label{LorentzInvarianceSection}
\renewcommand*{\thefootnote}{\arabic{footnote}}
If we are to take Kent's interpretation seriously, it better not contradict the empirical observation. Standard quantum physics is a firmly established scientific theory, and so far it has not been contradicted by any experimental observations. Thus, standard quantum physics is empirically adequate in its domain of applicability.
Thus, if we can show that Kent's interpretation is consistent with standard quantum physics, then it too will be empirically adequate to the same degree.  

In order to show that Kent's interpretation is consistent with standard quantum theory  and  does not contradict it, we will need to express $\ev*{T^{\mu\nu}(y)}_{\tau_S}$ in terms of the observable $\hat{T}^{\mu\nu}(y)$ and the initial state $\ket{\Psi_0}$. To find such an expression, we would ideally like to find a hypersurface $S'$ that contains both $S^1(y)$ and $y$. Then we could consider how the observables $\hat{T}_S(x)$ and $\hat{T}^{\mu\nu}(y)$ act on the state $\ket{\Psi'}=U_{S'S_0}\ket{\Psi_0}$ and use this action to determine the probabilities $P(q(\tau),r)$ and $P(r)$ needed to define the conditional probability $P(q(\kappa)|r)$ as defined in (\ref{conditionalprobability}). However, since by definition a hypersurface must be continuous with any two locations on it being spacelike-separated, it is going to be impossible to find a hypersurface $S'$ with the desired properties. Nevertheless, what we can do is find a sequence of hypersurfaces $S_n(y)$ such that\label{siydef} $S_n(y)\subset S_j(y)$ for $i<j$, and that for any $x\in S^1(y)$, there exists $i$ such that $x\in S_n(y)$. An example of one such $S_n(y)$ is shown in figure \ref{S3}. When there is no ambiguity, we will drop the $y$ and write $S_n$ instead of $S_n(y)$. 

 \begin{figure}[ht!]
\captionsetup{justification=justified}
\centering

\tikzmath{
\a= 1;  
\e = 0.1;
\lam=0.9;
\h=-1;
\hae=(3*\a*\a+6*\a*\e+7*\e*\e-3*\a*sqrt(\a*\a+4*\e*\e)-4*\e*sqrt(\a*\a+4\e*\e))/(4*\a+4*\e-2*sqrt(\a*\a+4*\e*\e));
\hae=0.205678;
\circsize=1.2;
\md = (\a+\h)/2;
\lrange = 4;
\rrange=2;
\fictlabel=(\rrange-\lrange)/2;
\ss=(-\lrange-\a)/2;
\sss=\a+(\rrange-\a)/2;
\tlen=0.75;
\labelpos=(-\lrange-\a)/2;
} 

\begin{tikzpicture}[thick, scale=2]

\def\dotsize{0.7}

\definecolor{tempcolor}{RGB}{0,151,76}
\draw[<->] (-\lrange, \h) node[left] {$S_0$} -- (\rrange, \h) node[right] {$S_0$};
\filldraw (0,0) circle (\dotsize pt) node [below right] {$y$} ;
              
\draw[->] (\rrange,\md-\tlen/2) --  (\rrange,\md+\tlen/2) node[midway,right]{time}; 

\draw[->,blue, thick] [domain=-\a/2:-\lrange, samples=150]   plot (\x, {\a-\e/2-1/2*(sqrt(\lam*\lam*pow(\x+\hae+\a,2)+\e*\e)-\e+\lam*(\x+\hae+\a))}) node[left, black]{$S_n(y)$}  ;
\draw[blue, thick] [domain=-\a/2:\a/2, samples=150] plot (\x, {sqrt(\lam*\lam*\x*\x+\e*\e)-\e})   node[right, black]{$S_n(y)$};
\draw[->,blue, thick] [domain=\a/2:\rrange, samples=150]   plot (\x, {\a-\e/2-1/2*(sqrt(\lam*\lam*pow(\x-\hae-\a,2)+\e*\e)-\e-\lam*(\x-\hae-\a))}) node[right, black]{$S_n(y)$}  ;
\draw[gray] (-\lrange, \a)  -- (\rrange, \a)  {};
\draw[gray, dashed] (-\a, \a) -- (0,0) {};
\draw[gray, dashed](0,0) -- (\a, \a) {};
\draw[gray](\a, \a) --  (\rrange, \a)  ;         
\coordinate (B) at (\a,\a);
\node at (B)[red,circle,fill,inner sep=\circsize pt]{};
\coordinate (A) at (-\a,\a);
\node at (A)[red,circle,fill,inner sep=\circsize pt]{};
\coordinate (C) at (0,0);
\node at (C)[black,circle,fill,inner sep=\circsize pt]{};

\coordinate[label = above:$S$]  (D) at (0,\a);

\coordinate[label = above:$S$]  (D) at (\sss,\a);

\filldraw (\ss,\a) circle (\dotsize pt) node [above] {$x\in S_n(y)\cap S$} ;


 
\node (start) at (\labelpos,\h) [below] {Initial State $\ket{\Psi_0}$};
\node (evolution) at (\labelpos,\md+0.05) [below] {Unitary Evolution $\ket{\Psi_n}=U_{S_nS_0}\ket{\Psi_0}$};
\node (final) at (\labelpos,\a) [below] {Unitary Evolution $U_{SS_0}\ket{\Psi_0}$};
%\node at (-\ss+0.17,\mn-0.18){$-a_0$};
\draw [->, shorten <= 5pt] (start) [above] -- (evolution); 
\draw [->] (evolution) -- (final); 
\end{tikzpicture}

\vspace*{2px}
\caption{$S_n\myeq S_n(y)$ is a hypersurface containing $y$ and all of $S^1(y)$ in the limit as $n\rightarrow\infty$.   }
\label{S3}
\end{figure}
 
 Now if $r_n$ is the statement that  $T_S(x)=\tau_S(x)$ for all $x\in S_n(y)\cap S$, then so long as $\tau_S(x)$ is chosen by the Born Rule so that $P(r)\neq 0$, it will follow that
 \begin{equation}
	P(q(\tau)|r)=\lim_{n\rightarrow\infty}P(q(\tau)|r_n),
 \end{equation}
 Therefore, from the definition of the beable $\ev*{T^{\mu\nu}(y)}_{\tau_S}$ given on page \pageref{Kentbeable} together with the definition of conditional expectation given in equation (\ref{conditionalexpectation}), we have 
\begin{equation}\label{beable1}
\ev*{T^{\mu\nu}(y)}_{\tau_S}=\lim_{n\rightarrow\infty}\sum_\tau\frac{P(q(\tau),r_n)\tau}{P(r_n)}.
\end{equation} 
 To calculate $P(q(\tau)|r_n)$, we note that since $S_n$ is a hypersurface,   there will exist a unitary operator $U_{S_nS_0}$ which maps the Hilbert space of states $H_{S_0}$ describing $S_0$ to the Hilbert space of states $H_{S_n}$\label{HSidef} describing $S_n$ in accord with how the states of $H_{S_0}$  evolve over time. Now let $H_{S_n,\tau_S}\subset H_{S_n}$ be subspace of states $\ket{\xi}$ for which  $\hat{T}_S(x)\ket{\xi}=\tau_S(x)\ket{\xi}$  for all $x\in S_n\cap S$, and  let $\{\ket{\xi_1},\ket{\xi_2},\ldots\}$ be an orthonormal basis of $H_{S_n,\tau_S}$. Given that the initial state of the world is $\ket{\Psi_0}$, the probability $P(r_n)$ of ``measuring'' the value of $T_S(x)$ on $S_n\cap S$ to be $\tau_S(x)$ will be 
\begin{equation}\label{Pri}
P(r_n)=\sum_j \abs{ \ip{\xi_j}{\Psi_n}}^2,
\end{equation}
where $\ket{\Psi_n}=U_{S_nS_0}\ket{\Psi_0}$, and this probability will be independent of the particular orthonormal basis  $\{\ket{\xi_j}:j\}$ of $H_{S_n,\tau_S}$.\footnote{To see why this is, we note that we can extend the orthonormal set $\{\ket{\xi_1},\ket{\xi_2},\ldots\}$ to an orthonormal basis  $\{\ket{\xi_1},\ket{\xi_2},\ldots\}\cup\{\ket{\zeta_1},\ket{\zeta_2},\ldots\}$ of $H_{S_n}$ which consists entirely of $\hat{T}_S$-eigenstates. We can think of each of the states of this orthonormal basis as the possible measurement outcomes when making the notional measurement of $T_S(x)$ on $S_n\cap S$. By the Born rule, it therefore follows that $P(r_n)=\sum_j \abs{ \ip{\xi_j}{\Psi_n}}^2$. But to see that this probability is independent of the particular basis, we can uniquely write $\ket{\Psi_n}$ as a sum $\ket{\Psi_n}=\ket{\xi}+\ket{\zeta}$ where $\ket{\xi}$ belongs to the span of $\{\ket{\xi_j}:j\}$ and $\ket{\zeta}$ belongs to the span of $\{\ket{\zeta_j}:j\}$.  Then since $\ket{\xi}=\sum_j\ip{\xi_j}{\Psi_n}\ket{\xi_j}$, it follows that $$\ip{\xi}{\xi}=\sum_j\abs{ \ip{\xi_j}{\Psi_n}}^2=P(r_n).$$ Therefore, since  $\ip{\xi}{\xi}$ is independent of the particular basis chosen of $H_{S_n,\tau_S}$, then so is $P(r_n)$.  \label{priproof} } If we define 
\begin{equation}\label{tauprojection}
\pi_n=\sum_j\dyad{\xi_j},
\end{equation}
then it is easy to see that
$$P(r_n)=\ev*{\pi_n}{\Psi_n}.$$
We also see that $pi_n$ is Hermitian (i.e. has real eigenvalues) and that $\pi_n \pi_n = \pi_n$. Any Hermitian operator $\pi$ with $\pi^2=\pi$ is called a \textbf{projection}. We thus see that $\pi_n$ is a projection.

Turning to the calculation of $P(q(\tau), r_n)$, note that for the Tomonaga-Schwinger formulation of relativistic quantum physics, the operators $\hat{T}_S(x)$ and $\hat{T}^{\mu\nu}(y)$ for fixed $\mu,\nu$ commute when $x$ and $y$ are spacelike-separated. It therefore follows that we can express any state of $H_{S_n}$ as a superposition of simultaneous eigenstates of $\hat{T}^{\mu\nu}(y)$ and $\hat{T}_S(x)$ for $x\in S_n\cap S$.\footnote{We make the same approximation as mentioned on page \pageref{simultaneous} in footnote \ref{glosssim}.}  For a particular choice of $\mu,\nu$, we can then form an orthonormal basis $\{\ket{\eta_j}:j\}$ of $H_{S_n}$ consisting of simultaneous $\hat{T}^{\mu\nu}(y)$, $\hat{T}_S(x)$-eigenstates so that $\hat{T}^{\mu\nu}(y)\ket{\eta_j}=\tau^{(j)}\ket{\eta_j}$ and $\hat{T}_{S}(x)\ket{\eta_j}=\tau_S^{(j)}(x)\ket{\eta_j}$ for $x\in S_n\cap S$, where $\tau^{(j)}$ and $\tau_S^{(j)}(x)$ are the corresponding eigenstates. If we define  $\pi_{n,\tau}=\sum_j\dyad{\chi_{j,\tau}}$ where $\{\ket{\chi_{j,\tau}}:j\}$ is the subset of $\{\ket{\eta_j}:j\}$ such that $\hat{T}^{\mu\nu}(y)\ket{\chi_{j,\tau}}=\tau\ket{\chi_{j,\tau}}$ and $\hat{T}_S(x)\ket{\chi_{j,\tau}}=\tau_S(x)\ket{\chi_{j,\tau}}$ for all $x\in S_n\cap S$, then 
\begin{equation}\label{pqtauri}
P(q(\tau), r_n)=\sum_j \abs{ \ip{\chi_{j,\tau}}{\Psi_n}}^2=\ev*{\pi_{n,\tau}}{\Psi_n}.\protect\footnotemark
\end{equation}
\footnotetext{The proof of this is very similar to the proof given in footnote \ref{priproof}.}
But if we define $\pi_\tau=\sum_j\dyad{\eta_{j,\tau}}$ where $\{\ket{\eta_{j,\tau}}:j\}$ is the subset of  $\{\ket{\eta_j}:j\}$ with $\hat{T}^{\mu\nu}(y)\ket{\eta_{j,\tau}}=\tau\ket{\eta_{j,\tau}}$, then we also have  $\pi_{n,\tau}=\pi_n\pi_\tau$.\footnote{To see why this is, 
we first show that $\pi_n=\sum_j\dyad{h_{n,j}}$ where $\{\ket{h_{n,j}}:j\}$ is the subset of $\{\ket{\eta_j}:j\}$  for which $\ket{h_{n,j}}\in H_{S_n,\tau_S}$. 
Note that $\pi_n\ket{h_{n,j}}=\ket{h_{n,j}}$    since $\{\ket{\xi_j}:j\}$ is a basis for $H_{S_n,\tau_S}$ and $\ket{h_{n,j}}\in H_{S_n,\tau_S}$. 
Therefore, $\pi_n\pi_{n,h}=\pi_{n,h}$  where  $\pi_{n,h}=\sum_j\dyad{h_{n,j}}$. 
But  $\pi_{n,h}\ket{\xi_j}=\ket{\xi_j}$ since $\{\ket{h_{n,j}}:j\}$ is a basis for $H_{S_n,\tau_S}$ and $\ket{\xi_j}\in H_{S_n,\tau_S}$. 
Therefore, $\pi_{n,h}\pi_n=\pi_n.$ But $\pi_{n,h}\pi_n= \pi_n\pi_{n,h}$ since $\pi_n$ and $\pi_{n,h}$ are Hermitian. Hence, $\pi_n= \pi_{n,h}$.

Now the summands of $\pi_n\pi_\tau$ are only going to consist of those $\dyad{\eta_j}$ for which $\hat{T}^{\mu\nu}(y)\ket{\eta_j}=\tau\ket{\eta_j}$ and for which $\hat{T}_S(x)\ket{\eta_j}=\tau_S(x)\ket{\eta_j}$ for all $x\in S_n\cap S$, and these are just the $\dyad*{\chi_{j,\tau}}$ which are the summands of  $\pi_{n,\tau}$. Hence,  $\pi_n\pi_\tau=\pi_{n,\tau}.$} 
  Hence,
\begin{equation}\label{pqtauri2}
P(q(\tau), r_n)=\ev*{\pi_n\pi_\tau}{\Psi_n}.
\end{equation}
But clearly $\hat{T}^{\mu\nu}(y)=\sum_\tau \tau \pi_\tau.$ Therefore, combining (\ref{beable1}), (\ref{pqtauri}), and (\ref{pqtauri2}), we have 
\begin{equation}\label{kentconsistency0}
\ev*{T^{\mu\nu}(y)}_{\tau_S}=\lim_{n\rightarrow\infty}\frac{\sum_\tau \ev*{\pi_n\pi_\tau}{\Psi_n}\tau}{\ev*{\pi_n}{\Psi_n}}=\lim_{n\rightarrow\infty}\frac{\ev*{\pi_n\hat{T}^{\mu\nu}(y)}{\Psi_n}}{\ev*{\pi_n}{\Psi_n}}.
\end{equation}
We are now in a position to show that Kent's theory is consistent with standard quantum theory. First let us consider what we need to show. 

In the pilot wave interpretation, its consistency with standard quantum theory requires that if one averages the expectation values of an observable over the hidden variables (i.e. the positions and the momenta of all the particles) then one obtains the expectation value of the observable given by standard quantum theory as indicated in equation (\ref{bohmconsistency}). 

Now in Kent's interpretation, the hidden variables on which his beables $\ev*{T^{\mu\nu}(y)}_{\tau_S}$ depend are the values $\tau_S(x)$ of $T_S(x)$ for $x\in S^1(y)\cap S$. The operator $\pi_n$ in equation (\ref{kentconsistency0}) in the limit as $n\rightarrow\infty$ encapsulates this hidden information. To remind ourselves of $\pi_n$'s dependency on $\tau_S$ restricted to $S_n\cap S$, we will now write $\pi_n(\tau_{S_n\cap S})$ for $\pi_n$ where $\tau_{S_n\cap S}$ is the function $\tau_S$ restricted to $S_n\cap S$. Likewise, we will write  $r_n(\tau_{S_n\cap S})$ for $r_n$, the statement that $T_S(x)=\tau_S(x)$ for all $x\in S_n(y)\cap S$. If we let $j$ index all possible functions $\tau^{(j)}_{S_n\cap S}$ taking real values on $S_n\cap S$, then the analogue of (\ref{bohmconsistency}) requires us to show that 
\begin{equation}\label{kentconsistency}
\ev*{\hat{T}^{\mu\nu}(y)}=\lim_{n\rightarrow\infty}\sum_{j}P\big(r_n(\tau^{(j)}_{S_n\cap S})\big)\ev*{T^{\mu\nu}(y)}_{\tau^{(j)}_{S_n\cap S}}
\end{equation}
for all $y$ lying between $S_0$ and $S$, where the left-hand side of (\ref{kentconsistency}) is just the expectation value of $\hat{T}^{\mu\nu}(y)$ predicted by standard quantum mechanics. Equation (\ref{kentconsistency}) is sufficient to establish consistency with standard quantum theory because ultimately, all observables are going to be reducible to expressions dependent on $\hat{T}^{\mu\nu}(y)$, since once we know what to expect for $\hat{T}^{\mu\nu}(y)$, we will know what to expect for the energy and momentum densities for all measuring apparatus readouts etc. and hence what to expect for all measurement outcomes. But from (\ref{kentconsistency0}), we have 
\begin{equation}\label{kentconsistency1}
\lim_{n\rightarrow\infty}\sum_jP\big(r_n(\tau^{(j)}_{S_n\cap S})\big)\ev*{T^{\mu\nu}(y)}_{\tau^{(j)}_{S_n\cap S}}=\lim_{n\rightarrow\infty}\sum_{j}{\ev*{\pi_{n}(\tau^{(j)}_{S_n\cap S})\hat{T}^{\mu\nu}(y)}{\Psi_n}}
\end{equation}
Since there is an orthonormal basis $\{\ket{\eta_j}:j\}$ of $H_{S_n}$ consisting of simultaneous $\hat{T}_S(x)$-eigenstates so that $\hat{T}_S(x)\ket{\eta_j}=\tau^{(j)}_{S_n\cap S}(x)\ket{\eta_j}$ for all $x\in S_n\cap S$, it follows that $\sum_j \pi_{n}(\tau^{(j)}_{S_n\cap S})=I$. Therefore, equation (\ref{kentconsistency}) follows from (\ref{kentconsistency1}) which is what we were aiming to show for orthodox quantum consistency to hold.




\subsection{Kent's interpretation and Lorentz Invariance\label{LorentzInvariance}\textsuperscript{*}}
In order to explain what it means for Kent's interpretation to be Lorentz invariant, we first need to explain how spacetime coordinates look to different observers. 

A spacetime location is represented by a four-tuple $(x^0, x^1, x^2, x^3)$ where $(x^i)_{n=1}^3$ are spatial coordinates, and where $x^0=ct$ with $c$ being equal to the speed of light and $t$ being the time. If $(1,0,0,0)$ corresponds to the spacetime location $\hat{e}_0$, $(0,1,0,0)$ corresponds to the spacetime location $\hat{e}_1$, etc., then we can express any other spacetime location  as a sum $\sum_{\mu=0}^3x^\mu\hat{e}_\mu$. We will use the so-called Einstein convention of dropping the summation sign and implicitly assuming that there is a summation whenever an upper index and a lower index are the same so that we can write $x^\mu\hat{e}_\mu$ instead of $\sum_{\mu=0}^3x^\mu\hat{e}_\mu$.  

Now suppose an observer $O$ expresses spacetime locations in terms of $\{\hat{e}_\mu\}_{\mu=0}^3$ and hence uses the coordinates $(x^0, x^1, x^2, x^3)$ to describe various spacetime locations. For another observer $O'$, it may be more natural to express spacetime locations in terms of a different set of spacetime locations $\{\hat{e'}_\mu\}_{\mu=0}^3$ so that the location described by $O$ as $(x^0, x^1, x^2, x^3)$ would be described by $O'$ as $({x'}^0, {x'}^1, {x'}^2, {x'}^3)$ where ${x'}^\mu{\hat{e}'}_\mu=x^\mu\hat{e}_\mu$.  For instance if $O$ and $O'$ are moving with respect to each other, they may both want to use coordinates in which their own spatial coordinates are fixed and in which the spatial coordinates of the other observer are changing. As another example, figure \ref{rotfigure} shows how the $(x^1, x^2)$-coordinates transform under a spatial rotation. 


\begin{figure}[ht!]
\captionsetup{justification=justified}
\centering
\tikzmath{
\textscale = 0.7;
\picscale = 0.58;
\circsize=3.5;
\px=3;
\py=3.5;
\pr=sqrt(\px*\px+\py*\py);
\th=33;
\thd=atan(\py/\px)-\th;
\pyd=\pr*sin(\thd);
\pxd=\pr*cos(\thd);
\rrange =7; 
\labelx= \rrange/2;
\labely=-0.3;
\vr=3;
\vth=75;
\vx=\vr*cos(\vth);
\vy=\vr*sin(\vth);
\vxt=\vx+\px;
\vyt=\vy+\py;
\vrt=sqrt(\vxt*\vxt+\vyt*\vyt);
\vthd=atan(\vyt/\vxt)-\th;
\vxtd=\vrt*cos(\vthd);
\vytd=\vrt*sin(\vthd);
\vxd=\vr*cos(\vth-\th);
\vyd=\vr*sin(\vth-\th);
} 
\begin{tikzpicture}[scale=\picscale] 
    \draw[-latex] (0,0) -- (\rrange,0)  node[right,scale=\textscale, text width=5em] {$\hat{e}_1$};
    \draw[-latex] (0,0) -- (0,\rrange)  node[right,scale=\textscale, text width=5em] {$\hat{e}_2$};
    \draw[dotted, thick] (\px,0) --  (\px,\py) node[midway,right, scale=\textscale]{${x}^2$}; 
     \draw[dotted, thick] (0,\py) --  (\px,\py)  node[midway,above, scale=\textscale]{${x}^1$};  

    \begin{scope}[rotate=\th,draw=red, text=red]
       \draw[-latex] (0,0) -- (\rrange,0)  node[right,scale=\textscale, text width=5em]  {$\hat{e}'_1$};
   	   \draw[-latex] (0,0) -- (0,\rrange)  node[right,scale=\textscale, text width=5em] {$\hat{e}'_2$};
   	   \draw[dotted, thick] (\pxd,0) --  (\pxd,\pyd) node[midway, above=4,right=1,scale=\textscale]{${x'}^2$}; 
   	   \draw[dotted, thick] (0,\pyd) --  (\pxd,\pyd)  node[midway,above, scale=\textscale]{${x'}^1$};  
    \end{scope}

  \draw [black,fill] (\px,\py) circle [radius=\circsize pt] ;
    
    \coordinate[label = below: (a)]  (D) at (\labelx,\labely); 
\end{tikzpicture}% pic 1
\vspace*{2px}
\caption{Shows how a location (marked as $\bullet$) can be expressed either  in coordinates $(x^1, x^2)$ with respect to the basis $\{\hat{e}_1,\hat{e}_2\}$ or in coordinates $({x'}^1,{x'}^2)$ with respect to the basis $\{\hat{e}'_1,\hat{e}'_2\}$.}\label{rotfigure}
\end{figure}

Now the key fact about all observers is that they must always observe light to have a constant speed $c$. Thus,  for a photon that goes through the spacetime locations $(0,0,0,0)$ and $(x^0, x^1, x^2, x^3)$ in the coordinates of $O$, we must have $(x^0, x^1, x^2, x^3)=(ct,tv^1,tv^2,tv^3)$ where 
$$\sqrt{(v^1)^2 +(v^2)^2+(v^3)^2}=c.$$ But if $(0,0,0,0)$ and $(x^0, x^1, x^2, x^3)$ corresponds to $(0,0,0,0)$ and $({x'}^0, {x'}^1, {x'}^2, {x'}^3)$ respectively in the coordinates of another observer $O'$, then we must also have $({x'}^0, {x'}^1, {x'}^2, {x'}^3)=(ct',t'{v'}^1,t'{v'}^2,t'{v'}^3)$ where 
$$\sqrt{({v'}^1)^2 +({v'}^2)^2+({v'}^3)^2}=c.$$ 
In either case, we must have 
\begin{equation}\label{invariant}
(x^0)^2- (x^1)^2- (x^2)^2 - (x^3)^2=({x'}^0)^2- ({x'}^1)^2- ({x'}^2)^2 - ({x'}^3)^2=0.
\end{equation}
If we define $\eta_{00}=1$, $\eta_{ni}=-1$ for $i=1,2,3$ and $\eta_{\mu\nu}=0$ for $\mu\neq\nu$, then using the Einstein summation convention as well as the convention of lowering indices so that we define $x_\mu\myeq\eta_{\mu\nu}x^\nu$, then (\ref{invariant}) is equivalent to 
$$x_\mu x^\mu={x'}_\mu {x'}^\mu=0.$$ 
Thus, for any coordinate transformation $x\rightarrow x'$ such that  $x_\mu x^\mu={x'}_\mu{x'}^\mu$,  if the speed of light is $c$ in the $x$-coordinates, then the speed of light is also guaranteed to be $c$ in the $x'$-coordinates.  A \textbf{Lorentz Transformation} $\Lambda$ is any coordinate transformation of the form ${x'}^\mu=\Lambda\indices{^\mu_\nu}x^\nu$ such that $x_\mu x^\mu={x'}_\mu{x'}^\mu$. Since a Lorentz transformation must satisfy
$$x_\mu x^\mu=\eta_{\mu\rho}\Lambda\indices{^\rho_\sigma}x^\sigma\Lambda\indices{^\mu_\nu}x^\nu$$
for all $x$, it follows that  
\begin{equation}\label{lorentztrans}
\Lambda\indices{^\rho_\mu}\eta_{\rho\sigma}\Lambda\indices{^\sigma_\nu}=\eta_{\mu\nu}.\protect\footnotemark
\end{equation}
\footnotetext{To see why this is, note that if  $x_\mu x^\mu={x'}_\mu{x'}^\mu$ for all $x$, then  for any other spacetime location $y$, we have $(x+y)_\mu (x+y)^\mu={(x'+y')}_\mu{(x'+y')}^\mu$. If we expand this out and cancel $x_\mu x^\mu$ with ${x'}_\mu{x'}^\mu$ and cancel $y_\mu y^\mu$ with ${y'}_\mu{y'}^\mu$, and using the fact that $y_\mu x^\mu=x_\mu y^\mu$, etc. we find that  $x_\mu y^\mu={x'}_\mu{y'}^\mu$ for all $x$ and $y$. Hence,
$$\eta_{\nu\mu}x^\mu y^\nu = x_\mu y^\mu=\eta_{\sigma\rho}\Lambda\indices{^\rho_\mu}\Lambda\indices{^\sigma_\nu}x^\mu y^\nu.$$  
Since we can choose $x$ such that $x^\mu=1$ and $x^\alpha = 0$ for $\alpha\neq\mu$, and can choose $y$ such that $y^\nu=1$ and $y^\beta=0$ for $\beta\neq\nu$. Then we get
$$\eta_{\mu\nu} = \eta_{\sigma\rho}\Lambda\indices{^\rho_\mu}\Lambda\indices{^\sigma_\nu}, $$ and hence the result follows.}Having considered how the coordinates of a spacetime location viewed by one observer relate to the coordinates of the same spacetime location viewed by a different observer, we can now consider how physical quantities viewed by different observers relate to each other. The simplest kind of physical quantity is called a \textbf{scalar}. A scalar defined at a particular spacetime location has the same value no matter what frame of reference an observer uses. One example of a scalar is an object's \textbf{rest mass} which is the mass an object would have if it had no velocity. There is still a transformation rule for scalars since the spacetime location at which the scalar is measured is usually expressed in terms of an observer's coordinate system, and the coordinates of  such a location  will differ for different observers. Thus, if $\phi(x)\myeq\phi(x^0, x^1, x^2, x^3)$ is the value of a scalar defined at the spacetime location $(x^0, x^1, x^2, x^3)$ as described by an observer $O$, then another observer $O'$ using a different set of coordinate $({x'}^0, {x'}^1, {x'}^2, {x'}^3)$ to describe the location $(x^0, x^1, x^2, x^3)$ will describe this same scalar as $\phi'(x')\myeq\phi'({x'}^0, {x'}^1, {x'}^2, {x'}^3)$  where $\phi'(x')=\phi(x)$. Since $\phi'$ is just a function of the four numbers ${x'}^0, {x'}^1, {x'}^2,$ and ${x'}^3$, we can rename these numbers ${x}^0, {x}^1, {x}^2,$ and ${x}^3$, and then 
\begin{equation}\label{lorentzscalar}
\phi'(x)=\phi(\Lambda^{-1}x)
\end{equation} 
where $\Lambda^{-1}$ is the inverse Lorentz transformation that takes the coordinates $x'=({x'}^0, {x'}^1, {x'}^2, {x'}^3)$ of a location to the coordinates $x=(x^0, x^1, x^2, x^3)$ describing that location. Thus, equation (\ref{lorentzscalar}) shows us how a scalar transforms under a Lorentz transformation $\Lambda$. 

Many physical quantities, however, are not scalars and so will look different to different observers. For instance, the energy of an object has a kinetic component that depends on the velocity the object has relative to an observer. However, it turns out that if an observer $O$ considers an object's energy $E$ together with its three components of momentum $p^1, p^2$, and $p^3$ (in the directions $\hat{e}_1$, $\hat{e}_2$, and $\hat{e}_3$ respectively) to form the four-tuple $p\myeq(E/c, p^1, p^2, p^3)$ known as the object's \textbf{four-momentum}, then $p$ transforms in the same way as spacetime coordinates transform between different observers. In other words, a different observer $O'$ whose coordinates are given by ${x'}^\mu=\Lambda\indices{^\mu_\nu}x^\nu$ would observe the object's four-momentum to be ${p'}^\mu=\Lambda\indices{^\mu_\nu}p^\nu$.\footnote{In order for $p$ to transform in this way, we have to redefine what we mean by energy and momentum. In classical mechanics, the momentum of an object is the product of the object's mass and its velocity. In the context of special relativity, however, the four-momentum of an object is defined to be the product of its rest mass $m_0$ and its \textbf{four-velocity} where the four velocity of an object is a four-tuple $(u^0, u^1, u^2, u^3)$ with $u_\mu u^\mu=c^2$ such that the object's velocity (in the classical sense) is the vector $(c \frac{u^1}{u^0}, c \frac{u^2}{u^0}, c\frac{u^3}{u^0})$. The motivation for this definition can be seen by considering an object whose classical velocity is $\vb{v}=(v^1,v^2,v^3)$ that goes through $(0,0,0,0)$. It will have a spacetime trajectory $x(t)=(ct, v^1 t, v^2 t, v^3 t)$. $u$ is just the four-vector proportional to $x(1)$ with $u_\mu u^\mu=c^2$.  We can easily work out the 
four-velocity of an object whose classical velocity is $\vb{v}$. For we must have $u^i=\frac{v^i u^0}{c}$, for $i=1$ to $3$. Therefore, since $u_\mu u^\mu=c^2$, we must have $(u^0)^2\big(1-\frac{v^2}{c^2}\big)=c^2$ where $v=\sqrt{({v}^1)^2+({v}^2)^2+({v}^3)^2}$. Thus, if we define $\beta={v}/{c}$ and $\gamma=\frac{1}{\sqrt{1-\beta^2}}$, then $u^0=c\gamma$ and $u^i=\gamma v^i$ for $i=1$ to $3$, and hence the four-velocity of the object must be $u=\gamma(c,v^1,v^2,v^3).$ From this, we see that the object's four-momentum will be $\gamma m_0(c,v^1,v^2,v^3).$ If the object's velocity is very small compared to the speed of light, then $\gamma\approx 1+\frac{v^2}{2c^2}$, and hence the object's four-momentum $(E/c, p^1, p^2, p^3)$ will be approximately $(m_0c+\frac{1}{2}m_0{v^2}/c, m_0v^1,m_0v^2,m_0v^3)$. Therefore, $(p^1, p^2, p^3)$ is approximately equal to the classical momentum. However, the energy is now $E=m_0c^2+\frac{1}{2}m_0{v^2}$. Thus, in addition to the kinetic energy term $\frac{1}{2}m_0{v^2}$, there is a rest mass energy $m_0c^2$. If we define the \textbf{relativistic mass} $m=\gamma m_0$, then we obtain Einstein's famous formula $E=mc^2$.  } More generally, any list of four physical quantities $(\varphi^0, \varphi^1, \varphi^2, \varphi^3)$ that transforms as $\varphi\rightarrow\varphi'$ with  ${\varphi'}^\mu=\Lambda\indices{^\mu_\nu}\varphi^\nu$ is called a \textbf{four-vector}.
\begin{figure}[ht!]
	\captionsetup{justification=justified}
	\centering
	\tikzmath{
	\textscale = 0.7;
	\picscale = 0.58;
	\circsize=3.5;
	\px=3;
	\py=3.5;
	\pr=sqrt(\px*\px+\py*\py);
	\th=33;
	\thd=atan(\py/\px)-\th;
	\pyd=\pr*sin(\thd);
	\pxd=\pr*cos(\thd);
	\rrange =7; 
	\labelx= \rrange/2;
	\labely=-0.3;
	\vr=3;
	\vth=75;
	\vx=\vr*cos(\vth);
	\vy=\vr*sin(\vth);
	\vxt=\vx+\px;
	\vyt=\vy+\py;
	\vrt=sqrt(\vxt*\vxt+\vyt*\vyt);
	\vthd=atan(\vyt/\vxt)-\th;
	\vxtd=\vrt*cos(\vthd);
	\vytd=\vrt*sin(\vthd);
	\vxd=\vr*cos(\vth-\th);
	\vyd=\vr*sin(\vth-\th);
	} 
	\begin{tikzpicture}[scale=\picscale ] 
		\draw[-latex] (0,0) -- (\rrange,0)  node[right,scale=\textscale, text width=5em] {$\hat{e}_1$};
		\draw[-latex] (0,0) -- (0,\rrange)  node[right,scale=\textscale, text width=5em] {$\hat{e}_2$};
		\draw[dotted, thick] (\px,0) --  (\px,\py) node[midway,right, scale=\textscale]{${x}^2$}; 
		\draw[dotted, thick] (0,\py) --  (\px,\py)  node[midway,above, scale=\textscale]{${x}^1$};  
		
		\draw[-latex] (\px,\py)  -- (\px+\vx,\py+\vy)  node[right=22,above=-4,scale=\textscale, text width=5em] {${\varphi}$};
		\draw[dotted, thick] (\px,\py) --  (\px,\py+\vy) node[midway,left, scale=\textscale]{${\varphi}^2$}; 
		\draw[dotted, thick] (\px,\py+\vy) --  (\px+\vx,\py+\vy) node[midway,above, scale=\textscale]{${\varphi}^1$};  
	
		\begin{scope}[rotate=\th,draw=red, text=red]
		   \draw[-latex] (0,0) -- (\rrange,0)  node[right,scale=\textscale, text width=5em]  {$\hat{e}'_1$};
			  \draw[-latex] (0,0) -- (0,\rrange)  node[right,scale=\textscale, text width=5em] {$\hat{e}'_2$};
		\draw[dotted, thick] (\pxd,\pyd) --  (\vxtd,\pyd) node[midway,right=3,below=-3, scale=\textscale]{${\varphi'}^1$}; 
		\draw[dotted, thick] (\vxtd,\pyd) --  (\vxtd,\vytd) node[midway,right=6,above=-4, scale=\textscale]{${\varphi'}^2$};  
		\end{scope}
	
	  \draw [black,fill] (\px,\py) circle [radius=\circsize pt];    
		\coordinate[label = below: (b)]  (D) at (\labelx,\labely); 
	\end{tikzpicture}% pic 1
	\vspace*{2px}
	\caption{Shows how a four-vector ${\varphi}$ (of which only two components are shown) defined at a spacetime location (indicated by $\bullet$) can be expressed either as $(\varphi^1, \varphi^2)$ with respect to the basis $\{\hat{e}_1,\hat{e}_2\}$ or as $({\varphi'}^1,{\varphi'}^2)$ with respect to the basis $\{\hat{e}'_1,\hat{e}'_2\}$.}\label{rotfigure2}
	\end{figure}
Figure \ref{rotfigure2} shows how (two of) the components of a four-vector $\varphi$ at a particular location will differ for different observers under a spatial rotation of the coordinates. A four-vector $\varphi^\mu(x)$ defined at every spacetime location $x$ is called a \textbf{four-vector field}. If $O$ observes this vector-field $\varphi^\mu(x)$, and $O'$ is another observer whose coordinates are related to the coordinates $O$ via the Lorentz transformation $\Lambda$, then $O'$ will describe this vector-field as ${\varphi'}^\mu(x')\myeq\Lambda\indices{^\mu_\nu}\varphi^\nu(x).$ Hence, under the Lorentz transformation $\Lambda$, ${\varphi}^\mu\rightarrow {\varphi'}^\mu$ where
\begin{equation}\label{lorentzvector}
{\varphi'}^\mu(x)=\Lambda\indices{^\mu_\nu}\varphi^\nu(\Lambda^{-1}x).
\end{equation} 



From a four-vector $\varphi^\mu$, we can also define the so called \textbf{four-covector}: 
\begin{equation}\label{covector}
	\varphi_\mu\myeq\eta_{\mu\nu}\varphi^\nu.
\end{equation}
To see how four-covectors transform under a Lorentz transformation $\Lambda$, it will be helpful to define 
\begin{equation}\label{colambda}
	\Lambda\indices{_\mu^\nu}\myeq\eta_{\mu\rho}\eta^{\nu\sigma}\Lambda\indices{^\rho_\sigma}
\end{equation}
where $\eta^{\nu\sigma}=\eta_{\nu\sigma}$. If we also define the \textbf{Kronecker-delta} $\delta^\nu_\mu$ such that $\delta^\nu_\mu=1$ when $\mu=\nu$ and $\delta^\nu_\mu=0$ otherwise, then using the fact that $\eta_{\mu\rho}\eta^{\nu\rho}=\delta^\nu_\mu$ together with equation (\ref{lorentztrans}), we have 
\begin{equation}\label{lambdainverse}
\Lambda\indices{^\rho_\mu}\Lambda\indices{_\rho^\nu}=\delta^\nu_\mu.
\end{equation}
Since by definition, the inverse of $\Lambda^{-1}$ satisfies 
$(\Lambda^{-1})\indices{^\nu_\rho}\Lambda\indices{^\rho_\mu}=\delta^\nu_\mu,$
 we have $(\Lambda^{-1})\indices{^\nu_\rho}=\Lambda\indices{_\rho^\nu}.$  From (\ref{lorentzvector}), (\ref{covector}), and (\ref{colambda}), we therefore see that under a Lorentz transformation $\Lambda$, a four-covector field $\varphi_\mu(x)$ transforms as $\varphi_\mu(x)\rightarrow\varphi'_\mu(x')$
where
\begin{equation}\label{lorentzcovector}
\varphi'_\mu(x)=\Lambda\indices{_\mu^\nu}\varphi_\nu(\Lambda^{-1}x)
\end{equation}
 

Besides scalars, four-vectors, and four-covectors, we also need to consider physical quantities called rank-two tensors. The stress-energy tensor $T^{\mu\nu}$ mentioned on page \pageref{stressenergy} is an example of a rank-two tensor. The defining property of a rank-two tensor field $\varphi^{\mu\nu}(x)$ is that under a Lorentz transformation $\Lambda$, $\varphi^{\mu\nu}(x)\rightarrow{\varphi'}^{\mu\nu}(x')$ where
\begin{equation}\label{lorentztensor}
{\varphi'}^{\mu\nu}(x)=\Lambda\indices{^\mu_\rho}\Lambda\indices{^\nu_\sigma}\varphi^{\rho\sigma}(\Lambda^{-1}x).
\end{equation}
On page \pageref{massenergydensity}, we introduced the mass-energy density $T_S(x)$ on a hypersurface $S$. As explained in section \ref{massenergydensity}, the values of $T_S(x)$ are the additional values that Kent uses to supplement standard quantum theory.  It was mentioned in passing that $T_S(x)$ does not depend on which frame of reference one is in. In other words, $T_S(x)$ is a scalar. I will now explain why this is so. 

We first need to consider the precise definition of $T_S(x)$. At each spacetime location on the hypersurface $S$ which an observer $O$ describes as having coordinates $x=(x^\mu)_{\mu=0}^3$, we define  $\eta^\mu(x)$ to be the future-directed  unit four-vector at $x$ that is orthogonal to $S$. In other words, $\eta^0(x)>0$, $\eta_\mu(x)\eta^\mu(x)=1$, and if $y\in S$ is very close to $x$, then $\frac{(x-y)_\mu\eta^\mu(x)}{\sqrt{(x-y)_\nu(x-y)^\nu}}\approx 0.$  $T_S(x)$ is then given by the formula 
\begin{equation}\label{TSdef}
T_S(x)=T^{\mu\nu}(x)\eta_{\mu}(x)\eta_{\nu}(x).
\end{equation}
For example, if $S$ was the hypersurface consisting of all spacetime locations $x = (0,x^1,x^2,x^3)$, then $\big(\eta^{0}(x),\eta^{1}(x),\eta^{3}(x),\eta^{3}(x)\big) =(1,0,0,0),$ and hence $T_S(x)=T^{00}(x)$ which is the density of relativistic mass at $x$, i.e. the energy density at $x$ divided by $c^2$. 

To see why $T_S(x)$ is a scalar, suppose that $\Lambda$ is a Lorentz transformation such that $\Lambda\indices{^0_\mu}\eta^\mu>0$ for any future-directed  unit four-vector vector $\eta^\mu$. We refer to a $\Lambda$ with this property as an \textbf{orthochronous} Lorentz transformation. Also suppose that $O$ and $O'$ are two observers such that spacetime locations that observer $O$ describes as having coordinates $x=(x^\mu)_{\mu=0}^3$ are described by $O'$ as having coordinates $x'=(\Lambda\indices{^\mu_\nu}x^\nu)_{\mu=0}^3$. Then since ${x'}_\mu{y'}^\mu= x_\mu y^\mu$, it follows that the future-directed unit four-vector orthogonal to $S$ at $x$ which $O$ describes as $\eta^\mu(x)$ will be described by $O'$ as  ${\eta'}^\mu(x')=\Lambda\indices{^\mu_\nu}\eta^\nu(x)$. Thus, for any location in $S$ that $O'$ describes as having coordinates $x'$ with corresponding  future-directed $S$-orthogonal unit four-vector ${\eta'}^\mu(x')$, $O'$ can construct a function $T'_S(x')$  with 
\begin{equation}\label{TSprimedef}
T'_S(x')=T'^{\mu\nu}(x')\eta'_{\mu}(x')\eta'_{\nu}(x').
\end{equation}
Then using  (\ref{lorentzcovector}) and (\ref{lorentztensor}) on the right-hand side of (\ref{TSprimedef}),  we have
\begin{equation}\label{invariantTS1}
\begin{split}
T'_S(x')&=\Lambda\indices{^\mu_\rho}\Lambda\indices{^\nu_\sigma}T^{\rho\sigma}(x)\Lambda\indices{_\mu^\alpha}\eta_{\alpha}(x)\Lambda\indices{_\nu^\beta}\eta_{\beta}(x)\\
&=\Lambda\indices{^\mu_\rho}\Lambda\indices{_\mu^\alpha} \Lambda\indices{^\nu_\sigma}\Lambda\indices{_\nu^\beta}T^{\rho\sigma}(x)\eta_{\alpha}(x)\eta_{\beta}(x)\\
&=\delta^\alpha_\rho\delta^\beta_\sigma T^{\rho\sigma}(x)\eta_{\alpha}(x)\eta_{\beta}(x)\\
&=T^{\alpha\beta}(x)\eta_{\alpha}(x)\eta_{\beta}(x)\\
&=T_S(x)
\end{split}
\end{equation}
where on the third line we have used (\ref{lambdainverse}) and on the last line we have used (\ref{TSdef}). To obtain (\ref{invariantTS1}), we assumed that $\Lambda$ is orthochronous, but if $\Lambda$ is non-orthochronous, we would need to take the negations of ${\eta'}^\mu(x')$ to get the future-directed $S$-orthogonal unit four-vector. But clearly this will not affect the equality in (\ref{invariantTS1}), so (\ref{invariantTS1}) holds for all Lorentz transformations, whether they are orthochronous or non-orthochronous.  We thus see that   $T_S(x)$ is a scalar.

Let us now consider the Hilbert space $H_{S_n}$ as defined on page \pageref{HSidef} for a hypersurface $S_n$. 
Given that $\hat{T}^{\mu\nu}(x)$ is the observable whose eigenstates with eigenvalues $\tau$ are the states of $S_n$ for which an observer $O$ observes the stress-energy tensor $T^{\mu\nu}(x)$ to take the value $\tau$ at $x$, it follows from (\ref{TSdef}) that 
\begin{equation}\label{TShat}
	T_S(x)\myeq T^{\mu\nu}(x)\eta_{\mu}(x)\eta_{\nu}(x)
	\end{equation}
	will be the observable whose eigenstates with eigenvalues $\tau_S(x)$ are the states of $S_n$ for which an observer $O$ observes $T_S(x)$ to take the value $\tau_S(x)$ at $x$.
Two observers $O$ and $O'$ will typically assign different physical states to $S_n$ based on their frame of reference. E.g. if $O$ and $O'$ are traveling at different speeds, they will attribute different energy levels and momenta to the spacetime locations of $S_n$. For the Lorentz transformation that relates the coordinates of $O'$ to the coordinates of $O$, i.e. $x'=\Lambda x$,  there  will then be a unitary operator $U(\Lambda):H_{S_n}\rightarrow H_{S_n}$ such that if
$O$ observes  $S_n$ to be in the state $\ket{\psi_n}\in H_{S_n}$, then $O'$ will observe $S_n$ to be in the state $U(\Lambda)\ket{\psi_n}$. But in order for $U(\Lambda)\ket{\psi_n}$ to be meaningful, we need to specify how the Hermitian operators that act on $U(\Lambda)\ket{\psi_n}$ correspond to the physical quantities that $O'$ observes. So we specify that the Hermitian operator 
\begin{equation}\label{Thatprime}
\hat{T}'^{\mu\nu}(x')=\hat{T}^{\mu\nu}(x')
\end{equation}
will be the observable whose eigenstates with eigenvalues $\tau'$ are the states of $S_n$ for which $O'$ observes the stress-energy tensor $T^{\prime\mu\nu}(x')$ to take the value $\tau'$ at $x'$. Since $T^{\mu\nu}(x)$ transforms according to (\ref{lorentztensor}), it will follow that
\begin{equation}\label{TUrelation}
U(\Lambda)^{-1}\hat{T}^{\mu\nu}(x)U(\Lambda)=\Lambda\indices{^\mu_\rho}\Lambda{^\nu_\sigma}\hat{T}^{\rho\sigma}(\Lambda^{-1}x).
\end{equation}

We also insist that $U(\Lambda)$ is unitary because this means that if $O$ calculates the probability $S_n$ transitions from state $\ket{\psi_n}$ to state $\ket{\chi_n}$, then $O'$ would calculate the same probability for the corresponding transition from the state $\ket{\psi_n'}=U(\Lambda)\ket{\psi_n}$ to the state $\ket{\chi_n'}=U(\Lambda)\ket{\chi_n}.$\footnote{This follows from (\ref{unitarycond}) which implies 
$\abs{\ip{\chi'_n}{\psi'_n}}^2=\abs{\ip{\chi_n}{\psi_n}}^2$, together with the Born rule given on page \pageref{bornrule}.}

Now to say that Kent's model is Lorentz invariant, is to say that (\ref{kentconsistency0}) defines a rank-two tensor, for then this quantity and the quantities on which it depends will transform in the way that physical quantities should transform under a Lorentz transformation. Thus, in order to show that Kent's model is Lorentz invariant, we need to show that if $\{\ket{\xi_j}\}_{j=1}^\infty$ is an orthonormal basis of the Hilbert space of states $H_{S_n,\tau_S}$ for which $O$ observes $T_S(x)$ to be $\tau_S(x)$ for all $x\in S_n(y)\cap S$, and if $\{\ket{\xi_j'}\}_{j=1}^\infty$ is an orthonormal basis of the Hilbert space of states $H_{S_n,\tau_S'}$ for which $O'$ observes $T'_S(x')$ to be $\tau'_S(x')$ for all $x'\in S_n(y')\cap S$, then
\begin{equation}\label{kentlorentz}
\lim_{n\rightarrow\infty}\frac{\ev{\pi_n'\hat{T}^{\mu\nu}(y')}{\Psi_n'}}{\ev{\pi_n'}{\Psi_n'}}=\Lambda\indices{^\mu_\rho}\Lambda\indices{^\nu_\sigma} \lim_{n\rightarrow\infty}\frac{\ev{\pi_n\hat{T}^{\rho\sigma}(y)}{\Psi_n}}{\ev{\pi_n}{\Psi_n}}
\end{equation}
where $\pi_n=\sum_j\dyad{\xi_j}$, $\pi_n'=\sum_j\dyad{\xi_j'}$, and $\ket{\Psi_n'}=U(\Lambda)\ket{\Psi_n}$. To see why (\ref{kentlorentz}) holds, we first recall that $\pi_n'$ will be independent of which orthonormal basis we choose for $H_{S_n,\tau_S'}$.\footnote{We showed this was the case for $\pi_n$ in footnote \ref{priproof} on page \pageref{priproof}.} Therefore, if we can show that $\{\ket{\xi_j'}\myeq U(\Lambda)\ket{\xi_j}\}_{j=1}^\infty$ is an orthonormal basis of $H_{S_n,\tau_S'}$, it will follow that $\pi_n'=U(\Lambda)\pi_nU(\Lambda)^{-1}$. 

That the elements of $\{U(\Lambda)\ket{\xi_j}\}_{j=1}^\infty$ are orthonormal follows from the unitarity of $U(\Lambda)$ together with the orthonormality of  $\{\ket{\xi_j}\}_{j=1}^\infty$.  Since $\hat{T}^{\mu\nu}(x')$ is the observable whose eigenstates with eigenvalue $\tau'$ are the states of $S_n(y')$ for which $O'$ observes the stress-energy tensor $T^{\prime\mu\nu}(x')$ to take the value $\tau'$ at $x'$, it follows from (\ref{TSprimedef}) and (\ref{Thatprime})  that 
\begin{equation}\label{TShatprime}
	\hat{T}'_S(x')\myeq\eta_\mu'(x')\eta_\nu'(x')\hat{T}^{\mu\nu}(x')
\end{equation}
 will be the observable whose eigenstates with eigenvalue $\tau'_S$ are the states of $S_n(y')$ for which $O'$ observes $T'_S(x')$ to take the value $\tau'_S$ at $x'$, where as usual, $\eta^{\prime\mu}(x')$ is the unit four-vector orthogonal to $S_n(y')$ at $x'$. Now if $x'\in S_n(y')\cap S$ in the coordinates of $O'$, then $x=\Lambda^{-1}x'\in S_n(y)\cap S$ in the coordinates of $O$. Using the same calculation as in (\ref{invariantTS1}) together with (\ref{lorentzcovector}), we have
\begin{equation}\label{TSLambda}
\begin{split}
\hat{T}_S(x)&\myeq\eta_\mu(x)\eta_\nu(x)\hat{T}^{\mu\nu}(x)\\
&=\eta_{\mu}'(x')\eta_{\nu}'(x') \Lambda\indices{^\mu_\rho}\Lambda\indices{^\nu_\sigma}\hat{T}^{\rho\sigma}(x)
\end{split}
\end{equation}
By (\ref{TUrelation}) we have
\begin{equation}
	U(\Lambda)^{-1}\hat{T}^{\mu\nu}(x')=\Lambda\indices{^\mu_\rho}\Lambda{^\nu_\sigma}\hat{T}^{\rho\sigma}(x)U(\Lambda)^{-1},
\end{equation}
so using this with (\ref{TSLambda}) and (\ref{TShatprime}), we have
\begin{equation}\label{TSU}
\begin{split}
\hat{T}_S(x)U(\Lambda)^{-1}&=\eta_{\mu}'(x')\eta_{\nu}'(x')\Lambda\indices{^\mu_\rho}\Lambda\indices{^\nu_\sigma}\hat{T}^{\rho\sigma}(x)U(\Lambda)^{-1}\\
&=U(\Lambda)^{-1} \eta_{\mu}'(x')\eta_{\nu}'(x')\hat{T}^{\mu\nu}(x')\\
&=U(\Lambda)^{-1} \hat{T}_S'(x').
\end{split}
\end{equation}
Now suppose that $\ket{\xi'}$ is a state for which $O'$ observes $T'_S(x')$ to be $\tau'_S(x')$ for all $x'\in S_n(y')\cap S$. Then $\hat{T}_S'(x')\ket{\xi'}=\tau_S'(x'),$ and so by (\ref{TSU}), 
\begin{equation}\label{TSUxi}
\begin{split}
\hat{T}_S(x)U(\Lambda)^{-1}\ket{\xi'}&= U(\Lambda)^{-1} \hat{T}_S'(x')\ket{\xi'}\\
&=\tau_S'(x')U(\Lambda)^{-1}\ket{\xi'}\\
&=\tau_S(x)U(\Lambda)^{-1}\ket{\xi'}
\end{split}
\end{equation}
where on the last line we have used the fact that $T_S(x)$ is a scalar. Therefore, $U(\Lambda)^{-1}\ket{\xi'}$ can be expressed as a linear combination of the basis elements $\{\ket{\xi_j}\}_{j=1}^\infty$ of $H_{S_n,\tau_S}$, and hence  $\ket{\xi'}$  can be expressed as a linear combination of $\{U(\Lambda)\ket{\xi_j}\}_{j=1}^\infty$. From (\ref{TSU}) we also see that  $U(\Lambda)\hat{T}_S(x)=\hat{T}_S'(x')U(\Lambda)$, so
$$
\hat{T}_S'(x')U(\Lambda)\ket{\xi_j}=U(\Lambda)\hat{T}_S(x)\ket{\xi_j}=\tau_S(x)U(\Lambda)\ket{\xi_j}=\tau_S'(x')U(\Lambda)\ket{\xi_j}
$$
for all $x'\in S_n(y')\cap S$. Therefore, $U(\Lambda)\ket{\xi_j}\in H_{S_n,\tau_S'}$.
Since $\{\ket{\xi_j'}\myeq U(\Lambda)\ket{\xi_j}\}_{j=1}^\infty$ is a spanning orthonormal subset of $H_{S_n,\tau_S'}$, it must therefore be an orthonormal basis of $H_{S_n,\tau_S'}$. From this it follows that $\pi_n'=U(\Lambda)\pi_nU(\Lambda)^{-1}$. Therefore, 
\begin{equation}\label{kentlorentz2}
\begin{split}
\frac{\ev{\pi_n'\hat{T}^{\mu\nu}(y')}{\Psi_n'}}{\ev{\pi_n'}{\Psi_n'}}&=\frac{\ev{U(\Lambda)^{-1}U(\Lambda)\pi_nU(\Lambda)^{-1}\hat{T}^{\mu\nu}(y')U(\Lambda)}{\Psi_n}}{\ev{U(\Lambda)^{-1}U(\Lambda)\pi_n U(\Lambda)^{-1}U(\Lambda)}{\Psi_n}}\\
&=\frac{\ev{\pi_nU(\Lambda)^{-1}\hat{T}^{\mu\nu}(y')U(\Lambda)}{\Psi_n}}{\ev{\pi_n}{\Psi_n}}\\
&=\frac{\ev{\pi_n\Lambda\indices{^\mu_\rho}\Lambda{^\nu_\sigma}\hat{T}^{\rho\sigma}(y)}{\Psi_n}}{\ev{\pi_n }{\Psi_n}}
\end{split}
\end{equation}
where on the last line we have used (\ref{TUrelation}). Thus, equation (\ref{kentlorentz}) holds, and hence Kent's model is Lorentz invariant.

Note that in this proof of Lorentz invariance, we don't need to take the limit of $S_n$ as $n\rightarrow\infty$. That is, we could remove the $\lim_{n\rightarrow\infty}$ from equation (\ref{kentconsistency0}) and consider a particular $S_n$, and the corresponding $\ev*{T^{\mu\nu}(y)}_{\tau_S}$ would still be a rank-two tensor. Butterfield tells us that Kent's interpretation is  Lorentz invariant because his algorithm respects the light cone structure of $y$.\footnote{See \cite[30]{Butterfield}.} However, this statement could be slightly misleading because we don't need to consider the subset $S^1(y)\subset S$ of locations outside the light cone of $y$ in order to obtain a Lorentz invariant model. Doing the calculation on any Tomonaga-Schwinger hypersurface is sufficient to guarantee Lorentz invariance since any such hypersurface (e.g. $S_n$) is not altered at all by a Lorentz transformation - only its coordinate description changes under a Lorentz transformation, and so the additional information of the scalar $\tau_S(x)$ on $S_n\cap S$ is Lorentz invariant. The only reason we need to consider the limit $\lim_{n\rightarrow \infty}S_n$ and hence $S^1(y)=\lim_{n\rightarrow \infty}S_n\cap S$ is that it is only in the limit that we use all the available information in $\tau_S(x)$ to calculate $\ev*{T^{\mu\nu}(y)}_{\tau_S}$. 



\subsection{Kent's Interpretation and Decoherence Theory\textsuperscript{*}}
In section \ref{probOutcomes} we saw that decoherence theory by itself does not offer a solution to the problem of outcomes. In this section, we consider how the additional information in Kent's interpretation is sufficient to address this problem. We will explain this by again considering  Kent's toy model discussed in section \ref{toysection}.

We thus suppose that a system is in a superposition $\psi_0^\text{sys} = c_1\psi_1^\text{sys}+c_2\psi_2^\text{sys}$ of two local states $\psi_1^\text{sys}$ and $\psi_2^\text{sys}$ where $\abs{c_1}^2+\abs{c_2}^2=1$, and that there is a photon coming in from the left that interacts with the system. We also suppose that  $y_1$ is a spacetime location with spatial location $z_1$ between the two hypersurfaces $S_0$ and $S$, and we consider a hypersurface $S_n=S_n(y_1)$  in a sequence of hypersurfaces that each contain $y_1$ as described on page \pageref{siydef}. 

In order to obtain a sufficiently simple description of the state $\ket{\Psi_n}\in H_{S_n}$ of $S_n$ for which we can use the formula (\ref{kentconsistency0}) to calculate Kent's beable, we will  
use a coarse-grained model so that $S_n$ is treated as a mesh of tiny cells labeled by a sequence $(y_k)_{k=1}^\infty$. Thus, for each cell $y_k$ there will be a Hilbert space $H_k$ describing the state of that cell. We can think of each of these $y_k$ as systems that can become entangled with one another, but we will assume that $y_1$ is entangled with only a finite number $M$ of the other $y_k$. What this means is that the most general expression for $\ket{\Psi_n}$ will be of the form
\begin{equation}\label{Sistate}
\ket{\Psi_n}=\Big(\sum_j\sum_{n\in\mathbb{N}^M} c_{j,n}\ket{\xi_{1,j}}\prod_{l=1}^{M}\ket{\xi_{k_{l},n_l}}\Big)\Xi.
\end{equation}
In this expression, $\{\ket{\xi_{1,j}}:j\}$ is an orthonormal basis of $H_1$, $\mathbb{N}^M$ means the set of all lists $(n_1,\ldots,n_M)$ with each $n_l\in\mathbb{N}$ where $\mathbb{N}$ is the set of positive integers greater than 0. The set of states $\{\ket{\xi_{k_{l},n_l}}:n_l\in\mathbb{N}\}$ form an orthonormal basis of $H_{k_{l}}$ for each $k_l$, and the $k_{l}$ are all distinct from each other and from $1$. Also, $M$ is chosen to be as small as possible so that any common factors of $\ket{\Psi_n}$ belong to $\Xi$ which is a sum of states of the form $\prod_l\ket{\xi_{\kappa_l}}$ where the states $\ket{\xi_{\kappa_l}}\in H_{\kappa_l}$ range over all the cells of $S_n$ not included in the set $\{k_{l}\}_{l=1}^M.$ We also assume that each summand $c_{j,n}\ket{\xi_{1,j}}\prod_{l=1}^{M}\ket{\xi_{k_{l},n_l}}\Xi$ of $\Psi_n$ contains a state in each $H_k$ for every cell $k$ of $S_n$. In other words if $k\neq 1$ and does not belong to the set $\{k_{l}\}_{l=1}^M$ then $k$ belongs to the set $\{\kappa_l:l\}$. Also, we will give $H_{S_n}$ an inner product so that if 
$$ \ket{\Psi_n'}=\Big(\sum_j\sum_{n\in\mathbb{N}^M} c'_{j,n}\ket{\xi_{1,j}}\prod_{l=1}^{N_j}\ket{\xi_{k_{l},n_l}}\Big)\Xi',$$ then
$$\ip{\Psi_n'}{\Psi_n}=\Big(\sum_j\sum_{n\in\mathbb{N}^M} \overline{c'_{j,n}}c_{j,n} \Big) \ip{\Xi'}{\Xi}$$
where $\ip{\Xi'}{\Xi}$ is defined in the obvious way. With this inner product, we will assume that $\ket{\Psi_n}$ is appropriately normalized so that $\ip{\Psi_n}{\Psi_n}=1$. If we also assume that  $\ip{\Xi}{\Xi}=1$, it will follow that $\sum_j\sum_{n\in\mathbb{N}^M}\abs{c_{j,n}}^2=1.$

We now consider several scenarios from Kent's toy model. In each scenario, we will use the decomposition (\ref{Sistate}) of $\ket{\Psi_n}$ to calculate the partial trace encapsulating all the information needed to calculate expectation values at different spacetime locations. 

First, consider Figure \ref{kentdeco1} which depicts the hypersurface $S_n(y^a_1)$ for a spacetime location $y^a_1$ that occurs before the photon has interacted with the system.

\begin{figure}[ht!]
\captionsetup{justification=justified}
\centering
\tikzmath{
\a=5.3;  
\psione=0;
\psitwo=1.5;
\h=1;
\labelx=(\psione+\psitwo)/2;
\labely=-1.5;
\phstartx=-1.7;
\phstarty=\h;
\tbeg=\phstarty;
\ca=\phstartx-\tbeg;
\ttwo=\psitwo-\ca;
\cb=\ttwo+\ca;
\xend=\ttwo-\a+\cb;
\tone=\psione-\ca;
\cc=\tone+\ca;
\xendz=\tone-\a+\cc;
\tthree=\cc+\tone-\psitwo;
\circsize=0.08;
\md = (\a+\h)/2;
\tlen=0.75;
\textscale = 0.7;
\picscale = 0.89;
\nudge=0.1;
\tnudge=(\ttwo-\tone)/2+0.8;
\ttesta=2*\tone-\ttwo-\tnudge;
\ttestb=2*\tone-\ttwo+\tnudge;
\ttestc=\ttwo-\tnudge;
\ttestd=\ttwo+\tnudge;
\sonea=\a+\psione-\ttesta;
\sadd=0.5;
\lrange = -(\psione-\a+\ttesta)+\sadd;
\rrange =\lrange; 
\timex=\rrange-1.5;
\e = 0.4;
\ttestx=2.4;
\at=\a-\ttestx;
\ct=\ttestx;
\lam = 0.87;
\e = 0.2;
\hae=(2*pow(\at,3)*\lam*(2+\lam)+\e*\e*(2*\e-sqrt(4*\e*\e+\at*\at*\lam*\lam))-8*\at*\e*(-2*\e+sqrt(4*\e*\e+\at*\at*\lam*\lam))-2*\at*\at*(2+\lam)*(-2*\e+sqrt(4*\e*\e+\at*\at*\lam*\lam)))/(4*\at*\lam*(2*\at+2*\e-sqrt(4*\e*\e+\at*\at*\lam*\lam)))-(\e*\e/4+\at*\at*(-1+\lam))/(\at*\lam);
\mmu=(\tone-\tbeg)/(\psione-\phstartx);
\nnu=(\psione*\tbeg-\phstartx*\tone)/(\psione-\phstartx);
} 
\tikzstyle{scorestars}=[star, star points=5, star point ratio=2.25, draw, inner sep=1pt]%
\tikzstyle{scoresquare}=[draw, rectangle, minimum size=1mm,inner sep=0pt,outer sep=0pt]%
\begin{tikzpicture}[scale=\picscale,
declare function={
	testxonep(\ps,\t)=\a+\ps-\t;
	testxonem(\ps,\t)=\ps-\a+\t; 
	xa(\m,\n)=(-\ct*\m+\e*\m+\m*\n-sqrt(\ct*\ct*\lam*\lam+\e*\e*\m*\m+2*\e*\lam*\lam*\n+\lam*\lam*\n*\n-2*\ct*\lam*\lam*(\e+\n)))/(\lam*\lam-\m*\m);
	xb(\m,\n)=(-\ct*\m+\e*\m+\m*\n+sqrt(\ct*\ct*\lam*\lam+\e*\e*\m*\m+2*\e*\lam*\lam*\n+\lam*\lam*\n*\n-2*\ct*\lam*\lam*(\e+\n)))/(\lam*\lam-\m*\m);
	bl(\x)=\ct+\at-\e/2-1/2*(sqrt(\lam*\lam*pow(\x+\hae+\at,2)+\e*\e)-\e+\lam*(\x+\hae+\at));
	br(\x)=\ct+\at-\e/2-1/2*(sqrt(\lam*\lam*pow(\x-\hae-\at,2)+\e*\e)-\e-\lam*(\x-\hae-\at));
	bc(\x)=\ct+sqrt(\lam*\lam*\x*\x+\e*\e)-\e;
},
 ] 
\definecolor{tempcolor}{RGB}{250,190,0}
\definecolor{darkgreen}{RGB}{40,190,40}

\draw[->,blue, thick] [domain=-\at/2:-\lrange, samples=150]   plot (\x, {bl(\x)})  ;
\draw[blue, thick] [domain=-\at/2:\at/2, samples=150] plot (\x, {bc(\x)})   ;
\draw[->,blue, thick] [domain=\at/2:\rrange, samples=150]   plot (\x, {br(\x)})   ;
 \node[scale=\textscale]  at (2.7,4.1) {$S_n(y^a_1)$}; 

\draw[<->] (-\lrange, \h) node[left, scale=\textscale] {$S_0$} -- (\rrange, \h) node[right, scale=\textscale] {$S_0$};
\draw[<->] (-\lrange, \a) node[left, scale=\textscale] {$S$} -- (\rrange, \a) node[right, scale=\textscale] {$S$};
              
\draw[->, shorten <= 5pt,  shorten >= 1pt] (\psione,\h) node[below, scale=\textscale]{$\psi_1^{\text{sys}}$} node[above left, scale=\textscale]{$z_1$}-- (\psione,\a) ;
\draw[->,  shorten <= 5pt,  shorten >= 1pt] (\psitwo,\h) node[below, scale=\textscale]{$\psi_2^{\text{sys}}$} node[above right, scale=\textscale]{$z_2$}-- (\psitwo,\a);

\draw[dashed, tempcolor,  thick](\phstartx,\tbeg) node[below left=-2,scale=\textscale]{}--(\psione,\tone) node[above, pos=0.3, rotate=45,scale=0.7,black] {} node[below, pos=0.3, rotate=45,scale=0.7,black] {};
\draw[dashed, tempcolor](\psione,\tone) node[below left=-2,scale=\textscale]{}--(\psitwo,\ttwo );
\draw[dashed, tempcolor](\psitwo,\ttwo)--(\xend,\a); 
\draw[dashed, tempcolor,  thick](\psione,\tone)--(\xendz,\a);



%\draw[dashed, darkgreen, ultra thick](\psione,\tone)--(\psitwo,\tthree);
%\draw [black,fill] (\psitwo,\tthree) circle [radius=\circsize] node [black,below=4,right,scale=\textscale] {$2t_1-t_2$}; 


%\draw [black,fill] (\psione,\tone) circle [radius=\circsize] node [black,left=4,scale=\textscale] {$t_1$}; 
%\draw [black,fill](\psitwo,\ttwo)circle [radius=\circsize] node [black,above right,scale=\textscale, align=left] {$t_2$}; 

%\draw [decorate, decoration = {calligraphic brace}] (\psitwo+\nudge,\ttwo) --  (\psitwo+\nudge,\tone+\nudge/4) node[midway,right, scale=\textscale]{$t_2-t_1$}; 
%\draw [decorate, decoration = {calligraphic brace}] (\psitwo+\nudge,\tone-\nudge/4) --  (\psitwo+\nudge,2*\tone-\ttwo) node[midway,right, scale=\textscale]{$t_2-t_1$}; 

\draw[->] (\timex,\md-\tlen/2) --  (\timex,\md+\tlen/2) node[midway,right, scale=\textscale]{time}; 
 
\draw[dotted](\psione,\ttestx)--({testxonep(\psione,\ttestx)},\a);
\draw[dotted](\psione,\ttestx)--({testxonem(\psione,\ttestx)},\a);
%\draw [black,fill](\psione,\ttestx) circle [radius=\circsize] node [black,below=6,left,scale=\textscale] {$y^a_1$}; 
\draw (\psione,\ttestx) node[ scoresquare, fill=gray]  {} node [black,below=6,right,scale=\textscale] {$y^a_1$};
\draw (\psitwo, {bc(\psitwo)}) node[ scoresquare, fill=gray]  {} node [black,below=6,right,scale=\textscale] {$y^a_2$};
\draw ({xa(\mmu,\nnu)}, {xa(\mmu,\nnu)*\mmu+\nnu}) node[ scoresquare, fill=white]  {} node [black,left=7,below=-4,scale=\textscale] {$y^a_3$};

\draw[magenta,->,ultra thick] ({testxonem(\psione,\ttestx)},\a)--(-\lrange,\a);
\draw[magenta,->,ultra thick] ({testxonep(\psione,\ttestx)},\a)--(\rrange,\a);
%\draw [black,fill] (\xendz,\a) circle [radius=\circsize] node [black,above,scale=\textscale] {$\gamma_1$}; 
\end{tikzpicture}% pic 1

\vspace*{2px}
\caption{Depiction of a superposition of two local states at $z_1$ and $z_2$ before the photon has interacted with them. The gray squares indicate cells in $S^1(y^a_1)$ whose states are among the summands in (\ref{Sistate}) rather than in $\Xi$. The white square indicates a cell in $S_n(y^a_1)$ whose state is a factor in $\Xi$.}
\label{kentdeco1}
\end{figure}

The gray squares correspond to the summands that appear in (\ref{Sistate}). If the system were in the $\psi_1^\text{sys}$-state, then the state describing $S_n(y^a_1)$ would have a factor $\ket{\psi_1^\text{sys}}\in H_1$ indicating that there is a 
non-zero mass at the $y^a_1$-cell, and there would also be a factor $\ket{0_2}\in H_2$ which we use to indicate that there is zero mass/energy at $y^a_2$. 
There is also an incoming photon at the $y^a_3$-cell, and so we use $\ket{\gamma_3}$ to indicate that there is a photon there.
 Thus, if  the system  were in the $\psi_1^\text{sys}$-state, we would write the state of $S_n(y^a_1)$ 
 as $\ket{\Psi_n}=\ket{\psi_1^\text{sys}}\ket{0_2}\ket{\gamma_3}\Xi'$ where $\Xi'$ describes the states of all the other cells of $S_n(y^a_1)$. In this very simple scenario, $\Xi'=\sum_{k\neq 1,2,3}\ket{0_k}$ indicating that there is zero mass/energy at all the other $y_k$.

 Alternatively, if the system were in the state $\psi_2^\text{sys}$, then the state describing $S_n(y^a_1)$ would have a factor $\ket{\psi_2^\text{sys}}\in H_2$ 
 indicating that there is a non-zero mass at the $y^a_2$-cell, and there would also be a factor $\ket{0_1}\in H_1$ which we use to indicate that there is zero mass at $y^a_1$,
  and again the $y^a_3$-cell would be in the $\ket{\gamma_3}$, and every other cell would be described by  $\Xi'$  just as if the system had been in the $\psi_1^\text{sys}$-state. Therefore, when the system is in the state $\psi_2^\text{sys}$, we would write the state of $S_n(y^a_1)$ as $\ket{\Psi_n}=\ket{0_1}\ket{\psi_2^\text{sys}}\ket{\gamma_3}\Xi'$. 
 
 Now since the system is actually in a supposition $\psi_0^\text{sys} = c_1\psi_1^\text{sys}+c_2\psi_2^\text{sys}$, the state of $S_n(y^a_1)$ will be 
 \begin{equation*}
 \ket{\Psi_n}=\big(c_1\ket{\psi_1^\text{sys}}\ket{0_2}+c_2\ket{0_1}\ket{\psi_2^\text{sys}}\big)\ket{\gamma_3}\Xi'=\big(c_1\ket{\psi_1^\text{sys}}\ket{0_2}+c_2\ket{0_1}\ket{\psi_2^\text{sys}}\big)\Xi
 \end{equation*}
where we have absorbed the $\ket{\gamma_3}$-state into $\Xi$ (i.e. $\Xi= \ket{\gamma_3}\Xi'$).

Now as it stands, the state $\ket{\Psi_n}$ describing $S_n(y^a_1)$ has a definite mass-energy density $\tau_S(x)$ for $x\in S_n(y^a_1)\cap S$, namely $0$. Thus, if $\pi_n$ is the operator featuring in (\ref{kentconsistency0}) that corresponds to this definite mass-energy density, then $\pi_n\ket{\Psi_n}=\ket{\Psi_n}$. Therefore, equation (\ref{kentconsistency0}) for Kent's beables tells us that
$$\ev*{T^{\mu\nu}(y^a_1)}_{\tau_S}=\ev*{\hat{T}^{\mu\nu}(y^a_1)}{\Psi_n}.$$ 
where we have also used the fact that $\ip*{\Psi_n}{\Psi_n}=1.$

Now as we saw in section \ref{decotheory}, if we are interested only in the expectation values of observables for a system $\mathcal{S}$ contained within a universe $\mathcal{U}=\mathcal{S}+\mathcal{E}$, then the information needed to do this can be encapsulated in the reduced density matrix for $\mathcal{S}$. Thus, if the universe is described by a state 
$\ket{\Psi}=\sum_j c_j \ket{\psi_j}_\mathcal{S}\ket{E_j}$ with corresponding density matrix $\hat{\rho}=\dyad{\Psi}\in M(H_\mathcal{U})$, then the reduced density matrix $\hat{\rho}_\mathcal{S}\in M(H_\mathcal{S})$ is the operator that acts on the Hermitian operators of the state space $H_\mathcal{S}$ with the property that 
\begin{equation}\tag{\ref{reducedev} revisited}
\ev*{\hat{O}_\mathcal{U}}_\rho=\Tr_\mathcal{S}(\hat{\rho}_\mathcal{S}\hat{O}_\mathcal{S})
\end{equation}
where $\hat{O}_\mathcal{S}$ is an observable on $H_\mathcal{S}$,  and $\hat{O}_\mathcal{U}$ is the corresponding observable on $H_\mathcal{U}$. Furthermore, we also have
\begin{equation}\label{reduced2}
\hat{\rho}_\mathcal{S}=\sum_j \abs{c_j}^2\dyad{\psi_j}+\sum_{j\neq k} c_j\overline{c_k}\ip{E_k}{E_j}\dyad{\psi_j}{\psi_k}.\protect\footnotemark
\end{equation}
\footnotetext{cf. (\ref{reduced})}We can thus apply this to the situation at hand by taking $S_n$ to be our universe $\mathcal{U}$ and $y^a_1$ to be the system $\mathcal{S}$, and $S_n\setminus \{y^a_1\}$ to be the environment $\mathcal{E}$. If we assume that $\ip{0_2}{\psi_2^\text{sys}}= 0$, then by (\ref{reduced2}), the corresponding reduced density matrix $\hat{\rho}_{y^a_1}$ takes the form of an improper mixture
\begin{equation}\label{kentred}
\hat{\rho}_{y^a_1}= \abs{c_1}^2\dyad{\psi_1^\text{sys}}+\abs{c_2}^2\dyad{0_1}.
\end{equation}
Kent's beables at $y^a_1$ will thus take the form 
\begin{equation}\label{kentbe}
\begin{split}
\ev*{T^{\mu\nu}(y^a_1)}_{\tau_S}&=\Tr_{y^a_1}(\hat{\rho}_{y^a_1}\hat{T}^{\mu\nu}(y^a_1))\\
&=\abs{c_1}^2\ev*{\hat{T}^{\mu\nu}(y^a_1)}{\psi_1^\text{sys}}+\abs{c_2}^2\ev*{\hat{T}^{\mu\nu}(y^a_1)}{0_1}.
\end{split}
\end{equation}

Let us now consider Kent's beables at the spacetime location $y^b_1$ depicted in figure \ref{kentdecoh2}.
 
\begin{figure}[ht!]
\captionsetup{justification=justified}
\centering
\tikzmath{
\a=5.3;  
\psione=0;
\psitwo=1.5;
\h=1;
\labelx=(\psione+\psitwo)/2;
\labely=-1.5;
\phstartx=-1.7;
\phstarty=\h;
\tbeg=\phstarty;
\ca=\phstartx-\tbeg;
\ttwo=\psitwo-\ca;
\cb=\ttwo+\ca;
\xend=\ttwo-\a+\cb;
\tone=\psione-\ca;
\cc=\tone+\ca;
\xendz=\tone-\a+\cc;
\tthree=\cc+\tone-\psitwo;
\circsize=0.08;
\md = (\a+\h)/2;
\tlen=0.75;
\textscale = 0.7;
\picscale = 0.89;
\nudge=0.1;
\tnudge=(\ttwo-\tone)/2+0.8;
\ttesta=2*\tone-\ttwo-\tnudge;
\ttestb=2*\tone-\ttwo+\tnudge;
\ttestc=\ttwo-\tnudge;
\ttestd=\ttwo+\tnudge;
\sonea=\a+\psione-\ttesta;
\sadd=0.5;
\lrange = -(\psione-\a+\ttesta)+\sadd;
\rrange =\lrange; 
\timex=\rrange-1.5;
\e = 0.4;
\ttestx=3.0;
\at=\a-\ttestx;
\ct=\ttestx;
\lam = 0.87;
\e = 0.2;
\hae=(2*pow(\at,3)*\lam*(2+\lam)+\e*\e*(2*\e-sqrt(4*\e*\e+\at*\at*\lam*\lam))-8*\at*\e*(-2*\e+sqrt(4*\e*\e+\at*\at*\lam*\lam))-2*\at*\at*(2+\lam)*(-2*\e+sqrt(4*\e*\e+\at*\at*\lam*\lam)))/(4*\at*\lam*(2*\at+2*\e-sqrt(4*\e*\e+\at*\at*\lam*\lam)))-(\e*\e/4+\at*\at*(-1+\lam))/(\at*\lam);
\mmu=(\tone-\tbeg)/(\psione-\phstartx);
\nnu=(\psione*\tbeg-\phstartx*\tone)/(\psione-\phstartx);
\muf=(\a-\tone)/(\xendz-\psione);
\nuf=(\xendz*\tone-\psione*\a)/(\xendz-\psione);
} 
\tikzstyle{scorestars}=[star, star points=5, star point ratio=2.25, draw, inner sep=1pt]%
\tikzstyle{scoresquare}=[draw, rectangle, minimum size=1mm,inner sep=0pt,outer sep=0pt]%
\begin{tikzpicture}[scale=\picscale,
declare function={
	testxonep(\ps,\t)=\a+\ps-\t;
	testxonem(\ps,\t)=\ps-\a+\t; 
	xa(\m,\n)=(-\ct*\m+\e*\m+\m*\n-sqrt(\ct*\ct*\lam*\lam+\e*\e*\m*\m+2*\e*\lam*\lam*\n+\lam*\lam*\n*\n-2*\ct*\lam*\lam*(\e+\n)))/(\lam*\lam-\m*\m);
	xb(\m,\n)=(-\ct*\m+\e*\m+\m*\n+sqrt(\ct*\ct*\lam*\lam+\e*\e*\m*\m+2*\e*\lam*\lam*\n+\lam*\lam*\n*\n-2*\ct*\lam*\lam*(\e+\n)))/(\lam*\lam-\m*\m);
	bl(\x)=\ct+\at-\e/2-1/2*(sqrt(\lam*\lam*pow(\x+\hae+\at,2)+\e*\e)-\e+\lam*(\x+\hae+\at));
	br(\x)=\ct+\at-\e/2-1/2*(sqrt(\lam*\lam*pow(\x-\hae-\at,2)+\e*\e)-\e-\lam*(\x-\hae-\at));
	bc(\x)=\ct+sqrt(\lam*\lam*\x*\x+\e*\e)-\e;
},
 ] 
\definecolor{tempcolor}{RGB}{250,190,0}
\definecolor{darkgreen}{RGB}{40,190,40}

\draw[->,blue, thick] [domain=-\at/2:-\lrange, samples=150]   plot (\x, {bl(\x)})  ;
\draw[blue, thick] [domain=-\at/2:\at/2, samples=150] plot (\x, {bc(\x)})  node[right=20, above=10,black,scale=\textscale]{}  ;
\draw[->,blue, thick] [domain=\at/2:\rrange, samples=150]   plot (\x, {br(\x)})   ;

 \node[scale=\textscale]  at (2.7,4.6) {$S_n(y^b_1)$}; 
\draw[<->] (-\lrange, \h) node[left, scale=\textscale] {$S_0$} -- (\rrange, \h) node[right, scale=\textscale] {$S_0$};
\draw[<->] (-\lrange, \a) node[left, scale=\textscale] {$S$} -- (\rrange, \a) node[right, scale=\textscale] {$S$};
              
\draw[->, shorten <= 5pt,  shorten >= 1pt] (\psione,\h) node[below, scale=\textscale]{$\psi_1^{\text{sys}}$} node[above left, scale=\textscale]{$z_1$}-- (\psione,\a) ;
\draw[->,  shorten <= 5pt,  shorten >= 1pt] (\psitwo,\h) node[below, scale=\textscale]{$\psi_2^{\text{sys}}$} node[above right, scale=\textscale]{$z_2$}-- (\psitwo,\a);

\draw[dashed, tempcolor,  thick](\phstartx,\tbeg) node[below left=-2,scale=\textscale]{}--(\psione,\tone) node[above, pos=0.3, rotate=45,scale=0.7,black] {} node[below, pos=0.3, rotate=45,scale=0.7,black] {};
\draw[dashed, tempcolor,  thick](\psione,\tone) node[below left=-2,scale=\textscale]{}--(\psitwo,\ttwo );
\draw[dashed, tempcolor,  thick](\psitwo,\ttwo)--(\xend,\a); 
\draw[dashed, tempcolor, thick](\psione,\tone)--(\xendz,\a);





\draw[->] (\timex,\md-\tlen/2) --  (\timex,\md+\tlen/2) node[midway,right, scale=\textscale]{time}; 
 
\draw[dotted](\psione,\ttestx)--({testxonep(\psione,\ttestx)},\a);
\draw[dotted](\psione,\ttestx)--({testxonem(\psione,\ttestx)},\a);
%\draw [black,fill](\psione,\ttestx) circle [radius=\circsize] node [black,below=6,left,scale=\textscale] {$y^b_1$}; 
\draw (\psione,\ttestx) node[ scoresquare, fill=gray]  {} node [black,below=6,right,scale=\textscale] {$y^b_1$};
\draw (\psitwo, {bc(\psitwo)}) node[ scoresquare, fill=gray]  {} node [black,below=6,right,scale=\textscale] {$y^b_2$};
\draw ({xa(\mmu,\nnu)}, {xa(\mmu,\nnu)*\mmu+\nnu}) node[ scoresquare, fill=gray]  {} node [black,below=3,scale=\textscale] {$y^b_4$};
\draw ({xb(\muf,\nuf)}, {xb(\muf,\nuf)*\muf+\nuf}) node[ scoresquare, fill=gray]  {} node [black,below=3,scale=\textscale] {$y^b_3$};

\draw[magenta,->,ultra thick] ({testxonem(\psione,\ttestx)},\a)--(-\lrange,\a);
\draw[magenta,->,ultra thick] ({testxonep(\psione,\ttestx)},\a)--(\rrange,\a);
%\draw [black,fill] (\xendz,\a) circle [radius=\circsize] node [black,above,scale=\textscale] {$\gamma_1$}; 
\end{tikzpicture}% pic 1

\vspace*{2px}
\caption{Depiction of a superposition of two local states at $z_1$ and $z_2$ with $S_n(y^b_1)$ being after the photon has interacted without the photon intersecting $S_n(y^b_1)\cap S$. The gray squares indicate cells in $S^1(y^b_1)$ whose states are among the summands in (\ref{Sistate}).}
\label{kentdecoh2}
\end{figure}
The state of $S_n(y^b_1)$ will then be
 \begin{equation*}
 \ket{\Psi_n}=\big(c_1\ket{\psi_1^\text{sys}}\ket{0_2}\ket{\gamma_3}\ket{0_4}+c_2\ket{0_1}\ket{\psi_2^\text{sys}}\ket{0_3}\ket{\gamma_4}\big)\Xi
 \end{equation*}
 where the notation is analogous to that in the previous example. Since no photon detections are registered on $S_n(y^b_1)\cap S$, we again have $\pi_n\ket{\Psi_n}=\ket{\Psi_n}$ so that the reduced density matrix $\hat{\rho}_{y_1^b}$ will again be given by  (\ref{kentred}) with $y^a_1$ replaced by $y^b_1$, and likewise,  Kent's beables $\ev*{T^{\mu\nu}(y^b_1)}_{\tau_S}$ will be given by (\ref{kentbe}).

For the next example, we consider the case in figure \ref{kentdecoh3}.


\begin{figure}[ht!]
\captionsetup{justification=justified}
\centering
\tikzmath{
\a=5.3;  
\psione=0;
\psitwo=1.5;
\h=1;
\labelx=(\psione+\psitwo)/2;
\labely=-1.5;
\phstartx=-1.7;
\phstarty=\h;
\tbeg=\phstarty;
\ca=\phstartx-\tbeg;
\ttwo=\psitwo-\ca;
\cb=\ttwo+\ca;
\xend=\ttwo-\a+\cb;
\tone=\psione-\ca;
\cc=\tone+\ca;
\xendz=\tone-\a+\cc;
\tthree=\cc+\tone-\psitwo;
\circsize=0.08;
\md = (\a+\h)/2;
\tlen=0.75;
\textscale = 0.7;
\picscale = 0.89;
\nudge=0.1;
\tnudge=(\ttwo-\tone)/2+0.8;
\ttesta=2*\tone-\ttwo-\tnudge;
\ttestb=2*\tone-\ttwo+\tnudge;
\ttestc=\ttwo-\tnudge;
\ttestd=\ttwo+\tnudge;
\sonea=\a+\psione-\ttesta;
\sadd=0.5;
\lrange = -(\psione-\a+\ttesta)+\sadd;
\rrange =\lrange; 
\timex=\rrange-1.5;
\e = 0.4;
\ttestx=4;
\at=\a-\ttestx;
\ct=\ttestx;
\lam = 0.87;
\e = 0.2;
\hae=(2*pow(\at,3)*\lam*(2+\lam)+\e*\e*(2*\e-sqrt(4*\e*\e+\at*\at*\lam*\lam))-8*\at*\e*(-2*\e+sqrt(4*\e*\e+\at*\at*\lam*\lam))-2*\at*\at*(2+\lam)*(-2*\e+sqrt(4*\e*\e+\at*\at*\lam*\lam)))/(4*\at*\lam*(2*\at+2*\e-sqrt(4*\e*\e+\at*\at*\lam*\lam)))-(\e*\e/4+\at*\at*(-1+\lam))/(\at*\lam);
\mmu=(\tone-\tbeg)/(\psione-\phstartx);
\nnu=(\psione*\tbeg-\phstartx*\tone)/(\psione-\phstartx);
\muf=(\a-\ttwo)/(\xend-\psitwo);
\nuf=(\xend*\ttwo-\psitwo*\a)/(\xend-\psitwo);
} 
\tikzstyle{scorestars}=[star, star points=5, star point ratio=2.25, draw, inner sep=1pt]%
\tikzstyle{scoresquare}=[draw, rectangle, minimum size=1mm,inner sep=0pt,outer sep=0pt]%
\begin{tikzpicture}[scale=\picscale,
declare function={
	testxonep(\ps,\t)=\a+\ps-\t;
	testxonem(\ps,\t)=\ps-\a+\t; 
	xa(\m,\n)=(-\ct*\m+\e*\m+\m*\n-sqrt(\ct*\ct*\lam*\lam+\e*\e*\m*\m+2*\e*\lam*\lam*\n+\lam*\lam*\n*\n-2*\ct*\lam*\lam*(\e+\n)))/(\lam*\lam-\m*\m);
	xb(\m,\n)=(-\ct*\m+\e*\m+\m*\n+sqrt(\ct*\ct*\lam*\lam+\e*\e*\m*\m+2*\e*\lam*\lam*\n+\lam*\lam*\n*\n-2*\ct*\lam*\lam*(\e+\n)))/(\lam*\lam-\m*\m);
	bl(\x)=\ct+\at-\e/2-1/2*(sqrt(\lam*\lam*pow(\x+\hae+\at,2)+\e*\e)-\e+\lam*(\x+\hae+\at));
	br(\x)=\ct+\at-\e/2-1/2*(sqrt(\lam*\lam*pow(\x-\hae-\at,2)+\e*\e)-\e-\lam*(\x-\hae-\at));
	bc(\x)=\ct+sqrt(\lam*\lam*\x*\x+\e*\e)-\e;
},
 ] 
\definecolor{tempcolor}{RGB}{250,190,0}
\definecolor{darkgreen}{RGB}{40,190,40}

\draw[->,blue, thick] [domain=-\at/2:-\lrange, samples=150]   plot (\x, {bl(\x)})  ;
\draw[blue, thick] [domain=-\at/2:\at/2, samples=150] plot (\x, {bc(\x)})  node[right=20, above=10,black,scale=\textscale]{}  ;
\draw[->,blue, thick] [domain=\at/2:\rrange, samples=150]   plot (\x, {br(\x)})   ;

 \node[scale=\textscale]  at (1,4.1) {$S_n(y^c_1)$}; 
\draw[<->] (-\lrange, \h) node[left, scale=\textscale] {$S_0$} -- (\rrange, \h) node[right, scale=\textscale] {$S_0$};
\draw[<->] (-\lrange, \a) node[left, scale=\textscale] {$S$} -- (\rrange, \a) node[right, scale=\textscale] {$S$};
              
\draw[->, shorten <= 5pt,  shorten >= 1pt] (\psione,\h) node[below, scale=\textscale]{$\psi_1^{\text{sys}}$} node[above left, scale=\textscale]{$z_1$}-- (\psione,\a) ;
\draw[->,  shorten <= 5pt,  shorten >= 1pt] (\psitwo,\h) node[below, scale=\textscale]{$\psi_2^{\text{sys}}$} node[above right, scale=\textscale]{$z_2$}-- (\psitwo,\a);

\draw[dashed, tempcolor,  thick](\phstartx,\tbeg) node[below left=-2,scale=\textscale]{}--(\psione,\tone) node[above, pos=0.3, rotate=45,scale=0.7,black] {} node[below, pos=0.3, rotate=45,scale=0.7,black] {};
\draw[dashed, tempcolor,  thick](\psione,\tone) node[below left=-2,scale=\textscale]{}--(\psitwo,\ttwo );
\draw[dashed, tempcolor,  thick](\psitwo,\ttwo)--(\xend,\a); 
\draw[dashed, tempcolor,  thick](\psione,\tone)--(\xendz,\a);

\draw[magenta,->,ultra thick] ({testxonem(\psione,\ttestx)},\a)--(-\lrange,\a);
\draw[magenta,->,ultra thick] ({testxonep(\psione,\ttestx)},\a)--(\rrange,\a);



\draw[->] (\timex,\md-\tlen/2) --  (\timex,\md+\tlen/2) node[midway,right, scale=\textscale]{time}; 
 
\draw[dotted](\psione,\ttestx)--({testxonep(\psione,\ttestx)},\a);
\draw[dotted](\psione,\ttestx)--({testxonem(\psione,\ttestx)},\a);
%\draw [black,fill](\psione,\ttestx) circle [radius=\circsize] node [black,below=6,left,scale=\textscale] {$y^c_1$}; 
\draw (\psione,\ttestx) node[ scoresquare, fill=gray]  {} node [black,below=6,right,scale=\textscale] {$y^c_1$};
\draw (\psitwo, {bc(\psitwo)}) node[ scoresquare, fill=gray]  {} node [black,below=6,right,scale=\textscale] {$y^c_2$};
\draw ({xb(\muf,\nuf)}, {xb(\muf,\nuf)*\muf+\nuf}) node[ scoresquare, fill=gray]  {} node [black,right=7, below=-4,scale=\textscale] {$y^c_4$};
\draw (\xendz,\a) node[ scoresquare, fill=gray]  {} node [black,below=3,scale=\textscale] {$y^c_3$};


%\draw [black,fill] (\xendz,\a) circle [radius=\circsize] node [black,above,scale=\textscale] {$\gamma_1$}; 
\end{tikzpicture}% pic 1

\vspace*{2px}
\caption{Depiction of a superposition of two local states at $z_1$ and $z_2$ with $y^c_1$ sufficiently late that the photon intersects $S_n(y^c_1)\cap S$. The gray squares indicate cells in $S^1(y^c_1)$ whose states are among the summands in (\ref{Sistate})}
\label{kentdecoh3}
\end{figure}

In this case, the state of $S_n(y^c_1)$ will be
 \begin{equation*}
 \ket{\Psi_n}=\big(c_1\ket{\psi_1^\text{sys}}\ket{0_2}\ket{\gamma_3}\ket{0_4}+c_2\ket{0_1}\ket{\psi_2^\text{sys}}\ket{0_3}\ket{\gamma_4}\big)\Xi
 \end{equation*}
 but this time we have to consider the fact that the photon intersects $S_n(y^c_1)\cap S$. There are two possible (notional) measurements outcomes that can occur on $S_n(y^c_1)\cap S$: either $T_S=\tau_{S,1}$ where $\tau_{S,1}(y^c_3)\neq 0$ or $T_S=\tau_{S,2}$ where $\tau_{S,2}(y^c_3)=0.$ 
 
 The case  $T_S=\tau_{S,1}$ indicates that there is a photon detection at $y^c_3$ so that the local state at the $y^c_3$-cell is $\ket{\gamma_3}$. Therefore, if we write $\pi_{n,1}$ for the operator $\pi_n$, we have 
 $$\pi_{n,1}\ket{\Psi_n}=c_1\ket{\psi_1^\text{sys}}\ket{0_2}\ket{\gamma_3}\ket{0_4}\Xi.$$
 Therefore, 
 $\ev*{\pi_{n,1}\hat{T}^{\mu\nu}(y^c_1)}{\Psi_n}=\abs{c_1}^2\ev*{\hat{T}^{\mu\nu}(y^c_1)}{\psi_1^\text{sys}}$ and  $\ev*{\pi_{n,1}}{\Psi_n}=\abs{c_1}^2$. Hence, by (\ref{kentconsistency0}), Kent's beables at $y^c_1$ will be 
 $$\ev*{T^{\mu\nu}(y^c_1)}_{\tau_{S,1}}=\ev*{\hat{T}^{\mu\nu}(y^c_1)}{\psi_1^\text{sys}}.$$ 
 From this, it follows that the reduced density matrix at $y^c_1$ will take the form of a pure state:
 \begin{equation}
\hat{\rho}_{y^c_1}= \dyad{\psi_1^\text{sys}}.
\end{equation} 
 On the other hand, for the case when  $T_S=\tau_{S,2}$, this indicates that there is no photon detection at $y^c_3$, so that the local state at the $y^c_3$-cell will be $\ket{0_3}$. So if we now  write $\pi_{n,2}$ for the operator $\pi_n$, we have 
 $$\pi_{n,2}\ket{\Psi_n}=c_2\ket{0_1}\ket{\psi_2^\text{sys}}\ket{0_3}\ket{\gamma_4}\Xi.$$
 Therefore, 
 $\ev*{\pi_{n,2}\hat{T}^{\mu\nu}(y^c_1)}{\Psi_n}=\abs{c_2}^2\ev*{\hat{T}^{\mu\nu}(y^c_1)}{0_1}$ and  $\ev*{\pi_{n,2}}{\Psi_n}=\abs{c_2}^2$,  
  and so by (\ref{kentconsistency0}), Kent's beables at $y^c_1$ will be 
 $$\ev*{T^{\mu\nu}(y^c_1)}_{\tau_{S,2}}=\ev*{\hat{T}^{\mu\nu}(y^c_1)}{0_1}.$$
 In this case, the reduced density matrix at $y^c_1$  will be
  \begin{equation}
\hat{\rho}_{y^c_1}= \dyad{0_1},
\end{equation} 
which is again a pure state.

In these examples we have therefore seen how the additional information concerning photon detection on $S_n(y_1)\cap S$ is able to determine whether the reduced density matrix at $y_1$ is a pure state or an improper mixture. Hence, Kent's interpretation offers an answer to d'Espagnat's problem of outcomes. As mentioned in section \ref{probOutcomes}, d'Espagnat noticed that with decoherence theory alone, we are not entitled to give an ignorance interpretation to the reduced density matrix for a system that is an improper mixture, and thus we are not able to conclude from the reduced density matrix that an outcome has occurred. However, if the reduced density matrix of a system goes from being an improper mixture to a pure state of the form $\dyad{\psi}$ as it does when Kent's additional information is taken into account, then we can say that an outcome has occurred, namely the outcome of the system being in the state $\ket{\psi}.$  




\subsection{Outcome Independence and Parameter Independence in Kent's interpretation}
Let us now consider Kent's interpretation in the light of Shimony's notions of Outcome Independence (OI) and Parameter Independence (PI) as defined in section \ref{OIVI}. If Kent's interpretation is to be consistent with special relativity, then it mustn't allow for the possible for faster than light signalling, and hence it must satisfy parameter independence. 

Now Butterfield\footnote{See \cite[30-32]{Butterfield}} tries to answer the question of whether OI holds in Kent's interpretation by considering an example that builds on Kent's toy model. Butterfield's example is designed to capture the salient features of a Bell experiment where two spatially separated observers always observe opposite outcomes of some measurement. He thus considers a universe in one spatial dimensional. In this universe, there are two entangled systems, a left-system and a right-system as depicted in figure \ref{ButterfieldOI}.

\begin{figure}[ht!]
	\captionsetup{justification=justified}
	\centering
	\tikzmath{
	\a=5.3;  
	\psione=-1;
	\psitwo=-0.5;
	\psioneq=2;
	\psitwoq=2.5;
	\psioner=0;
	\psitwor=1;
	\e = 0.1;
	\h=-0.8;
	\phstartx=-3.9;
	\phstarty=-.8;
	\tbeg=\phstarty;
	\ca=\phstartx-\tbeg;
	\ttwo=\psitwo-\ca;
	\cb=\ttwo+\ca;
	\xend=\ttwo-\a+\cb;
	\tone=\psione-\ca;
	\cc=\tone+\ca;
	\xendz=\tone-\a+\cc;
	\tthree=\cc+\tone-\psitwo;
	\phstartxq=\psitwoq+2.9;
	\phstartyq=-.8;
	\tbegq=\phstartyq;
	\ttwoq=\tbegq-(\psitwoq-\phstartxq);
	\xendq=-\ttwoq+\a+\psitwoq;
	\toneq=\tbegq-(\psioneq-\phstartxq);
	\xendzq=-\toneq+\a+\psioneq;
	\circsize=0.05;
	\md = (\a+\h)/2;
	\tlen=0.75;
	\textscale = 0.8;
	\picscale = 0.95;
	\nudge=0.1;
	\tnudge=(\ttwo-\tone)/2;
	\ttesta=2*\tone-\ttwo-\tnudge;
	\ttestb=2*\tone-\ttwo+\tnudge;
	\ttestc=\ttwo-\tnudge;
	\ttestd=\ttwo+\tnudge;
	\sonea=\a+\psione-\ttesta;
	\sadd=0.5;
	\lrange = -(\psioner-\a+\ttesta)+\sadd;
	\rrange =\a+\psitwor-\ttesta+\sadd+0.5; 
	\timex=\rrange-0.7;
	} 
	\begin{tikzpicture}[scale=1.2,
	declare function={
		testxonep(\ps,\t)=\a+\ps-\t;
		testxonem(\ps,\t)=\ps-\a+\t; 
	},
	 ] 
	
	 \definecolor{tempcolor}{RGB}{250,190,0}
	 \definecolor{darkgreen}{RGB}{40,190,40}
	 \draw[<->] (-\lrange, \h) node[left, scale=\textscale] {$S_0$} -- (\rrange, \h) node[right, scale=\textscale] {$S_0$};
	 \draw[<->] (-\lrange, \a) node[left, scale=\textscale] {$S$} -- (\rrange, \a) node[right, scale=\textscale] {$S$};
	 
				   
	 \draw[->, shorten <= 5pt,  shorten >= 1pt] (\psione,\h) node[below, scale=\textscale]{$\psi_1^{\text{sys}}$} node[above left, scale=\textscale]{$Z=z_1$}-- (\psione,\a);
	 \draw[->,  shorten <= 5pt,  shorten >= 1pt] (\psitwo,\h) node[below, scale=\textscale]{$\psi_2^{\text{sys}}$} node[above right, scale=\textscale]{$Z=z_2$}-- (\psitwo,\a);
	 
	 \draw[->, shorten <= 5pt,  shorten >= 1pt] (\psioneq,\h) node[below, scale=\textscale]{$\psi_3^{\text{sys}}$} node[above left, scale=\textscale]{$Z=z_3$}-- (\psioneq,\a);
	 \draw[->,  shorten <= 5pt,  shorten >= 1pt] (\psitwoq,\h) node[below, scale=\textscale]{$\psi_4^{\text{sys}}$} node[above right, scale=\textscale]{$Z=z_4$}-- (\psitwoq,\a);
	 
	 %\draw[dashed, tempcolor, ultra thick](\phstartx,\tbeg) node[below left=-2,scale=\textscale]{}--(\psitwo,\ttwo );
	 \draw[dashed, tempcolor, ultra thick](\phstartx,\tbeg) node[below left=-2,scale=\textscale]{}--(\psione,\tone );
	 \draw[dashed, gray, ultra thick](\psitwo,\ttwo)--(\xend,\a);
	 \draw[dashed, gray, ultra thick](\psione,\tone)--(\psitwo,\ttwo) ;
	 \draw[dashed, tempcolor, ultra thick](\psione,\tone)--(\xendz,\a) ;
	 
	 \draw [red,fill] (\xendz,\a) circle [radius=\circsize] node [black,above,scale=\textscale] {$\gamma_1$}; 
	 \draw [black,fill] (\xend,\a) circle [radius=\circsize] node [black,above,scale=\textscale] {$\gamma_2$}; 
	 
	 \draw[dashed, tempcolor, ultra thick](\phstartxq,\tbegq) node[below left=-2,scale=\textscale]{}--(\psitwoq,\ttwoq );
	 \draw[dashed, tempcolor, ultra thick](\psitwoq,\ttwoq)--(\xendq,\a)  ;
	 \draw[dashed, gray, ultra thick](\psioneq,\toneq)--(\psitwoq,\ttwoq) ;
	 \draw[dashed, gray, ultra thick](\psioneq,\toneq)--(\xendzq,\a) ;
	 
	 \draw [black,fill] (\xendzq,\a) circle [radius=\circsize] node [black,above,scale=\textscale] {$\gamma_3$}; 
	 \draw [red,fill] (\xendq,\a) circle [radius=\circsize] node [black,above,scale=\textscale] {$\gamma_4$}; 
	 %\draw[dashed, darkgreen, ultra thick](\psione,\tone)--(\psitwo,\tthree);
	 %\draw [black,fill] (\psitwo,\tthree) circle [radius=\circsize] node [black,below=4,right,scale=\textscale] {$t=2t_1-t_2$}; 
	 
	 
	 \draw [red,fill] (\psione,\tone) circle [radius=\circsize]; 
	 \draw [black,fill](\psitwo,\ttwo)circle [radius=\circsize]; 
	 
	 \draw [black,fill] (\psioneq,\toneq) circle [radius=\circsize]; 
	 \draw [red,fill](\psitwoq,\ttwoq)circle [radius=\circsize]; 
	 
	 %\draw [decorate, decoration = {calligraphic brace}] (\psitwo+\nudge,\ttwo) --  (\psitwo+\nudge,\tone+\nudge/4) node[midway,right, scale=\textscale]{$t_2-t_1$}; 
	 %\draw [decorate, decoration = {calligraphic brace}] (\psitwo+\nudge,\tone-\nudge/4) --  (\psitwo+\nudge,2*\tone-\ttwo) node[midway,right, scale=\textscale]{$t_2-t_1$}; 

	\draw[->] (\timex,\md-\tlen/2) --  (\timex,\md+\tlen/2) node[midway,right, scale=\textscale]{time}; 
	 
	%\draw[dotted](\psione,\ttesta)--({testxonep(\psione,\ttesta)},\a);
	%\draw[dotted](\psione,\ttesta)--({testxonem(\psione,\ttesta)},\a);
	%\draw [black,fill](\psione,\ttesta) circle [radius=\circsize] node [black,below=5,right,scale=\textscale] {$y_a$}; 
	
	%\draw[magenta,->,ultra thick] ({testxonem(\psione,\ttesta)},\a)--(-\lrange,\a);
	%\draw[magenta,->,ultra thick] ({testxonep(\psione,\ttesta)},\a)--(\rrange,\a);
	
	\end{tikzpicture}% pic 1
	
	\vspace*{2px}
	\caption{Butterfield's analysis of Outcome Independent}
	\label{ButterfieldOI}
	\end{figure}

Two locations $z_1$ and $z_2$ with $z_2>z_1$ belong to the left-system, and there are two possible outcomes for a measurement on the left-system: either all the mass/energy of the left-system is localized at $z_1$ or all the mass/energy of the left-system  is localized at $z_2$. These two possibilities are analogous to a spin up or a spin down measurement outcome in a Stern-Gerlach statement. Likewise, two locations $z_3$ and $z_4$ with $z_3<z_4$ and $z_3/gg z_2$ belong to the right-system, and again, there are two possible measurement outcomes: either all the mass/energy of the right-system is localized at $z_3$ or all the mass/energy of the right-system  is localized at $z_4$.

The initial joint state of the two systems is 
$a \psi_1\psi_4 +b \psi_2\psi_3.$
This means that the left-system will be found to be localized at $z_1$ with probability $\abs{a}^2$ and at $z_2$ with probability $\abs{b}^2$, and if the left-system is locaized at $z_1$, the  right system must be localized at $z_4$, whereas if the left-system is localized at $z_2$, then the right system must be localized at $z_3$.  

Now Butterfield supposes that there are two photons, one coming in from the left that interacts with the left system, and one coming in from the right that interacts with the right system. As in Kent's toy model, there is a late time hypersurface $S$, on which the photons are ``measured''. Since the joint state of the two systems  is in superposition, there will be two possible measurement outcomes for the two photons that arrive at $S$. Either the left-photon is measured at $\gamma_1$ and the right-photon is measured at $\gamma_4$, or the left-photon is measured at $\gamma_2$ and the right photon is measured at $\gamma_3$. Thus, if we suppose that the (notional) measurement for $T_S(x)$ yields an energy distribution $\tau_S(x)$ that is nonzero at $\gamma_1$ and $\gamma_4$, but is zero at $\gamma_2$ and $\gamma_3$, then we can say that the outcome of the measurement on the two systems is that the left system is localized at $x_1$ and the right system is localized at $x_4$. Moreover, the probability of this outcome is $1$ given that (notional) measurement of $T_S(x)$ on $S$ is $\tau_S(x)$. In other words, it is deterministic. But as we saw on page \pageref{OIdet}, if a model is deterministic, then OI must hold. This is the conclusion that Butterfield draws. 

Now if Kent's interpretation is to be consistent with special relativity, OI being satisfied might initially seem concerning, for we saw on pages \pageref{OI}--\pageref{OIPIproofend} that OI implies PI, and PI is not consistent with special relativity. However, there is one salient feature of a Bell experiment that is not captured in Butterfield's scenario, namely, in a Bell experiment, one can perform different measurements.  PI only makes sense when there are parameters that can be changed. Furthermore, in the proof that OI implies PI,\footnote{It is also the case that in the proof (on pages \pageref{bellinequality2} to \pageref{PIdeterminism}) that determinism implies PI, it is assumed that the choice of parameter is not determined by the hidden variables of $\lambda$} it is assumed that the choice of parameter is not determined by the hidden variables of $\lambda$. If the choice of parameters did depend on $\lambda$, then for $\hat{a}\neq\hat{b}$, at least one of the probabilities $P_{\lambda,\bm{\hat{a}},\bm{\hat{c}}}(\uvbp{a};\uvbp{c}),$ $P_{\lambda,\bm{\hat{c}},\bm{\hat{b}}}(\uvbp{c};\uvbp{b})$ or $P_{\lambda,\bm{\hat{a}},\bm{\hat{b}}}(\uvbp{a};\uvbp{b})$ would not be well-defined.\footnote{For example, if we thought of $P_{\lambda,\bm{\hat{a}},\bm{\hat{b}}}(X;Y)$ as a conditional probability $P(X;Y|\lambda,\bm{\hat{a}},\bm{\hat{b}})$ and the probability $P(\lambda,\bm{\hat{a}},\bm{\hat{b}})=0$, then according to the definition of conditional probability,  $P(X;Y|\lambda,\bm{\hat{a}},\bm{\hat{b}})=\frac{0}{0}.$} 

Now in Kent's interpretation, the information in $\tau_S(x)$ clearly would determine which parameter is chosen in a Bell experiment, for $\tau_S(x)$ would determine where a silver atom coming out of Stern-Gerlach apparatus would be detected on a detection screen (as depicted in figure \ref{rotate}), and from the position of this detection, one could determine the orientation of the magnetic field used in the Stern-Gerlach experiment. So in this regard, Kent's interpretation is radically different from the pilot wave interpretation where the hidden variables are the positions and momenta of the particles and are independent of the choice of measurement.

If, however, we are more discerning in what we count as being the relevant hidden variables in Kent's interpretation, then we can make the hidden variables independent of the choice of measurement. Being discerning in this regard does not seem at all unreasonable. After all, in the pilot wave interpretation, there are positions and momenta for all particles in the universe, but if we are considering the measurement of a particle, we only count the position  and the  momentum of this particle as its relevant hidden  variables. If we stipulated that all the positions and the momenta of all the particles describing measuring apparatus were to count as being hidden variables of the particle, then we would have the same problem as in Kent's interpretation of having the choice of measurement depending on the hidden variables of the particle. But just as it would seem unreasonable  in the pilot wave interpretation to count the positions and momenta of the apparatus particles as being hidden variables of the particle we wish to measure, it seems unreasonable in Kent's interpretation to assume that all the information in $\tau_S$ should count as being hidden variables of the particle we wish to measure.


In his 2016 paper, Leegwater gives us some precise conditions for some additional information beyond the quantum state to count as hidden variables.\footnote{See \cite{LeegwaterGijs2016Aitf}.} With this definition of hidden variables (to be specified shortly), Leegwater proves a version of the Colbeck-Renner theorem. Leegwater's version takes the following form: suppose we have an observable $\hat{O}_{\mathcal{S}}$  with eigenvalues $o_i$ and eigenstates $\ket{\psi_i}$ corresponding to some measurement $O_{\mathcal{S}}$ that can be performed on a system, and let $\ket{\psi}$ be a quantum state of the system $\mathcal{S}$ which satisfies the usual Born rule: the probability that the measurement $O_{\mathcal{S}}$ on the system $\mathcal{S}$ has outcome $o_i$ is $P^{\ket{\psi}_\mathcal{A}}(O_{\mathcal{S}}=o_i)=\abs{\ip{\psi}{\psi_i}}^2$. Now suppose that this standard quantum theory is augmented with hidden variables $\lambda\in\Lambda$ with each $\lambda$ being realized with probability $p_\lambda$ so that $\sum_{\lambda\in \Lambda}=1$. Each $\lambda$ determines a new probability $P_{\lambda}^{\ket{\psi}_\mathcal{A}}(O_{\mathcal{S}}=o_i)$ that the measurement $O_{\mathcal{S}}$ on the system $\mathcal{S}$ has outcome $o_i$, but in order that this new probability does not empirically contradict standard quantum theory, we demand that $\sum_{\lambda\in\Lambda}P_{\lambda}^{\ket{\psi}}(O_{\mathcal{S}}=o_i)=P^{\ket{\psi}_\mathcal{A}}(O_{\mathcal{S}}=o_i) $. We also demand that PI holds as defined on page \pageref{PIdef}.  Then the Colbeck-Renner theorem states that $P_{\lambda}^{\ket{\psi}_\mathcal{A}}(O_{\mathcal{S}}=o_i)=P^{\ket{\psi}_\mathcal{A}}(o_i).$ In other words, in a hidden variables quantum theory that is empirically adequate (i.e. consistent with current observations) and which satisfies PI, the predictions this theory yields are identical to standard quantum theory, and so the hidden variables are redundant. 

According to Leegwater's definition, (which I paraphrase here) information denoted by the symbol $\lambda$ is a \textbf{hidden variable} of a system $\mathcal{A}$ when the following conditions are fullfilled:  
\begin{itemize}
	\item $\mathcal{A}$ has an associated quantum state $\ket{\psi}_\mathcal{A}$ which encapsulates everything that is known about the system in terms of standard quantum mechanics (i.e. $\ket{\psi}_\mathcal{A}$ can be successfully used to calculate probabilites of measurement outcomes on $\mathcal{A}$ via the Born rule.)
	\item $\lambda$ is a variable that can range over a set of possible values belonging to a set $\Lambda_\mathcal{A}$ associated with the system $A$,
	\item the quantum state $\ket{\phi}_\mathcal{A}$ does not depend on $\lambda$,
	\item although $\lambda$ can encapsulate a lot of information about $\mathcal{A}$, it is assumed that only one $\lambda\in\Lambda_\mathcal{A}$ is actually realized, and it is realized with a probability,
	\item for any measurement $O_\mathcal{A}$ that can be performed on $\mathcal{A}$,  there is a probability distribution $P_{\lambda}^{\ket{\psi}_\mathcal{A}}(O_{\mathcal{A}}=o_i)$ that gives the probability of the measurement outcome $O_{\mathcal{A}}=o_i$  given that the system $\mathcal{A}$ is in quantum state $\ket{\psi}_\mathcal{A}$ and has hidden variable $\mathcal{A}$,
	\item the probability distribution $p_\lambda$ for the hidden variables $\lambda\in\Lambda_\mathcal{A}$ is independent of any measurement $O_\mathcal{A}$ that can be made on $\mathcal{A}$,
	\item $\lambda$ does not depend on any other system $\mathcal{B}$ that is disjoint from $\mathcal{A}$, 
	\item for any other system $\mathcal{B}$ that is entangled with $\mathcal{A}$, then for any measurement $O_\mathcal{A}$ on $\mathcal{A}$ and $O_\mathcal{B}$ on $\mathcal{B}$, there is a probability $P_\lambda^{\ket{\phi}_{\mathcal{A}+\mathcal{B}}}(O_\mathcal{A}=o_\mathcal{A},O_\mathcal{B}=o_\mathcal{B})$ for the joint measurement of $O_\mathcal{A}$ and $O_\mathcal{B}$ on $\mathcal{A}+\mathcal{B}$ that depends on $\lambda$  despite $\lambda$ only referring to the system $\mathcal{A}$,
	\item for any other system $\mathcal{B}$ that is not entangled with $\mathcal{A}$, that is, when the state of the composite system $\mathcal{A}+\mathcal{B}$ takes the form $\ket{\psi}_\mathcal{A}\ket{\zeta}_\mathcal{B})$, then the probability $P_{\lambda}^{\ket{\psi}_\mathcal{A}}(O_{\mathcal{A}}=o_i)$ for outcome of a measurement $O_{\mathcal{A}}$ on $\mathcal{A}$ is entirely independent of the quantum state $\ket{\zeta}_\mathcal{B}$ that describes $\mathcal{B}$.
	

\end{itemize}

The Colbeck-Renner theorem, however, does not imply there is no non-trivial way of augmenting standard quantum theory in a PI and an empirically adequate way -- it only implies there is no such way of augmenting standard quantum theory with hidden variables as defined by Leegwater. This implies that we should expect none of the information $\tau_S(x)$ of Kent's interpretation to come under Leegwater's definition of hidden variables if Kent's interpretation is to be an empirically adequate theory in which PI holds. So let us consider whether this is the case.

To this end, we first suppose we have a single piece of experimental apparatus $\mathcal{A}$ and a particle $\mathcal{Q}$ that we are interested in measuring. Since the apparatus has been around for a long time, it has already interacted with many photons during its existence. Likewise, the particle has interacted with many photons. So let us suppose that the hypersurface $S$ has energy density $\tau_S(x)$ indicating that some photons have been ``measured'' on $S$ to be in a state $\ket*{\gamma_i^{(\mathcal{A})}}$ which is correlated with the apparatus being in a state $\ket{a_i}$ shortly before time $t_i$ and in the vicinity of spatial location $z_1$.  Similarly, we suppose that $\tau_S(x)$ also indicates that some photons have been ``measured'' on $S$ to be in a state $\ket*{\gamma_i^{(\mathcal{Q})}}$ which is correlated with the particle being in a state $\ket{q_i}$ also shortly before time $t_i$ and in the vicinity of spatial location $z_1$. 

Now let us choose a sequence of hypersurfaces $S_{n,i}$ which go through the spacetime location $y_i=(t_i, z_1)$ such that $\lim_{n\rightarrow\infty} S_n\cap S=S^1(y_i),$ where as usual,  $S^1(y_i)$ consists of all the spacetime locations of $S$ outside the light cone of $y_i$. Let us assume that $n$ is sufficiently large so that the photons described by $\ket*{\gamma_i^{(\mathcal{Q})}}$ and $\ket*{\gamma_i^{(\mathcal{A})}}$ belong to $S_{n,i}$. Typically, the state of the hypersurface $S_{n,i}$ will also include photon correlations with $\mathcal{Q}$ and $\mathcal{A}$ corresponding to other possible ``measurements'' of $T_S(x)$ besides $\tau_S(x)$, so in general, we would expect the state of $S_{n,i}$ to be of the form
$$ \ket{\Psi_{n,i}}=\sum_{j,k}c_{j,k}\ket{q_j}\ket{a_k}\ket*{\gamma_j^{(\mathcal{Q})}}\ket*{\gamma_k^{(\mathcal{A})}},$$
where $\{\ket{q_j}\}$ 
is an orthonormal basis of states (containing $\ket{q_i}$) for the particle $\mathcal{Q}$, $\{\ket{a_k}\}$ 
is an orthonormal basis of states (containing $\ket{a_i}$) describing the apparatus $\mathcal{A}$, $\{\ket*{\gamma_j^{(\mathcal{Q})}}\}$ 
are normalized states of photons in $S_{n,i}\cap S$ that are entangled with the particle $\mathcal{Q}$ such that $\ip*{\gamma_j^{(\mathcal{Q})}}{\gamma_{j'}^{(\mathcal{Q})}}\approx 0$ for $j\neq j'$,   $\{\ket*{\gamma_k^{(\mathcal{A})}}\}$  are normalized states of photons in $S_{n,i}\cap S$ that are entangled with the apparatus $\mathcal{A}$ such that $\ip*{\gamma_k^{(\mathcal{A})}}{\gamma_{k'}^{(\mathcal{A})}}\approx 0$ for $k\neq k'$, and for clarity, we have absorbed any other environmental information into the states $\ket{a_k}$. The hypersurface $S_{n,i}$ and the photons being reflected from the vicinity of $z_1$ just after time $t_i$ are depicted in figure \ref{pisolution}.

\begin{figure}[ht!]
	\captionsetup{justification=justified}
	\centering
	\tikzmath{
	\a=5.3;  
	\qa=5.3;  
	\psione=0;
	\qpsione=0;
	\psitwo=1.5;
	\h=-1;
	\labelx=(\psione+\psitwo)/2;
	\labely=-1.5;
	\phstartx=-1.1;
	\qphstartx=-3.8;
	\wphstartx=-0.8;
	\phstarty=\h;
	\tbeg=\phstarty;
	\ca=\phstartx-\tbeg;
	\ttwo=\psitwo-\ca;
	\cb=\ttwo+\ca;
	\xend=\ttwo-\a+\cb;
	\tone=\psione-\ca;
	\cc=\tone+\ca;
	\xendz=\tone-\a+\cc;
	\qca=\qphstartx-\tbeg;
	\qtone=\qpsione-\qca;
	\qqcc=\qtone+\qca;
	\qxendz=\qtone-\qa+\qqcc;
	\wa=5.3;  
	\wpsione=0;
	\wttestx=3.7;
	\wca=\wphstartx-\tbeg;
	\wtone=\wpsione-\wca;
	\wwcc=\wtone+\wca;
	\wxendz=\wtone-\wa+\wwcc;
	\wat=\wa-\wttestx;
	\wct=\wttestx;
	\wlam = 0.87;
		\we=0.1;
	\tthree=\cc+\tone-\psitwo;
	\circsize=0.08;
	\md = (\a+\h)/2;
	\tlen=0.75;
	\textscale = 0.7;
	\picscale = 0.89;
	\nudge=0.1;
	\tnudge=(\ttwo-\tone)/2+0.8;
	\ttesta=2*\tone-\ttwo-\tnudge;
	\sonea=\a+\psione-\ttesta;
	\sadd=0.5;
	\lrange = -(\psione-\a+\ttesta)+\sadd;
	\rrange =\lrange; 
	\timex=\rrange-1.5;
	\ttestx=2.4;
	\at=\a-\ttestx;
	\ct=\ttestx;
	\qttestx=1.2;
	\qat=\qa-\qttestx;
	\qct=\qttestx;
	\qlam = 0.87;
	\lam = 0.87;
	\e = 0.1;
	\qe=0.1;
	\hae=(2*pow(\at,3)*\lam*(2+\lam)+\e*\e*(2*\e-sqrt(4*\e*\e+\at*\at*\lam*\lam))-8*\at*\e*(-2*\e+sqrt(4*\e*\e+\at*\at*\lam*\lam))-2*\at*\at*(2+\lam)*(-2*\e+sqrt(4*\e*\e+\at*\at*\lam*\lam)))/(4*\at*\lam*(2*\at+2*\e-sqrt(4*\e*\e+\at*\at*\lam*\lam)))-(\e*\e/4+\at*\at*(-1+\lam))/(\at*\lam);
	\qhae=(2*pow(\qat,3)*\qlam*(2+\qlam)+\qe*\qe*(2*\qe-sqrt(4*\qe*\qe+\qat*\qat*\qlam*\qlam))-8*\qat*\qe*(-2*\qe+sqrt(4*\qe*\qe+\qat*\qat*\qlam*\qlam))-2*\qat*\qat*(2+\qlam)*(-2*\qe+sqrt(4*\qe*\qe+\qat*\qat*\qlam*\qlam)))/(4*\qat*\qlam*(2*\qat+2*\qe-sqrt(4*\qe*\qe+\qat*\qat*\qlam*\qlam)))-(\qe*\qe/4+\qat*\qat*(-1+\qlam))/(\qat*\qlam);
		\whae=(2*pow(\wat,3)*\wlam*(2+\wlam)+\we*\we*(2*\we-sqrt(4*\we*\we+\wat*\wat*\wlam*\wlam))-8*\wat*\we*(-2*\we+sqrt(4*\we*\we+\wat*\wat*\wlam*\wlam))-2*\wat*\wat*(2+\wlam)*(-2*\we+sqrt(4*\we*\we+\wat*\wat*\wlam*\wlam)))/(4*\wat*\wlam*(2*\wat+2*\we-sqrt(4*\we*\we+\wat*\wat*\wlam*\wlam)))-(\we*\we/4+\wat*\wat*(-1+\wlam))/(\wat*\wlam);
	} 
	\tikzstyle{scorestars}=[star, star points=5, star point ratio=2.25, draw, inner sep=1pt]%
	\tikzstyle{scoresquare}=[draw, rectangle, minimum size=1mm,inner sep=0pt,outer sep=0pt]%
	\begin{tikzpicture}[scale=\picscale,
	declare function={
		testxonep(\ps,\t)=\a+\ps-\t;
		testxonem(\ps,\t)=\ps-\a+\t; 
		bl(\x)=\ct+\at-\e/2-1/2*(sqrt(\lam*\lam*pow(\x+\hae+\at,2)+\e*\e)-\e+\lam*(\x+\hae+\at));
		br(\x)=\ct+\at-\e/2-1/2*(sqrt(\lam*\lam*pow(\x-\hae-\at,2)+\e*\e)-\e-\lam*(\x-\hae-\at));
		bc(\x)=\ct+sqrt(\lam*\lam*\x*\x+\e*\e)-\e;
		qbl(\qx)=\qct+\qat-\qe/2-1/2*(sqrt(\qlam*\qlam*pow(\qx+\qhae+\qat,2)+\qe*\qe)-\qe+\qlam*(\qx+\qhae+\qat));
		qbr(\qx)=\qct+\qat-\qe/2-1/2*(sqrt(\qlam*\qlam*pow(\qx-\qhae-\qat,2)+\qe*\qe)-\qe-\qlam*(\qx-\qhae-\qat));
		qbc(\qx)=\qct+sqrt(\qlam*\qlam*\qx*\qx+\qe*\qe)-\qe;
		wbl(\wx)=\wct+\wat-\we/2-1/2*(sqrt(\wlam*\wlam*pow(\wx+\whae+\wat,2)+\we*\we)-\we+\wlam*(\wx+\whae+\wat));
		wbr(\wx)=\wct+\wat-\we/2-1/2*(sqrt(\wlam*\wlam*pow(\wx-\whae-\wat,2)+\we*\we)-\we-\wlam*(\wx-\whae-\wat));
		wbc(\wx)=\wct+sqrt(\wlam*\wlam*\wx*\wx+\we*\we)-\we;
	},
	 ] 
	\definecolor{tempcolor}{RGB}{250,190,0}
	\definecolor{darkgreen}{RGB}{40,190,40}
	
	\draw[->,blue, thick] [domain=-\at/2:-\lrange, samples=150]   plot (\x, {bl(\x)})  ;
	\draw[blue, thick] [domain=-\at/2:\at/2, samples=150] plot (\x, {bc(\x)})   ;
	\draw[->,blue, thick] [domain=\at/2:\rrange, samples=150]   plot (\x, {br(\x)})   ;
	
	 
	 \draw[->,gray, thick] [domain=-\at/2:-\lrange, samples=150]   plot (\x, {qbl(\x)})  ;
	\draw[gray, thick] [domain=-\at/2:\at/2, samples=150] plot (\x, {qbc(\x)})   ;
	\draw[->,gray, thick] [domain=\at/2:\rrange, samples=150]   plot (\x, {qbr(\x)})   ;
	
	\draw[->,black, thick] [domain=-\at/2:-\lrange, samples=150]   plot (\x, {wbl(\x)})  ;
	 \draw[black, thick] [domain=-\at/2:\at/2, samples=150] plot (\x, {wbc(\x)})   ;
	 \draw[->,black, thick] [domain=\at/2:\rrange, samples=150]   plot (\x, {wbr(\x)})   ;

	  
	  
	
	
	 \node[scale=\textscale]  at (2.5,4.1) {$S_{n,f}$}; 
	  \node[scale=\textscale]  at (3.9,4.1) {$S_{n,i}$}; 
	  	  \node[scale=\textscale]  at (1.1,4.1) {$S_{n,m}$}; 
	
	\draw[<->] (-\lrange, \h) node[left, scale=\textscale] {$S_0$} -- (\rrange, \h) node[right, scale=\textscale] {$S_0$};
	\draw[<->] (-\lrange, \a) node[left, scale=\textscale] {$S$} -- (\rrange, \a) node[right, scale=\textscale] {$S$};
				  
	\draw[->, shorten <= 5pt,  shorten >= 1pt] (\psione,\h)  node[above right, scale=\textscale]{$z_1$}-- (\psione,\a) ;
	
	
	\draw[dashed, tempcolor,  thick](\phstartx,\tbeg) node[below left=-2,scale=\textscale]{}--(\psione,\tone) node[above, pos=0.3, rotate=45,scale=0.7,black] {} node[below, pos=0.3, rotate=45,scale=0.7,black] {};
	\draw[dashed, tempcolor,  thick](\psione,\tone)--(\xendz,\a);
	
	
	\draw[dashed, tempcolor,  thick](\qphstartx,\tbeg) node[below left=-2,scale=\textscale]{}--(\psione,\qtone) node[above, pos=0.3, rotate=45,scale=0.7,black] {} node[below, pos=0.3, rotate=45,scale=0.7,black] {};
	\draw[dashed, tempcolor,  thick](\psione,\qtone)--(\qxendz,\a);

	\draw[dashed, orange,  thick](\wphstartx,\tbeg) node[below left=-2,scale=\textscale]{}--(\psione,\wtone) node[above, pos=0.3, rotate=45,scale=0.7,black] {} node[below, pos=0.3, rotate=45,scale=0.7,black] {};
	\draw[dashed, orange,  thick](\psione,\wtone)--(\wxendz,\a);
	
	\draw[->] (\timex,\md-\tlen/2) --  (\timex,\md+\tlen/2) node[midway,right, scale=\textscale]{time}; 
	 
	\draw[dotted](\psione,\ttestx)--({testxonep(\psione,\ttestx)},\a);
	\draw[dotted](\psione,\ttestx)--({testxonem(\psione,\ttestx)},\a);
	\draw[dotted](\psione,\qttestx)--({testxonep(\psione,\qttestx)},\a);
	\draw[dotted](\psione,\qttestx)--({testxonem(\psione,\qttestx)},\a);
	
	\draw (\psione,\ttestx) node[ scoresquare, fill=gray]  {} node [black,below=6,right,scale=\textscale] {$t_f$};
	\draw (\psione,\qttestx) node[ scoresquare, fill=gray]  {} node [black,below=6,right,scale=\textscale] {$t_i$};
	\draw (\psione,\wttestx) node[ scoresquare, fill=gray]  {} node [black,below=6,right,scale=\textscale] {$t_m$};
	
%	\draw[magenta,->,ultra thick] ({testxonem(\psione,\qttestx)},\a)--(-\lrange,\a);
%	\draw[magenta,ultra thick] ({testxonem(\psione,\ttestx)},\a)-- ({testxonem(\psione,\qttestx)},\a);
%	\draw[magenta,ultra thick] ({testxonep(\psione,\ttestx)},\a)-- ({testxonep(\psione,\qttestx)},\a);
%	\draw[magenta,->,ultra thick] ({testxonep(\psione,\qttestx)},\a)--(\rrange,\a);
	
	\draw [black,fill](\xendz,\a) circle [radius=\circsize] node [black,above=9,right=-4,scale=\textscale] {$\gamma_i^{(\mathcal{A})}$}; 
	\draw [black,fill](\wxendz,\a) circle [radius=\circsize] node [black,above=9,left=-7,scale=\textscale] {$\gamma_i^{(\mathcal{Q})}$}; 
	\draw [black,fill](\qxendz,\a) circle [radius=\circsize] node [black,above,scale=\textscale] {$\gamma_f^{(\mathcal{Q})}$}; 
	%\draw [black,fill] (\xendz,\a) circle [radius=\circsize] node [black,above,scale=\textscale] {$\gamma_1$}; 
	\end{tikzpicture}% pic 1
	
	\vspace*{2px}
	\caption{Depicts an experiment where the state of some photons $\gamma_i^{(\mathcal{Q})}$ and $\gamma_i^{(\mathcal{A})}$ on the hypersurface $S$ determines the initial conditions of an experimental setup of a particle $\mathcal{Q}$ and apparatus $\mathcal{A}$ in the vicinity of the spacetime location $(z_1, t_i)$, and the state of the photons $\gamma_f^{(\mathcal{Q})}$ on the hypersurface $S$ determines the final state of the particle as it leaves the apparatus at time $t_f$ such that measurement at time $t_m$ has a definite outcome. It is assumed that no incoming photons have interacted with the experiment after the $\gamma_i^{(\mathcal{Q})}$ and $\gamma_i^{(\mathcal{A})}$ photons and before the $\gamma_i^{(\mathcal{Q})}$ photons have interacted with the experiment.  }
	\label{pisolution}
	\end{figure}


If we now define the projection $\pi_{n,i}$ corresponding to the ``measurement'' $\tau_S(x)$ as in equation (\ref{tauprojection}),
 then
 $$\pi_{n,i}\ket{\Psi_{n,i}}\approx c_{i,i}\ket{q_i}\ket{a_i}\ket*{\gamma_i^{(\mathcal{Q})}}\ket*{\gamma_k^{(\mathcal{A})}}$$
 We assume that $\ket*{\gamma_i^{(\mathcal{Q})}}$ determines the initial condition of the particle $\mathcal{Q}$ before it interacts with the apparatus $\mathcal{A}.$ We also assume that no further interaction of the particl with external photons until after time $t_f$.

\subsection{An objection to Kent's beables}


There is still the question of why Kent decides that the beables of his theory should take the form of expectation values. As an analogy, it seems a bit like saying a six sided dice can actually come up with a $3.5$ since this is its expectation value. We can however address this objection if we can find a way of having multiple throws of the dice, so to speak. My suggestion is to stipulate that the reduced density matrices $\hat{\rho}_y$ as calculated in the previous section are more fundamental beables than the conditional expectation values of $\hat{T}_{\mu,\nu}(y)$, and that the determinate value of $T_S$ is more fundamental still. There are a few things I need to explain here such as what I mean fundamental, what I mean by saying a beable is a reduced density matrix, and how the beable of a reduced density matrix can give rise to Kent's expectation value beables.

By saying that the determinate value of $T_S$ is more fundamental than the reduced density matrices,  I mean that if we have a statement of the form ``the beable at $y$ is $\hat{\rho}_y$'', then such a statement is reducible to statements about $T_S$. Such statements might be simple factual statements such as ``there is photon is at $x_1$, and $x_2$ but not at $x_3$ or $x_4$'' where the locations are indicated in figure \ref{kentdecoh5}.

\begin{figure}[ht!]
\captionsetup{justification=justified}
\centering
\tikzmath{
\a=5.3;  
\psione=0;
\psitwo=1.5;
\psithree=-0.7;
\h=1;
\labelx=(\psione+\psitwo)/2;
\labely=-1.5;
\phstartx=-1.7;
\phstartxx=-0.9;
\phstarty=\h;
\tbeg=\phstarty;
\ca=\phstartx-\tbeg;
\caa=\phstartxx-\tbeg;
\ttwo=\psitwo-\ca;
\ttwoo=\psitwo-\caa;
\cb=\ttwo+\ca;
\cbb=\ttwoo+\caa;
\xend=\ttwo-\a+\cb;
\xendd=\ttwoo-\a+\cbb;
\tone=\psione-\ca;
\tonee=\psione-\caa;
\cc=\tone+\ca;
\ccc=\tonee+\caa;
\xendz=\tone-\a+\cc;
\xendzz=\tonee-\a+\ccc;
\tthree=\cc+\tone-\psitwo;
\circsize=0.08;
\md = (\a+\h)/2;
\tlen=0.75;
\textscale = 0.7;
\picscale = 0.89;
\nudge=0.1;
\tnudge=(\ttwo-\tone)/2+0.8;
\ttesta=2*\tone-\ttwo-\tnudge;
\ttestb=2*\tone-\ttwo+\tnudge;
\ttestc=\ttwo-\tnudge;
\ttestd=\ttwo+\tnudge;
\sonea=\a+\psione-\ttesta;
\sadd=0.5;
\lrange = -(\psione-\a+\ttesta)+\sadd;
\rrange =\lrange; 
\timex=\rrange-1.5;
\e = 0.4;
\ttestx=4;
\at=\a-\ttestx;
\ct=\ttestx;
\lam = 0.87;
\e = 0.2;
\hae=(2*pow(\at,3)*\lam*(2+\lam)+\e*\e*(2*\e-sqrt(4*\e*\e+\at*\at*\lam*\lam))-8*\at*\e*(-2*\e+sqrt(4*\e*\e+\at*\at*\lam*\lam))-2*\at*\at*(2+\lam)*(-2*\e+sqrt(4*\e*\e+\at*\at*\lam*\lam)))/(4*\at*\lam*(2*\at+2*\e-sqrt(4*\e*\e+\at*\at*\lam*\lam)))-(\e*\e/4+\at*\at*(-1+\lam))/(\at*\lam);
\mmu=(\tone-\tbeg)/(\psione-\phstartx);
\nnu=(\psione*\tbeg-\phstartx*\tone)/(\psione-\phstartx);
\muf=(\a-\ttwo)/(\xend-\psitwo);
\nuf=(\xend*\ttwo-\psitwo*\a)/(\xend-\psitwo);
} 
\tikzstyle{scorestars}=[star, star points=5, star point ratio=2.25, draw, inner sep=1pt]%
\tikzstyle{scoresquare}=[draw, rectangle, minimum size=1mm,inner sep=0pt,outer sep=0pt]%
\begin{tikzpicture}[scale=\picscale,
declare function={
	testxonep(\ps,\t)=\a+\ps-\t;
	testxonem(\ps,\t)=\ps-\a+\t; 
	xa(\m,\n)=(-\ct*\m+\e*\m+\m*\n-sqrt(\ct*\ct*\lam*\lam+\e*\e*\m*\m+2*\e*\lam*\lam*\n+\lam*\lam*\n*\n-2*\ct*\lam*\lam*(\e+\n)))/(\lam*\lam-\m*\m);
	xb(\m,\n)=(-\ct*\m+\e*\m+\m*\n+sqrt(\ct*\ct*\lam*\lam+\e*\e*\m*\m+2*\e*\lam*\lam*\n+\lam*\lam*\n*\n-2*\ct*\lam*\lam*(\e+\n)))/(\lam*\lam-\m*\m);
	bl(\x)=\ct+\at-\e/2-1/2*(sqrt(\lam*\lam*pow(\x+\hae+\at,2)+\e*\e)-\e+\lam*(\x+\hae+\at));
	br(\x)=\ct+\at-\e/2-1/2*(sqrt(\lam*\lam*pow(\x-\hae-\at,2)+\e*\e)-\e-\lam*(\x-\hae-\at));
	bc(\x)=\ct+sqrt(\lam*\lam*\x*\x+\e*\e)-\e;
},
 ] 
\definecolor{tempcolor}{RGB}{250,190,0}
\definecolor{darkgreen}{RGB}{40,190,40}

%\draw[->,blue, thick] [domain=-\at/2:-\lrange, samples=150]   plot (\x, {bl(\x)})  ;
%\draw[blue, thick] [domain=-\at/2:\at/2, samples=150] plot (\x, {bc(\x)})  node[right=20, above=10,black,scale=\textscale]{}  ;
%\draw[->,blue, thick] [domain=\at/2:\rrange, samples=150]   plot (\x, {br(\x)})   ;

% \node[scale=\textscale]  at (1,4.1) {$S_n(y^c_1)$}; 
\draw[<->] (-\lrange, \h) node[left, scale=\textscale] {$S_0$} -- (\rrange, \h) node[right, scale=\textscale] {$S_0$};
\draw[<->] (-\lrange, \a) node[left, scale=\textscale] {$S$} -- (\rrange, \a) node[right, scale=\textscale] {$S$};
              
\draw[->, shorten <= 5pt,  shorten >= 1pt] (\psione,\h) node[below, scale=\textscale]{$\psi_1^{\text{sys}}$} node[above left, scale=\textscale]{$z_1$}-- (\psione,\a) ;
\draw[->,  shorten <= 5pt,  shorten >= 1pt] (\psitwo,\h) node[below, scale=\textscale]{$\psi_2^{\text{sys}}$} node[above right, scale=\textscale]{$z_2$}-- (\psitwo,\a);
\draw[->,  shorten <= 5pt,  shorten >= 1pt] (\psithree,\h) node[below, scale=\textscale]{$\psi_{3}^{\pm}$}   node[above left, scale=\textscale]{$z_3$}-- (\psithree,\a);


\draw[dashed, tempcolor,  thick](\phstartx,\tbeg) node[below left=-2,scale=\textscale]{}--(\psione,\tone) ;
\draw[dashed, tempcolor,  thick](\psione,\tone) node[below left=-2,scale=\textscale]{}--(\psitwo,\ttwo );
\draw[dashed, tempcolor,  thick](\psitwo,\ttwo)--(\xend,\a); 
\draw[dashed, tempcolor,  thick](\psione,\tone)--(\xendz,\a);

\draw[dashed, tempcolor,  thick](\phstartxx,\tbeg) node[below left=-2,scale=\textscale]{}--(\psione,\tonee) ;
\draw[dashed, tempcolor,  thick](\psione,\tonee) node[below left=-2,scale=\textscale]{}--(\psitwo,\ttwoo );
\draw[dashed, tempcolor,  thick](\psitwo,\ttwoo)--(\xendd,\a); 
\draw[dashed, tempcolor,  thick](\psione,\tonee)--(\xendzz,\a);

\draw[magenta,<->,ultra thick] (\rrange,\a)--(-\lrange,\a);



\draw[->] (\timex,\md-\tlen/2) --  (\timex,\md+\tlen/2) node[midway,right, scale=\textscale]{time}; 

\draw [black,fill] (\xendzz,\a) circle [radius=\circsize] node [black,above,scale=\textscale] {$x_1$}; 
\draw [black,fill] (\xend,\a) circle [radius=\circsize] node [black,above,scale=\textscale] {$x_4$}; 
\draw [black,fill] (\xendz,\a) circle [radius=\circsize] node [black,above,scale=\textscale] {$x_2$}; 
\draw [black,fill] (\xendd,\a) circle [radius=\circsize] node [black,above,scale=\textscale] {$x_3$}; 
 
%\draw[dotted](\psione,\ttestx)--({testxonep(\psione,\ttestx)},\a);
%\draw[dotted](\psione,\ttestx)--({testxonem(\psione,\ttestx)},\a);
\draw [black,fill] (\psione,\tone) circle [radius=\circsize] node [black,left=4,scale=\textscale] {$y_1$}; 
\draw [black,fill](\psitwo,\ttwo)circle [radius=\circsize] node [black,above right,scale=\textscale, align=left] {$y_2$}; 

%\draw (\psione,\ttestx) node[ scoresquare, fill=gray]  {} node [black,below=6,right,scale=\textscale] {$y^c_1$};
%\draw (\psitwo, {bc(\psitwo)}) node[ scoresquare, fill=gray]  {} node [black,below=6,right,scale=\textscale] {$y^c_2$};
%\draw ({xb(\muf,\nuf)}, {xb(\muf,\nuf)*\muf+\nuf}) node[ scoresquare, fill=gray]  {} node [black,right=7, below=-4,scale=\textscale] {$y^c_4$};
%\draw (\xendz,\a) node[ scoresquare, fill=gray]  {} node [black,below=3,scale=\textscale] {$y^c_3$};


%\draw [black,fill] (\xendz,\a) circle [radius=\circsize] node [black,above,scale=\textscale] {$\gamma_1$}; 
\end{tikzpicture}% pic 1

\vspace*{2px}
\caption{Depiction of a superposition of two local states at $z_1$ and $z_2$ with $y^c_1$ sufficiently late that the photon intersects $S_n(y^c_1)\cap S$. With enough photon detections on $S$ we can make statements about }
\label{kentdecoh5}
\end{figure}


 With enough such factual statements, we would have enough information on $T_S$ to say that there is a local state $\psi_1^\text{sys}$ at spacetime location $y_1$ and hence conclude that the statement p=``the beable at $y_1$ is $\dyad{\psi_1^\text{sys}}$'' is true. But we would very likely need quite a lot more information than knowledge of the fact that a photon is at $x_1$, and $x_2$, to conclude p since we would need to be able to work out something about time at which the incoming arrived in the vicinity of the system, and this would depend on physics of photon creation. But it seems plausible that from all the information in $T_S$ one could make statements such as p that involve pure states. It is no more controversial than the assumption that we can draw valid conclusions about the physical world based on which cells in our retina are excited. What is controversial is my (and Kent's) suggestion   that the information contained in $T_S$ determines the state of physical reality on earlier hypersurfaces rather than the physical state of the earlier hypersurfaces determining the information contained in $T_S$. In the final chapter, I will aim to justify this suggestion and show that it is not quite as alien to common sense as it might first seem. 
 
As for statements that involve improper mixtures, for example statements of the form q=``the beable at $y_1$ is $\abs{c_1}^2\dyad{\psi_1^\text{sys}}+\abs{c_2}^2\dyad{0_1}$'', we could take these to be expressible in terms of modal statement about such as ``it's possible that a photon could have been detected at either $x_1$ or $x_3$ but not both'' as depicted in figure \ref{kentdecoh5}. As in the case for pure states, we would also need other modal statements and declarative propositions about $T_S$ in order to say enough about the times at which incoming photons would arrive at the $z_1$ and $z_2$. But with enough information on $T_S$ it seems plausible that we could build up a picture of such photon interaction on earlier hypersurfaces. Also, by comparing the values of $T_S$ over different region of $S$, we could detect similar configurations from which a super-intelligent being could conclude that these similar configurations correspond to some kind of activity such as a human being performing an experiment.   But these multiple configurations would also have differences, some of which would correspond to different measurement outcomes. By surveying many of these configurations, the super-intelligent being could assign probabilities to these outcomes and hence calculate expectation values for observables and the reduced density matrices that would give rise to these expectation values and hence make statements like $q$ which involve improper mixtures. 

At this point it is worth reminding ourselves that Kent is not saying that an actual measurement of $T_S$ on $S$ is made, but only a notional measurement which is to say if a measurement were made on $T_S$ it would have a determinate value $\tau_S$, say. One could choose a hypersurface $S'$ even later than $S$, but Kent supposes that the description of physical reality between $S_0$ and $S$ is not going to be significantly different if the one used the notional measurements for $T_{S'}$ on $S'$ rather than those on $T_S$.

So let's now consider how the understanding of beables in terms of reduced density matrices can give rise to Kent's beables as conditional expectation values of $T_{\mu,\nu}(y)$. In this section we have been approximating $S_n$ as a coarse-grained model so that $S_n$ is treated as a mesh of tiny cells labeled. The state of these one of these tiny cells, $y_k$ would not in general be pure eigenstates of $T_{\mu,\nu}(y_k)$


\nocite{Shimony93}
\nocite{Bell}