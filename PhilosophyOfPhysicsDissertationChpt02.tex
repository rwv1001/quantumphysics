\documentclass[letter, 12pt]{turabian-thesis}
\setlength{\skip\footins}{1.2pc plus 5pt minus 10pt}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{csquotes}
\usepackage{biblatex-chicago}
\usepackage{paralist}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{lipsum}  
\usepackage{ragged2e}
\usepackage{cancel}
\usepackage{bm}
\usepackage{amssymb}
\usepackage{physics}
\usepackage{gensymb} 
\usepackage{csquotes}
\usepackage{enumitem}
\usepackage{comment}
\usepackage{mathtools}
\usepackage{siunitx}
\usepackage[acronym, nopostdot, nonumberlist, section]{glossaries}
\usepackage{glossary-mcols}
\usepackage{etoolbox}
\usepackage{graphicx} % Required for including images
\usepackage{tikz, tikz-3dplot}
\usetikzlibrary{calc,decorations.markings}
\usetikzlibrary{decorations.pathreplacing,calligraphy}
\usetikzlibrary{math,fixedpointarithmetic,shapes.geometric}
\usetikzlibrary{decorations.text}
\usepackage[autolanguage]{numprint}
\usepackage{caption}
\usepackage{parskip}
\usepackage{bigfoot}
\usepackage{cleveref}
\usepackage{tensor}
\setcounter{secnumdepth}{5}

\tdplotsetmaincoords{80}{45}
\tdplotsetrotatedcoords{-90}{180}{-90}

\thispagestyle{empty}
\makeatletter
\patchcmd{\chapter}{\if@openright\cleardoublepage\else\clearpage\fi}{}{}{}
\makeatother

\usepackage[inline]{showlabels}

\newcommand{\du}[2]{\mathbf{\SI[inter-unit-product={}\cdot{}]{#1}{#2}}}

\theoremstyle{hypothesis}
\newtheorem*{hypothesis}{Partitioning Criterion}
\newcommand\myeq{\stackrel{\mathclap{\scriptsize\mbox{def}}}{=}}
\newcommand{\uvb}[1]{\vb{\hat{{#1}}}}
\newcommand{\uvbp}[1]{\uvb{#1}\bm{+}}
\newcommand{\uvbm}[1]{\uvb{#1}\bm{-}}
\newcommand{\uvbpm}[1]{\uvb{#1}\bm{\pm}}
\newcommand{\dotsize}{2pt}
\makeatletter 
\def\footnoterule{\kern-6\p@ % you can put other values to increase vertical space between rule and notes (just try out); difference between the values after "kern" is the width of the rule!
\hrule \@width 2in \kern 5.7\p@} % the in value is the length of the footnoterule
% footnotemark

\renewcommand{\@makefntext}[1]{%
\if@optraggedright
\raggedright%
\fi
\setlength{\parindent}{\footnotemargin}%
\textsuperscript{\@thefnmark}#1%
}

\addtolength{\skip\footins}{2pt} % vertical space between rule and main text
\setlength{\footnotesep}{12pt} % vertical space between footnotes
\let\origfootnote\footnote % font size of footnotes; changes \footnotesize command only inside footnotes!
\setlength{\footnotemargin}{0in}
\renewcommand{\footnote}[1]{%
\noindent % here there is scriptsize in footnotes (example) 
\origfootnote{#1}} 

\makeatother




\usepackage{url}



\let\URL\url
\makeatletter
\def\url#1{\@URL#1;;;\@nil}
\def\@URL#1;#2;#3;#4\@nil{%
\URL{#1}\ifx\relax#2\relax\else\ifx\relax#3\relax; \URL{#2} \else; \URL{#2}; \URL{#3}\fi \fi}
\makeatother
%url = {http://citeseer.ist.psu.edu/562256.html; http://gfs.sf.net/gerris.pdf}



\renewcommand{\Tr}{\operatorname{Tr}}
\newcommand{\diag}{\operatorname{diag}}


\addbibresource{PhilosophyOfPhysicsDissertationChpt02.bib}
\title{On Physics and Common Sense}
\author{Robert Verrill OP}

\date{\today}
\interfootnotelinepenalty=0
\allowdisplaybreaks
\setcounter{tocdepth}{4}
\begin{document}
\justifying
\setlength{\abovedisplayskip}{3pt}
\setlength{\belowdisplayskip}{3pt}
\setlength{\textheight}{675pt}
\setlength{\parindent}{0em}
\setlength{\oddsidemargin}{10pt}
\setlength{\marginparwidth}{80pt}


\maketitle


\thispagestyle{empty}
\tableofcontents
\chapter{Evaluating Kent's Solution to the Measurement Problem}


In thet previous chapter, we saw how a denial of the Copenhagen interpretation of quantum mechanics and a denial of hidden variables leads fairly naturally to a so-called Many-Worlds interpretation of quantum mechanics. However, the Many-Worlds interpretation seems to be radically opposed to the view that we can make common sense truth claims about the physical world. A strategy among some philosophers of physics who do not wish to endorse the Many-Worlds interpretation is therefore to reexamine the assumptions that lead to Bell's Inequality. One of these assumptions will have to be discarded since Bell's Inequality is experimentally violated. The false assumption that is used to prove Bell's Inequality is sometimes referred to as \textbf{the culprit}. We therefore need to identify the culprit, that is we need to decide which assumption we should discard while keeping in mind that we wish to maintain a theory that is compatible with the experimental findings of quantum physics and special relativity.

Shimony, noticed that there are two key assumptions in the proof of Bell's Inequality that might be identified as the culprit. He refers to one assumption as {Outcome Independence} (OI), and to the other assumption as {Parameter Independence} (PI).\footnote{See \cite[146-147]{Shimony86}.} Shimony argued that if we only denied OI, then the proof of Bell's Inequality would fail to go through. Yet by continuing to assume PI, there is a sense in which Special Relativity is not obviously violated. Shimony therefore thought that denying OI and assuming PI was sufficient to ensure peaceful coexistence between quantum theory and special relativity. In other words, Shimony thought OI was the culprit. Butterfield\footnote{See \cite{Butterfield}.}, however, argues that although PI is a necessary assumption if there is to be peaceful coexistence between quantum theory and special relativity, PI together with the denial of OI independence is not sufficient to ensure peaceful coexistence, the reason being that Shimony offers no account of what an outcome is. As mentioned in the previous chapter, the problem of outcomes is an important issue that d'Espagnat highlights.
It is Shimony's failure to address the problem of outcomes that motivated Butterfield to explore whether Kent's interpretation of quantum physics provides what is lacking in Shimony's account. 

In this chapter, I will present and evaluate Kent's interpretation of quantum physics. In order to provide such an evaluation, it will be necessary show that the predictions of Kent's theory do not contradict the  predictions of quantum theory that have been experimetnally validated. We also need to show that Kent's theory also possesses the symmetries, known as Lorentz invariance, that belong to a theory that is consistent with Einstein's theory of Special Relativity. But we also need to address Shimony's question of identifying the cultprit, and to this end, we will need to explain what is meant by OI and PI. In recent years,  Leegwater et al.\footnote{See \cite{LeegwaterGijs2016Aitf}, \cite{ColbeckRoger2011Neoq}, \cite{ColbeckRoger2012Tcoq}, \cite{LandsmanK2015OtCt}, and \cite{Landsman}.} have also proved an important theorem, the so-called {`Collbeck-Renner Theorem'} regarding PI which suggest that if PI holds together with what is called a {`no conspiracy'} criterion, then this implies standard quantum theory without any additional variables. And finally, we will have to consider the extent to which Kent's interpretation yields a convincing account of what an outcome is.

We will first turn our attention to the notions of OI and PI.

\section{Outcome Independence versus Parameter Independence}
To explain Shimony's\footnote{See \cite[146-147]{Shimony86} and \cite[7-9]{Butterfield}.}  notion of  Outcome Independence and Parameter Independence, we suppose we have an experimental setup similar to the experimental setup described in section \ref{BellSection} on Bell's Inequality. Thus, we suppose there are two particles labeled $q_A$, and $q_B$, and that a measurement can be made on particle  $q_A$ at one location (e.g. Alice's laboratory), and a measurement can be made on particle $q_B$ at some other location (e.g. Bob's laboratory). Alice can make a choice of one of $n$ measurements to be made labeled $a_1,\ldots, a_n$. For example, $a_1$ might be a measurement of $q_A$'s spin along the $z$-axis, whereas $a_2$ might be the measurement of $q_A$'s spin along an axis that is at  a $45^\circ$ angle to the $z$-axis etc.. We use the variable $x$ to denote Alice's choice so that $x=a_i$ for some $i\in\{1,\ldots,n\}$. If Alice chooses to make measurement $a_i$ (i.e. $x=a_i$), the measurement outcome is labeled $A_i$ and can take values $+1$ or $-1$. For example, Alice could use the convention in which $+1$ corresponds to a spin up outcome, and $-1$ corresponds to a spin down outcome. We will use the variable $X$ to denote the measurement outcome Alice obtains, so for example, if Alice chooses to make the $a_1$ measurement so that $x=a_1$ and obtains the outcome $A_1=1$, then $X=1$. In a similar way, we use the notation $b_i,\, y$ and $B_i,\, Y$ to correspond to the measurement choices and measurement outcomes for Bob.

We now suppose that there is is a complete state $\lambda\in\Lambda$ describing both $q_A$ and $q_B$ that is independent of Alice and Bob's measurement choices, but that encodes all other features that would influence the corresponding measurement outcomes. Here, the domain $\Lambda$ of all such complete states will depend on how the two particles are prepared and the model we assuming. We also assume that  $q_A$ and $q_B$ are initially coupled together in such a way that Alice and Bob would always get opposite results when they made their measurements in the same direction. For instance, for $n=3$, we might assume a model in which 
\begin{equation}\label{bellLambda}
\Lambda=\big\{(A_1, A_2, A_3 ,B_1, B_2, B_3):A_1,\, A_2,\, A_3=\pm1,\, B_i=-A_i\big\}.
\end{equation}
 In this case, $\lambda\in\Lambda$ would fully determine Alice and Bob's measurement outcomes. This would be like the model described in the proof of Bell's Inequality with all the states of $\Lambda$ being described in table \ref{hiddentable} of section \ref{BellSection}. 
 
However, in general, we don't insist on such determinism. Rather, we suppose that given a complete state $\lambda\in\Lambda$, and given that Alice makes measurement $x$ and Bob makes measurement $y$, then there there will be a probability $P_{\lambda,x,y}(X , Y)$ representing the probability Alice gets outcome $X$ and Bob gets outcome $Y$. It is only in deterministic models that $P_{\lambda,x,y}(X , Y)$ will only have values restricted to either $0$ or $1$. In non-deterministic models, there will have to be some situations when $P_{\lambda,x,y}(X, Y)$ has a value strictly between $0$ and $1$. For example, if our model was standard quantum mechanics, we could take $\lambda$ to be the Bell state (\ref{bell}). Then it follows from equation (\ref{bellstate2}) that as long as Alice's and Bob's measurement choices $x$ and $y$ are in the same direction, then $P_{\lambda,x,y}(1,-1)=1/2$. Incidentally, we also note that equation (\ref{bellstate2}) implies the domain $\Lambda$ consists of a single state:
\begin{equation}\label{quantumLambda}
\Lambda=\Bigg\{\frac{1}{\sqrt{2}}\big(\ket*{\uvbp{a}}_A\ket*{\uvbm{a}}_B-\ket*{\uvbm{a}}_A\ket*{\uvbp{a}}_B\big)\Bigg\}.
\end{equation}

In both models (\ref{bellLambda}) and (\ref{quantumLambda}) we see that if we define
\begin{align}
P_{A, \lambda,x,y}(X)&=P_{\lambda,x,y}(X, 1)+P_{\lambda,x,y}(X, -1),\label{PIone}\\
P_{B, \lambda,x,y}(Y)&=P_{\lambda,x,y}(1, Y)+P_{\lambda,x,y}(-1, Y),\label{PItwo}
\end{align}
then $P_{A,\lambda,x,y}(X)$ is independent of Bob's choice of measurement $y$ and $P_{B,\lambda,x,y}(Y)$ is independent of Alice's choice of measurement $x$.\footnote{It is easy to see\label{onehalf} that $P_{A, \lambda,x,y}(X)=1/2$ and $P_{B,\lambda,x,y}(Y)=1/2$ for any $X,\, Y$. E.g. for $x=\vb{\hat{a}}$ and $y=\vb{\hat{b}}$, by (\ref{bellstate2}), we can assume the two particles are in the state 
$$\ket{\zeta}=\frac{1}{\sqrt{2}}\big(\ket*{\uvbp{b}}_A\ket*{\uvbm{b}}_B-\ket*{\uvbm{b}}_A\ket*{\uvbp{b}}_B\big).$$
Since the inner product on the composite system is given by  $\ip{\xi'}{\xi}=\ip{\psi'}{\psi}_A\ip{\chi'}{\chi}_B$ for $\ket{\xi}=\ket{\psi}_A\ket{\chi}_B$ and $\ket{\xi'}=\ket{\psi'}_A\ket{\chi'}_B$, it follows that 
$$\prescript{}{A}{ \bra*{\vb{\hat{a}+}}}\prescript{}{B}{\bra*{\vb{\hat{b}\pm}}}=\mp\frac{1}{\sqrt{2}}\ip*{\vb{\hat{a}+}}{\vb{\hat{b}\mp}}_A$$ 
Therefore, by the Born Rule (see page \pageref{bornrule})
$$P_{\lambda,\vb{\hat{a}},\vb{\hat{b}}}(\vb{\hat{a}+}, \vb{\hat{b}+})+P_{\lambda,\vb{\hat{a}},\vb{\hat{b}}}(\vb{\hat{a}+}, \vb{\hat{a}-})=\frac{1}{2}\abs*{\ip*{\vb{\hat{a}+}}{\vb{\hat{b}+}}_A}+\frac{1}{2}\abs*{\ip*{\vb{\hat{a}+}}{\vb{\hat{b}-}}_A}.$$
But since
$$\ket*{\vb{\hat{a}+}}_A=\ip*{\vb{\hat{b}+}}{\vb{\hat{a}+}}_A\ket*{\vb{\hat{b}+}}_A+\ip*{\vb{\hat{b}-}}{\vb{\hat{a}+}}_A\ket*{\vb{\hat{b}-}}_A$$
it follows that 
$$\abs*{\ip*{\vb{\hat{a}+}}{\vb{\hat{b}+}}_A}+\abs*{\ip*{\vb{\hat{a}+}}{\vb{\hat{b}-}}_A} =1. $$
Therefore 
$$P_{\lambda,\vb{\hat{a}},\vb{\hat{b}}}(\vb{\hat{a}+}, \vb{\hat{b}+})+P_{\lambda,x,y}(\vb{\hat{a}+}, \vb{\hat{b}-})=\frac{1}{2}.$$
 } In other models, however, it's possible that such independence does not hold. So to distinguish between such possibilities, we say a model satisfies \textbf{Parameter Independence} (PI) if and only if $P_{A,\lambda,x,y}(X)$ is independent of $y$ and $P_{B,\lambda,x,y}(Y)$ is independent of $x$. In other words, PI holds if and only if (\ref{PIone}) and (\ref{PItwo}) hold for all $\lambda,$ $x,$ $y,$, $X,$ and $Y$.

One model in which PI fails to hold is the \textbf{pilot wave interpretation} of quantum mechanics. In this interpretation, it is assumed that at any instant of time $t$, the particles $q_A$ and $q_B$ will have definite positions $\vb{x}_A$ and $\vb{x}_B$ and definite momenta $\vb{p}_A$ and $\vb{p}_B$ respectively. But in addition, it is also assumed that there is a so-called \textbf{pilot wave} 
\begin{equation}
\psi(\vb{x}_A, \vb{x}_B, t)=r(\vb{x}_A, \vb{x}_B, t)e^{i S(\vb{x}_A, \vb{x}_B, t)} 
\end{equation}
where $r(\vb{x}_A, \vb{x}_B, t)>0$ is the magnitude of $\psi(\vb{x}_A, \vb{x}_B, t)$, and the real-valued function $S(\vb{x}_A, \vb{x}_B,t )$ is the phase of $\psi(\vb{x}_A, \vb{x}_B, t).$
The time evolution of the pilot-wave is deterministically governed by the Schr\"{o}dinger equation, and the phase $S(\vb{x}_A, \vb{x}_B, t )$ the positions $\vb{x}_A$ and $\vb{x}_B$ to the momenta $\vb{p}_A$ and $\vb{p}_B$ via the gradient of $S$:
\begin{equation}
\vb{p}_A=\grad_A{S}(\vb{x}_A, \vb{x}_B),\qquad
\vb{p}_B=\grad_B{S}(\vb{x}_A, \vb{x}_B).
\end{equation}
In other words, if we fix $\vb{x}_B$ and consider $S$ to be just a function of $\vb{x}_A$, then the momentum $\vb{p}_A$ is in the direction and has the magnitude of the steepest ascent of $S$ considered as a function of $\vb{x}_A$, and the momentum $\vb{p}_B$ is determined in a similar fashion. 

In reality, we don't know the exact positions of all the particles, but based on what we know about an experimental setup, we can average over our uncertainty and recover exactly the same predictions that quantum mechanics would make.\footnote{See \cite{BohmDavid1952A} and \cite{BohmDavid1952B}.} So for instance, our knowledge of the experimental setup above should enable us both to know that $q_A$ and $q_B$ are contained within a region $V,$ and also for us to workout the probability  $p(V_i, V_j)$ that particle $q_A$  will be in a region $V_i$ and $q_B$ will be in a region $V_j,$ where the $V_i$ are small non-overlapping regions such that $V=\bigcup_iV_i$. Then given some physical quantity $\Lambda(\vb{x}_A, \vb{x}_B)$ that depends on the positions $\vb{x}_A$ and $\vb{x}_B$ of the two particles, then when the regions $V_i$ are  sufficiently small so that $\Lambda(\vb{x}_i, \vb{x}_j)$ varies negligibly for any $\vb{x}_i\in V_i$ and $\vb{x}_j\in V_j$,  the average value
\begin{equation}\label{bohmconsistency}
\ev{\Lambda}=\sum_{i,j}p(V_i, V_j)\Lambda(\vb{x}_i, \vb{x}_j)
\end{equation}
will be the same as the expectation value for $\Lambda$ predicted by standard quantum mechanics.\footnote{In this explanation, I've refrained from using measure theory, but basically this explanation is saying that we when we construct a measure $\mu$ on $V\times V$ based on our knowledge of the the experiemental setup,  $\int_{V\times V}\Lambda(\vb{x}_i, \vb{x}_j)\dd\mu$ will be the same as the expectation value for $\Lambda$ predicted by standard quantum physics. }

So to see why PI fails to hold in the pilot wave model,\footnote{This is my own proof} we first note that since the pilot wave model makes the same predictions as quantum mechanics when averaged over all the hidden variables, the violation of Bell's inequality (\ref{bellinequality}) implies there must be some hidden variable $\lambda$ and choices of measurement directions $\bm{\hat{a}}$, $\bm{\hat{b}}$, and $\bm{\hat{c}}$ such that 
 \begin{equation}\label{bellinequality}
P_{\lambda,\bm{\hat{a}},\bm{\hat{b}}}(\uvbp{a};\uvbp{b})> P_{\lambda,\bm{\hat{a}},\bm{\hat{c}}}(\uvbp{a};\uvbp{c})+P_{\lambda,\bm{\hat{c}},\bm{\hat{b}}}(\uvbp{c};\uvbp{b}).
\end{equation}
Since physics in the pilot wave model is deterministic, probabilities must be either $0$ or $1$. Therefore, the only way (\ref{bellinequality}) can be satisfied is for
 \begin{align}
P_{\lambda,\bm{\hat{a}},\bm{\hat{b}}}(\uvbp{a};\uvbp{b})&=1 \label{PDproof1}\\
P_{\lambda,\bm{\hat{a}},\bm{\hat{c}}}(\uvbp{a};\uvbp{c})&=0 \label{PDproof2}\\
P_{\lambda,\bm{\hat{c}},\bm{\hat{b}}}(\uvbp{c};\uvbp{b})&=0 \label{PDproof3}
 \end{align}
 We suppose that PI holds and we will try to arrive at a contradiction. If both Alice and Bob make their measurement in the $\bm{\hat{c}}$-direction, there there are two possibilities: either Alice measures $q_A$ to be in the state $\uvbm{c}$ and Bob measures $q_B$ to be in the state $\uvbp{c}$, or Alice measures $q_A$ to be in the state $\uvbp{c}$ and Bob measures $q_B$ to be in the state $\uvbm{c}.$ So expressed in terms of probabilities, these two possibilities are equivalent to either 
 \begin{equation}\label{PDproofcase1}
 P_{\lambda,\bm{\hat{c}},\bm{\hat{c}}}(\uvbm{c};\uvbp{c})=1 \qquad\text{and}\qquad  P_{\lambda,\bm{\hat{c}},\bm{\hat{c}}}(\uvbp{c};\uvbm{c})=0.
 \end{equation}
 or 
  \begin{equation}\label{PDproofcase2}
 P_{\lambda,\bm{\hat{c}},\bm{\hat{c}}}(\uvbp{c};\uvbm{c})=1 \qquad\text{and}\qquad P_{\lambda,\bm{\hat{c}},\bm{\hat{c}}}(\uvbm{c};\uvbp{c})=0
 \end{equation}
 Let's first consider case (\ref{PDproofcase1}). Note that
\begin{equation}
 P_{\lambda,\bm{\hat{c}},\bm{\hat{c}}}(\uvbp{c};\uvbm{c})+P_{\lambda,\bm{\hat{c}},\bm{\hat{c}}}(\uvbm{c};\uvbm{c})=0.
\end{equation}
 Therefore, since we are assuming PI, 
 \begin{equation}
 P_{\lambda,\bm{\hat{a}},\bm{\hat{c}}}(\uvbp{a};\uvbm{c})+P_{\lambda,\bm{\hat{a}},\bm{\hat{c}}}(\uvbm{a};\uvbm{c})=0.
\end{equation}
 In particular, 
  \begin{equation}\label{PDproof4}
  P_{\lambda,\bm{\hat{a}},\bm{\hat{c}}}(\uvbp{a};\uvbm{c})=0.
  \end{equation}
  But by (\ref{PDproof1}), we know that 
  \begin{equation}
  P_{\lambda,\bm{\hat{a}},\bm{\hat{b}}}(\uvbp{a};\uvbp{b})+P_{\lambda,\bm{\hat{a}},\bm{\hat{b}}}(\uvbp{a};\uvbm{b})=1,
  \end{equation}
  so using this together with PI, we must have
    \begin{equation}\label{PDproof5}
  P_{\lambda,\bm{\hat{a}},\bm{\hat{c}}}(\uvbp{a};\uvbp{c})+P_{\lambda,\bm{\hat{a}},\bm{\hat{c}}}(\uvbp{a};\uvbm{c})=1.
  \end{equation}
 But by (\ref{PDproof2}) and (\ref{PDproof4})
\begin{equation}\label{PDproof6}
  P_{\lambda,\bm{\hat{a}},\bm{\hat{c}}}(\uvbp{a};\uvbp{c})+P_{\lambda,\bm{\hat{a}},\bm{\hat{c}}}(\uvbp{a};\uvbm{c})=0.
\end{equation}
Since (\ref{PDproof5}) contradicts (\ref{PDproof6}), the assumption (\ref{PDproofcase1}) must be false if PI is to hold.

So we now consider the alternative case when (\ref{PDproofcase2}) holds. We will again see that this assumption leads to a contradiction. First note that
\begin{equation}
 P_{\lambda,\bm{\hat{c}},\bm{\hat{c}}}(\uvbm{c};\uvbp{c})+P_{\lambda,\bm{\hat{c}},\bm{\hat{c}}}(\uvbm{c};\uvbm{c})=0.
\end{equation}
 By PI
\begin{equation}
P_{\lambda,\bm{\hat{c}},\bm{\hat{b}}}(\uvbm{c};\uvbp{b})+P_{\lambda,\bm{\hat{c}},\bm{\hat{b}}}(\uvbm{c};\uvbm{b})=0.
\end{equation}
In particular, 
\begin{equation}\label{PDproof8}
P_{\lambda,\bm{\hat{c}},\bm{\hat{b}}}(\uvbm{c};\uvbp{b})=0.
\end{equation}
   But by (\ref{PDproof1}), we know that 
  \begin{equation}
  P_{\lambda,\bm{\hat{a}},\bm{\hat{b}}}(\uvbp{a};\uvbp{b})+P_{\lambda,\bm{\hat{a}},\bm{\hat{b}}}(\uvbm{a};\uvbp{b})=1.
  \end{equation}   
 so using this together with PI, we must have
    \begin{equation}\label{PDproof7}
  P_{\lambda,\bm{\hat{c}},\bm{\hat{b}}}(\uvbp{c};\uvbp{b})+P_{\lambda,\bm{\hat{c}},\bm{\hat{b}}}(\uvbm{c};\uvbp{b})=1.
  \end{equation} 
   But by (\ref{PDproof3}) and (\ref{PDproof8})
\begin{equation}\label{PDproof9}
 P_{\lambda,\bm{\hat{c}},\bm{\hat{b}}}(\uvbp{c};\uvbp{b})+P_{\lambda,\bm{\hat{c}},\bm{\hat{b}}}(\uvbm{c};\uvbp{b})=0.
\end{equation}
Since (\ref{PDproof7}) contradicts (\ref{PDproof9}), the assumption (\ref{PDproofcase2}) must also be false if PI is to hold. So we can only conclude that PI fails to hold in the pilot wave model.   But we can conclude even more than that: any deterministic hidden variable model that gives the same predictions as quantum mechanics when averaged over the hidden variables must violate PI. 

The violation of PI by the pilot wave model does not sit easily with Einstein's theory of relativity, for according to Einstein's theory, it should be impossible to send signals faster than the speed of light. However, if PI is violated, then if Alice happened to know what $\lambda$ was for each run of the experiment and if Bob made the same measurement, then because the distribution of Alice's outcomes will depend of Bob's choice of measurement, with enough runs of the experiment, Alice should be able to work out what measurement Bob is making. And this should be possible even if Alice and Bob are separated by many light years. So it seems faster than light communication would be possible. The only thing preventing such communication would be Alice's lack of knowledge of $\lambda$. 

But although a PI violation can account for the violation of Bell's Inequality, this is not the only possible culprit to consider. Another assumption of Bell's Inequality that might be violated is \textbf{Outcome Independence} (OI). Outcome independence is the assumption
\begin{equation}\label{OI}
P_{\lambda,x,y}(X,Y)=P_{A,\lambda,x,y}(X)\cdot P_{B,\lambda,x,y}(Y),
\end{equation}
We can see that if OI holds any model which gives the same predictions as standard quantum theory when averaged over the hidden variables, then PI must be violated in such a model. For if both PI and OI hold, then for any measurement choices $\vb{\hat{a}},$ $\vb{\hat{b}},$ and $\vb{\hat{c}}$ and hidden variable $\lambda$, we have
\begin{equation}\label{OIPI1}
\begin{split}
 P_{\lambda,\bm{\hat{a}},\bm{\hat{c}}}&(\uvbp{a};\uvbp{c})=P_{A,\lambda,\bm{\hat{a}},\bm{\hat{c}}}(\uvbp{a})\cdot P_{B,\lambda,\bm{\hat{c}},\bm{\hat{a}}}(\uvbp{c})\\
 &= \Big( P_{\lambda,\bm{\hat{a}},\bm{\hat{c}}}(\uvbp{a};\uvbp{c})+ P_{\lambda,\bm{\hat{a}},\bm{\hat{c}}}(\uvbp{a};\uvbm{c})\Big)\cdot\Big( P_{\lambda,\bm{\hat{a}},\bm{\hat{c}}}(\uvbp{a};\uvbp{c})+ P_{\lambda,\bm{\hat{a}},\bm{\hat{c}}}(\uvbm{a};\uvbp{c})\Big)\\
 &= \Big( P_{\lambda,\bm{\hat{a}},\bm{\hat{c}}}(\uvbp{a};\uvbp{c})+ P_{\lambda,\bm{\hat{a}},\bm{\hat{c}}}(\uvbp{a};\uvbm{c})\Big)\cdot\Big( \cancelto{0}{P_{\lambda,\bm{\hat{c}},\bm{\hat{c}}}(\uvbp{c};\uvbp{c})}+ P_{\lambda,\bm{\hat{c}},\bm{\hat{c}}}(\uvbm{c};\uvbp{c})\Big)\\
 &=\Big( P_{\lambda,\bm{\hat{a}},\bm{\hat{b}}}(\uvbp{a};\uvbp{b})+ P_{\lambda,\bm{\hat{a}},\bm{\hat{b}}}(\uvbp{a};\uvbm{b})\Big)\cdot P_{\lambda,\bm{\hat{c}},\bm{\hat{c}}}(\uvbm{c};\uvbp{c})\\
 &\geq P_{\lambda,\bm{\hat{a}},\bm{\hat{b}}}(\uvbp{a};\uvbp{b})\cdot P_{\lambda,\bm{\hat{c}},\bm{\hat{c}}}(\uvbm{c};\uvbp{c}) 
\end{split}
\end{equation}
Similarly, we have
\begin{equation}\label{OIPI2}
\begin{split}
 P_{\lambda,\bm{\hat{c}},\bm{\hat{b}}}&(\uvbp{c};\uvbp{b})=P_{A,\lambda,\bm{\hat{c}},\bm{\hat{b}}}(\uvbp{c})\cdot P_{B,\lambda,\bm{\hat{c}},\bm{\hat{b}}}(\uvbp{b})\\
 &= \Big( P_{\lambda,\bm{\hat{c}},\bm{\hat{b}}}(\uvbp{c};\uvbp{b})+ P_{\lambda,\bm{\hat{c}},\bm{\hat{b}}}(\uvbp{c};\uvbm{b})\Big)\cdot\Big( P_{\lambda,\bm{\hat{c}},\bm{\hat{b}}}(\uvbp{c};\uvbp{b})+ P_{\lambda,\bm{\hat{c}},\bm{\hat{b}}}(\uvbm{c};\uvbp{b})\Big)\\
 &= \Big(  \cancelto{0}{P_{\lambda,\bm{\hat{c}},\bm{\hat{c}}}(\uvbp{c};\uvbp{c})}+ P_{\lambda,\bm{\hat{c}},\bm{\hat{c}}}(\uvbp{c};\uvbm{c})\Big)\cdot\Big(P_{\lambda,\bm{\hat{c}},\bm{\hat{b}}}(\uvbp{c};\uvbp{b})+ P_{\lambda,\bm{\hat{c}},\bm{\hat{b}}}(\uvbm{c};\uvbp{b})\Big)\\
 &=P_{\lambda,\bm{\hat{c}},\bm{\hat{c}}}(\uvbp{c};\uvbm{c})\cdot\Big( P_{\lambda,\bm{\hat{a}},\bm{\hat{b}}}(\uvbp{a};\uvbp{b})+ P_{\lambda,\bm{\hat{a}},\bm{\hat{b}}}(\uvbm{a};\uvbp{b})\Big)\\
 &\geq P_{\lambda,\bm{\hat{c}},\bm{\hat{c}}}(\uvbp{c};\uvbm{c})\cdot P_{\lambda,\bm{\hat{a}},\bm{\hat{b}}}(\uvbp{a};\uvbp{b}) .
\end{split}
\end{equation}
But since the hidden variable $\lambda$ is assumed to be independent of Alice and Bob's measurement, and since Alice and Bob will always get opposite results when they make the same choice of measurement, it follows that 
\begin{equation}\label{OIPI3}
P_{\lambda,\bm{\hat{c}},\bm{\hat{c}}}(\uvbp{c};\uvbm{c})+P_{\lambda,\bm{\hat{c}},\bm{\hat{c}}}(\uvbm{c};\uvbp{c})=1
\end{equation}
Therefore, putting (\ref{OIPI1}), (\ref{OIPI2}), and (\ref{OIPI3}) together, we have
\begin{equation}
P_{\lambda,\bm{\hat{a}},\bm{\hat{c}}}(\uvbp{a};\uvbp{c})+P_{\lambda,\bm{\hat{c}},\bm{\hat{b}}}(\uvbp{c};\uvbp{b})\geq P_{\lambda,\bm{\hat{a}},\bm{\hat{b}}}(\uvbp{a};\uvbp{b}).
\end{equation}
We have thus proved that OI and PI implies Bell's Inequality (\ref{bellinequality}). But since Bell's Inequality does not hold in reality, it follows that if OI is always true, then PI must be violated.


In the case of deterministic models, OI necessarily holds. To see why, we first note that for deterministic models, either $P_{\lambda,x,y}(X,Y)=1$ or $P_{\lambda,x,y}(X,Y)=0$. When $P_{\lambda,x,y}(X,Y)=1$ by (\ref{PIone}), $P_{A, \lambda,x,y}(X)=1$, and by (\ref{PItwo}), $P_{B, \lambda,x,y}(Y)=1$, so (\ref{OI}) is seen to hold in this case. On the other hand, when $P_{\lambda,x,y}(X,Y)=0$,  if $P_{A, \lambda,x,y}(X)=1$, then by (\ref{PIone}), $P_{\lambda,x,y} (X,-Y)=1$ so that (\ref{PItwo}), $P_{B, \lambda,x,y}(Y)=0$ in which case (\ref{OI}) holds. And similarly, if $P_{B, \lambda,x,y}(Y)=1$, by (\ref{PItwo}), $P_{\lambda,x,y} (-X,Y)=1$ so that (\ref{PIone}), $P_{A, \lambda,x,y}(X)=0$ so again (\ref{OI}) holds. And (\ref{OI}) obviously holds when $P_{A, \lambda,x,y}(X)=P_{B, \lambda,x,y}(Y)=0$. It therefore follows that OI holds in any deterministic model.

When it comes to standard quantum mechanics, however, OI fails to hold. For instance, if $x=y=\vb{\hat{a}}$, then $P_{\lambda,\vb{\hat{a}},\vb{\hat{a}}}(\vb{\hat{a}+},\vb{\hat{a}+})=0,$ but $P_{A, \lambda,\vb{\hat{a}},\vb{\hat{a}}}(\vb{\hat{a}+})=P_{B, \lambda,\vb{\hat{a}},\vb{\hat{a}}}(\vb{\hat{a}+})=1/2.$\footnote{See footnote \ref{onehalf}. } Hence, OI fails. Nevertheless, as long as PI holds, the failure of OI does not enable Bob to send message to Alice faster than light because Bob only has control over the measurement he makes. Assuming Bob's mental states have no effect on the measurement outcome, there is nothing he can do to influence his outcome, so although Alice will be able to work out Bob's measurement outcome if she already happens to know which choice of measurement he has made, she will not be able to work out which Bob makes (or even whether he has made a measurement at all) by measuring the outcome of her particle. For Shimony\footnote{See \cite[146-147]{Shimony86}.} this inability to send superluminal messages between Alice and Bob when PI holds and OI is violate was deemed sufficient for the theories of standard quantum physics and special relativity to peacefully coexist. 

However, Butterfield is not satisfied with Shimony's solution to peaceful coexistence.\footnote{See \cite[p. 12]{Butterfield}.} Firstly, he notes that proofs of non-superluminal signaling\footnote{e.g. see \cite[p. 113--116]{Redhead}; \cite[p. 139--140]{Hiley}} make no assumptions about spacetime locations. One would have thought that any proof that superluminal signalling between two points is impossible would have to show that a signal cannot be transmitted from one point to the other in less time than the time it takes light to travel between the two points. But if nothing is said about the location of these two points or what is so special about the speed of light compared to the speed of any other particle, then there does not seem to be enough information in the premises to draw the desired conclusion superluminal signaling is impossible in quantum physics.

Secondly,  Butterfield notes that Shimony thinks peaceful coexistence of quantum physics and special relativity is guaranteed by the denial of OI and the acceptance of PI, but OI itself depends on the sometimes rather vague notion of what an outcome really is. For instance, in the Many-Worlds interpretation described in sections \ref{manyworldsinterpretation1} and \ref{manyworldsinterpretation2}, it is not clear that there are ever any outcomes at all. Rather, there is just a universal wavefunction that tells us the probability of a certain outcomes, if there were such things as outcomes -- it doesn't tell us that there really are any outcomes. But as we saw in the previous chapter, the Many-Worlds interpretation does flow rather naturally from the postulate of standard quantum theory. 

Still, the notion of what an outcome is doesn't have to be vague. In the pilot wave interpretation of quantum physics, it is very clear what an outcome of an experiment is since all the particles have definite positions and momenta, and so because of this the pointers and displays of measuring devices which are made up of particles will have definite read outs which will correspond to the definite positions of particles being measured (assuming the measurement is working properly). So unlike the Many-Worlds interpretation, measurements in the pilot-wave interpretation have definite outcomes, and hence there is only a single world in the pilot-wave interpretation of quantum physics. But as we've just seen, the problem with the pilot wave interpretation is the violation of PI.  

Thus, a satisfactory account of the peaceful coexistence of quantum physics and special relativity requires an interpretation of quantum physics in which not only PI holds, but also an interpretation of quantum physics that has special relativity built into it (thus satisfying Butterfield's first objection), and in which we can make sense of what it means to be an outcome (thus satisfying Butterfield's second objection). To fully address Butterfield's first objection would require quantum field theory and this would be beyond the scope of this dissertation. But a more modest aspiration that would go some way to address Butterfield's first objection would be to insist on an interpretation of quantum physics that has a property known as Lorentz invariance. Thus, in the next section, we will examine Kent's interpretation of quantum physics which we see has this property of Lorentz invariance and in which the notion of outcome has a clear meaning.

\section{A description of Kent's Interpretation of Quantum Physics}
In this section I will describe Kent's interpretation of quantum focusing on the ideas he presents in his 2014 paper.\footnote{\cite{Kent2014}.} Kent's interpretation of quantum physics has some similarities in common with the pilot wave interpretation. Firstly,  there is no wave-function collapse in Kent's interpretation. Secondly, some additional values beyond standard quantum orthodoxy (i.e. in addition to the quantum wave function) are included in Kent's interpretation. And thirdly, Kent's interpretation is a one-world interpretation of quantum physics. I'll consider these three features of Kent's interpretation in some detail as I describe his theory. I'll then present an account of his toy model that provides a simple example of how the ideas of his theory fit together. Then I'll show that Kent's interpretation is consistent with standard quantum theory, and I'll also show that it is consistent with special relativity. I'll then consider how Kent's interpretation ties in with decoherence theory and d'Espagnat's objection about improper mixtures. I'll then show that PI holds for Kent's interpretation, and I will show why Collbeck and Renner's theorem does not apply to Kent's interpretation. 

\subsection{The No-collapse Feature of Kent's Interpretation}
We first consider the no-collapse feature of Kent's interpretation. This is a feature that belongs both to the Many-World's interpretation as well as to the pilot wave interpretation. In all three interpretations the wave-function deterministically evolves according to the Schr\"{o}dinger equation. The Schr\"{o}dinger equation itself describes how a quantum state evolves over time. The precise formula for the Schr\"{o}dinger equation need not concern us here, but all we need to know is that the Schr\"{o}dinger equation determines a so-called \textbf{unitary operator} $U(t',t)$, so that if a system is in state $\ket{\psi}$ at time $t$, then it will be in state $\ket{\psi'}=U(t',t)\ket{\psi}$
at time $t'$. A unitary operator $U$ has the property that if $\ket{\psi'}=U\ket{\psi}$ and $\ket{\chi'}=U\ket{\chi}$, then 
\begin{equation}\label{unitarycond}
\ip{\chi'}{\psi'}=\ip{\chi}{\psi}.\protect\footnotemark
\end{equation}
\footnotetext{A unitary operator also has the property that it is invertible: there is an operator $U^{-1}$ such that $U U^{-1}$ and $U^{-1} U$ are the identity operator $I$, i.e. $U^{-1} U\ket{\psi}=UU^{-1}\ket{\psi}=\ket{\psi}$ for any state $\ket{\psi}$.}
In non-collapse models  such as the pilot-wave, the Many-World's, and Kent's interpretation, the wavefunction always evolves unitarily. In contrast,  in the Copenhagen interpretation, the state will evolve unitarily for the most part, but there will typically be a non-unitary change in the state whenever there is a measurement. To see why this is, we recall the situation described on page \pageref{span} where a state $\ket{\psi}$ is the sum of eigenstates $\ket{\psi_i}$ of an observable 
\begin{equation}\tag{\ref{span} revisited}
\ket{\psi}=\sum_{i=1}^N\alpha_i\ket{\psi_i}.
\end{equation}
If $\ket{\psi_i'}=U(t,t_0)\ket{\psi_i}$ and $\ket{\psi'}=U\ket{\psi}$, then the unitary condition (\ref{unitarycond}) implies that 
$\ip{\psi'_i}{\psi'}=\alpha_i$. But if on measurement at time $t$, the system collapses to the $\ket{\psi'_j}$ state for $j\neq i$ so that $\ket{\psi'}=\ket{\psi_j'},$ we will have $\ip{\psi'_i}{\psi'}=0$. So in the Copenhagen interpretation, the unitary condition (\ref{unitarycond})  will fail if $\alpha_i\neq 0$. 

\subsection{The Additional Values of Kent's Interpretation\label{additional}}
Secondly, like the pilot wave interpretation, some additional values beyond standard quantum orthodoxy (i.e. in addition to the quantum wave function) are included in Kent's interpretation. In the pilot wave interpretation, these additional values are the positions and momenta of all the particles, whereas in Kent's interpretation, the additional values specify the mass-energy density on a three-dimensional distant future hypersurface in space-time $S$. To understand the nature of this three-dimensional hyperspace, we recall that in special relativity, there is no such thing as absolute time. So for instance, two events (i.e. two points in space-time) might seem to be simultaneous from one frame of reference, but another person travelling at a different velocity would judge the same two events to be non-simultaneous. But it is not the case that for any two events we can find a frame of reference in which the two events are simultaneous. But we refer to events that could be simultaneous in some frame of references as being \textbf{spacelike separated}. The two points $O$ and $A$  in figure \ref{cone} are spacelike separated. 

\begin{figure}[!h]
\centering

 \tikzset{surface/.style={draw=blue!70!black, fill=yellow!20!white, fill opacity=.6}}

 \newcommand{\coneback}[4][]{
 \draw[canvas is xy plane at z=#2, #1] (45-#4:#3) arc (45-#4:225+#4:#3) -- (O) --cycle;
 }
 \newcommand{\conefront}[4][]{
 \draw[canvas is xy plane at z=#2, #1] (45-#4:#3) arc (45-#4:-135+#4:#3) -- (O) --cycle;
 }
 \begin{tikzpicture}[tdplot_main_coords, grid/.style={help lines,violet!40!white,opacity=0.5},scale=1.25]
  \coordinate (O) at (0,0,0);
  
     \coneback[surface]{-3}{2}{-12}
   \conefront[surface]{-3}{2}{-12} 
  
   \fill[brown!40!white,opacity=0.5] (-4,-4,0) -- (-4,4,0) -- (4,4,0) -- (4,-4,0) -- cycle;
  
   \foreach \x in {-4,...,4}
     \foreach \y in {-4,...,4}
     {
         \draw[grid] (\x,-4) -- (\x,4);
         \draw[grid] (-4,\y) -- (4,\y);
         \draw[violet] (-4,4)--(-4,-4)--(4,-4)--(4,4)--cycle;
     }

   \draw[->] (-4,0,0) -- (4,0,0) {};
   \draw[->] (0,-4,0) -- (0,4,0) {};
   \coneback[surface]{3}{2}{12}
   \draw[-,dashed] (0,0,-2.65) -- (0,0,2.65) node[above] {};
   \draw[-,dashed] (0,0,-4) -- (0,0,-3.35) node[above] {};
   \draw[->,dashed] (0,0,3.35) -- (0,0,4) node[above] {time};
   \conefront[surface]{3}{2}{12}

   \draw[red, thick] (0,0,0) -- (4,0,2) node[below, pos=0.6, rotate=26.5651,scale=0.80,black] {spacelike separated};
   \draw[red, thick] (0,0,0) -- (1.56,0.6,2.4) node[below, pos=0.62, rotate=55.1459,scale=0.80,black] {lightlike separated};
   \draw[red, thick] (0,0,0) -- (-0.5,-0.85,2.2) node[above, pos=0.57, rotate=-65.8557,scale=0.80,black] {timelike separated};
   \node[black] at (0,0,3) {Future Light Cone};
   \node[black] at (0,0,-3) {Past Light Cone};
   
   \fill (4,0,2) circle (2pt) node[above right] {$A$};
   \fill (0,0,0) circle (2pt) node[below ] {$O$};
   \fill (-0.5,-0.85,2.2) circle (2pt) node[above left] {$C$};
   \fill (1.56,0.6,2.4) circle (2pt) node[above left] {$B$};
  
   \node[black] at (0,4.7,0) {space};
   \node[black] at (5,-0.3,0) {space};
 \end{tikzpicture}
 \caption{The meaning of spacelike, timelike and lightlike separation when there are two space dimensions and one time dimension}
 \label{cone}
\end{figure}
There are also events in space-time that could be connected by a beam of light such as the two event $O$ and $B$ in figure \ref{cone}. Such events are referred to as being lightlike separated. For any given event, the events that are lightlike separated from it form two cone called the future light cone and the past light cone as shown in figure \ref{cone}. Because light appear to travel at the same speed no matter what frame of reference one uses, the light cone of an event remains invariant when one change from one reference frame to another. In other words if another event lies on the light cone of an event in one frame of reference, then it must lie on the light cone in every frame of reference. 

Figure \ref{cone} also depicts two events $O$ and $C$ that are timelike separated. Such events lie within the light cones of each other, and when two events are timelike separated, it is always possible to choose a frame of reference in which the two events are located at the same point in space, but with one event occuring after the other  depending on which event is  the future light cone of the other. 

Now a three-dimensional hypersurface $S$ in space-time is a three-dimensional surface in which all the events of $S$ are spacelike separated. Kent assumes that this hypersurface $S$ is in the distant future of an expanding universe so that all nearly all the particles that can decay have already done so, and that all the particles are very far from each other so that probability any particle collisions is very small. In other words, all the interesting physics in universe has played its course before $S$.

At every point of $x\in S$ there is a quantity $T_S(x)$ called the \label{massenergydensity}\textbf{mass-energy density}.\footnote{The definition of $T_S(x)$ will be discussed in section \ref{massenergydensity}.} The important thing to note about $T_S(x)$ is that it does not depend on which frame of reference one is in.\footnote{The reason for why this is will be discussed in section \ref{massenergydensity}.}
  This property is in contrast to many physical properties that do depend on which frame of reference one is in. For example, the kinetic energy of an object will depend on the calculated velocity of the object, and this velocity will depend on the frame of reference in which this calculation is done. 
  
Now according to the Tomogana-Schwinger formulation of relativistic quantum physics,\footnote{See \cite{SchwingerJulianI}; \cite{TomonagaI}} for any hypersurface $S$, there is a Hilbert space $H_S$ of states describing $S$. One of the properties of $H_S$ is that for any event $x\in S$ there is an observable $\hat{T}_S(x)$ acting on $H_S$ such that if  $\ket{\Psi}\in H_S$ is an eigenstate of  $\hat{T}_S(x)$  with eigenvalue $t(x)$, then $\ket{\Psi}$ corresponds to a state of $S$ in which the energy-density at $x$ is $t(x)$. This can be done in such a way that $\hat{T}_S(x)$ only depends on $x$ rather than on the hypersurface $S$ that contains $x$. Furthermore, if $x$ and $y$ are any two events of $S$, then the observables  $\hat{T}_S(x)$ and $\hat{T}_S(y)$ commute. In other words,
$$\hat{T}_S(x)\hat{T}_S(y)=\hat{T}_S(y)\hat{T}_S(x).$$
The commutativity of all the $\hat{T}_S(x)$ for $x\in S$ means that if $\ket{\Psi}$ is an eigenstate $\hat{T}_S(x)$, then for any $y\in S$, $\hat{T}_S(y)\ket{\Psi}$ is also an eigenstate of  $\hat{T}_S(x)$ with the same eigenvalue as $\ket{\Psi}$. The invariance of the $\hat{T}_S(x)$-eigenspace under the action of   $\hat{T}_S(y)$ means that we can create simultaneous eigenstates for both  $\hat{T}_S(x)$ and  $\hat{T}_S(y)$, albeit with different eigenvalues. But because $x$ and $y$ are arbitrary points of $S$, this means that we can express any state $H_S$ as a superposition of simultaneous $\hat{T}_S$-eigenstates of the form $\ket{\Psi^{(i)}}$ where
  $\hat{T}_S(x)\ket{\Psi^{(i)}}=t^{(i)}_S(x)\ket{\Psi^{(i)}}$ for all $x\in S$ where $t^{(i)}_S(x)\geq 0$ is a possible energy-density measurement over the whole of $S$.\footnote{We will gloss over \label{glosssim}the details of how to make this rigorous for continuous variables $x$ and continuous indices $i$. It is sufficient to approximate to the desired level of accuracy the continuous variables and indices as discrete variables and indices when thinking about the simultaneous $\hat{T}_S(x)$-eigenspaces.}\label{simultaneous}
  
The additional values beyond standard quantum orthodoxy that are included in Kent's interpretation are given by one of these possible outcomes for an energy-density measurement over the whole of $S$. We will denote this outcome as $\tau_S(x)$ and we will let $\ket{\Psi}$ be the state such that $\hat{T}_S(x)\ket{\Psi}=\tau_S(x)\ket{\Psi}.$ But although we speak of the measurement of $T_S(x)$ over $S$ as being $\tau_S(x)$, this is only a notional measurement. Thus, we speak of measurement of  $T_S(x)$ on $S$ only to mean that the state describing $S$ goes from a state in which $T_S(x)$ is indeterminate to a state in which $T_S(x)$ is determinate, i.e. to an $\hat{T}_S(x)$-eigenstate for every $x\in S$ with corresponding eigenvalue $\tau_S(x)$. How this determination comes about is up to one's philosophical preferences. For example, one could suppose that it was simply by divine fiat that this determination  of $T_S(x)$ came about.\footnote{I will discuss my philosophical preference in the final chapter.} 

Nevertheless, the particular density $\tau_S(x)$ which is found to describe $S$ can't be absolutely anything. Rather, we suppose there is a much earlier hypersurface $S_0$ which is described by a state $\ket{\Psi_0}$ belonging to a Hilbert space $H_{S_0}$ as shown in figure \ref{S1}.  It is assumed that all physics that we wish to describe takes place between these two hypersurfaces $S_0$ and $S$. In figure \ref{S1}, we therefore let $y$ depicts a generic event that we wish to describe. 
 \begin{figure}[ht!]
\captionsetup{justification=justified}
\centering

\tikzmath{
\a= 1;  
\h=-1;
\md = (\a+\h)/2;
\lrange = 4;
\rrange=2;
\fictlabel=(\rrange-\lrange)/2;
\tlen=0.75;
\labelpos=(-\lrange-\a)/2;
} 

\begin{tikzpicture}[thick, scale=2]
\def\dotsize{0.7}
\definecolor{tempcolor}{RGB}{0,151,76}
\draw[<->] (-\lrange, \h) node[left] {$S_0$} -- (\rrange, \h) node[right] {$S_0$};
\draw[<->](-\lrange, \a) node[left] {$S$} --  (\rrange, \a)  node[right] {$S$};                   
\draw[->] (\rrange,\md-\tlen/2) --  (\rrange,\md+\tlen/2) node[midway,right]{time}; 
\coordinate[label = above: Notional Measurement of $T_S(x)$ on $S$]  (D) at (\fictlabel,\a+0.2); 
\node (start) at (\labelpos,\h) [below] {Initial State $\ket{\Psi_0}$};
\node (final) at (\labelpos,\a) [below] {Unitary Evolution $U_{SS_0}\ket{\Psi_0}$};
\draw [->, shorten <= 5pt] (start) [above] -- (final); 
\filldraw (0,0) circle (\dotsize pt) node [below right] {$y$} ;
\end{tikzpicture}

\vspace*{2px}
\caption{A notional measurement of $T_S(x)$ is made for all $x\in S$. The simultaneous  $\hat{T}_S$-eigenstate $\ket{\Psi}$ with $\hat{T}_S(x)\ket{\Psi}=\tau_S(x)\ket{\Psi}$ is selected with probability $\abs{\mel{\Psi}{U_{SS_0}}{\Psi_0}}^2$. The values $\tau_S(x)$ obtained for $T_S(x)$ are then used to calculate the physical properties at the event $y$.  }
\label{S1}
\end{figure} 
\vspace*{-12px}

 Now according to Schwinger\footnote{\cite[p.1459]{SchwingerJulianI}} there is a unitary operator  $U_{SS_0}$ that maps states in $H_{S_0}$ such as $\ket{\Psi_0}$ to states in $H_S$. Then the probability $P(\Psi|\Psi_0)$ that  $S$ will be found to be in the state $\ket{\Psi}$ with mass-energy density $\tau_S(x)$ given that $S_0$ was initially in the state $\ket{\Psi_0}$ will be given by the Born rule (see page \pageref{bornrule}):
 \begin{equation}\label{bornpsi}
 P(\Psi|\Psi_0) = \abs{\mel{\Psi}{U_{SS_0}}{\Psi_0}}^2
 \end{equation}
It's possible that there might be several different states of $H_S$ that have the same mass-energy density $\tau_S(x)$, but one of these states is still realized with probability given by equation (\ref{bornpsi}). But it is $\tau_S(x)$ rather than one of the eigenstates with mass-energy density $\tau_S(x)$ that constitute the additional values that Kent adds to standard quantum orthodoxy. 

\subsection{The One-World Feature of Kent's Interpretation}
The third similarity Kent's interpretation shares with the pilot wave interpretation is that it is a one-world interpretation of quantum physics. So unlike the Many-Worlds interpretation there are no superpositions of living and dead cats in Kent's interpretation. In the Many-Worlds interpretation, Schr\"{o}dinger still only observes his cat to be either dead or alive, and both dead and alive, but Schr\"{o}dinger himself goes into a superposition of observing his cat to be alive and his cat to be dead. In the Many-Worlds interpretation, there is thus a difference between observing something to be so and something actually being so: observation is a particular outcome, but the reality is a superposition of different outcomes. To capture this distinction, Bell speaks of \textbf{beables}. Bell introduces the term beable when speculating on what would be a more satisfactory physical theory than quantum physics currently has to offer.\footnote{See \cite{Bell2}} Bell says that such a theory should be able to say of a system not only such and such is observed to be so, but that such and such be so. In other words, such a theory is a theory of beables rather than observables. On the macroscopic level, these beables should be the underlying reality that give rise to all the familiar things in the world around us, things like cats, laboratories, procedures, and so on. In the pilot wave interpretation, the beables are all the particles with their precise position and momentum. It is because of such beables, that a scientist can observe a physical system to be in such and such a state, and so observables are made out of beables.   

Now the beables in Kent's one world interpretation are expressed in terms of a physical quantity called the \textbf{stress-energy tensor}  $T^{\mu\nu}(y)$.\label{stressenergy}  For any event $y$ in spacetime, the stress-energy tensor $T^{\mu\nu}(y)$ is an array of 16 values corresponding to each combination of $\mu, \nu=0,1,2,$ or $3$. The value $T^{00}(y)$ is the energy density at $y$,\footnote{This is not to be confused with the mass-energy density $T_S(x)$ defined for $x$ on a hypersurface $S$. As will be shown in section \ref{massenergydensity},  typically all 16 elements of $T^{\mu\nu}(x)$ will be needed to calculate $T_S(x)$.} whereas the other values of $T^{\mu\nu}(y)$ indicate how much energy and momentum flow across different surfaces in the neighborhood of $y$. 

It was mentioned in the previous section that for any event $x\in S$, there is an observable $\hat{T}_S(x)$ acting on $H_S$. It turns out that for any $\mu, \nu=0,1,2,$ or $3$, there is also an observable  $\hat{T}^{\mu\nu}(x)$ acting on $H_S$, such that if $\ket{\Psi}\in H_S$ is an eigenstate of $\hat{T}_S(x)$ with eigenvalue $\tau^{\mu\nu}(x)$, then $\ket{\Psi}$ corresponds to a state of $S$ in which the $T^{\mu\nu}(x)$ is  $\tau^{\mu\nu}(x)$. Moreover, the observable $\hat{T}_S(x)$ is expressible in terms of the  $\hat{T}^{\mu\nu}(x)$-observables.\footnote{See section  \ref{massenergydensity}.} 

Now the beables in Kent's interpretation are defined at each event $y$ that occurs after $S_0$ and before $S$. For such an event $y$, the beables will be determinate values of the stress-energy tensor $T^{\mu\nu}(y)$, but calculated from the the expectation of the observable $\hat{T}^{\mu\nu}(y)$ conditional on the energy-density on $S$ being given by $\tau_S(x)$ for all $x$ outside the lightcone of $y$. To explain what this means in more detail, recall the definition of expectation in equation (\ref{expectation2}) and the expectation formula (\ref{evev}) for an observable. If the beable in question was simply the expectation of $\hat{T}^{\mu\nu}(y)$ without conditioning on the value of the energy-density on $S$, the $T^{\mu\nu}(y)$-beable would just be $\ev*{\hat{T}^{\mu\nu}(y)}{\Psi'}$ where $\ket{\Psi'}=U_{S'S_0}\ket{\Psi_0}$ for any hypersurface $S'$ that goes through $y$.\footnote{This can be done such that $\ev*{\hat{T}^{\mu\nu}(y)}{\Psi'}$ does not depend on the hypersurface $S'$ other than the fact that it contains $y$. For more details see \cite{SchwingerJulianI}.} However, such a beable would give a description of reality that was very different from what we observe -- for instance, in a Schr\"{o}dinger cat-like experiment, there would be energy-densities corresponding to both the cat being alive and the cat being dead in the same world. To overcome this defect, information about the mass-energy density on $S$ is required, specifically the values of $\tau_S(x)$ for $x\in S^1(y)$ where  $S^1(y)$ consists of all the events of $S$ outside of the lightcone of $y$ as depicted in figure \ref{S2}.  



 \begin{figure}[ht!]
\captionsetup{justification=justified}
\centering

\tikzmath{
\a= 1;  
\e = 0.1;
\h=-1;
\hae=(3*\a*\a+6*\a*\e+7*\e*\e-3*\a*sqrt(\a*\a+4*\e*\e)-4*\e*sqrt(\a*\a+4\e*\e))/(4*\a+4*\e-2*sqrt(\a*\a+4*\e*\e));
\hae=0.0463647;
\hae=0.0858615;
\circsize=1.2;
\md = (\a+\h)/2;
\lrange = 4;
\rrange=2;
\ss=(-\lrange-\a)/2;
\sss=\a+(\rrange-\a)/2;
\tlen=0.75;
\labelpos=(-\lrange-\a)/2;
} 

\begin{tikzpicture}[thick, scale=2]

\def\dotsize{0.7}

\definecolor{tempcolor}{RGB}{0,151,76}
\draw[<->] (-\lrange, \h) node[left] {$S_0$} -- (\rrange, \h) node[right] {$S_0$};
\filldraw (0,0) circle (\dotsize pt) node [below right] {$y$} ;
              


\draw[<-] (-\lrange, \a)  -- (-\a, \a)  {};
\draw[gray, dotted] (-\a, \a) -- (0,0) {};
\draw[gray, dotted](0,0) -- (\a, \a) {};
\draw[->](\a, \a) --  (\rrange, \a)  ;         
\coordinate (B) at (\a,\a);
\node at (B)[red,circle,fill,inner sep=\circsize pt]{};
\coordinate (A) at (-\a,\a);
\node at (A)[red,circle,fill,inner sep=\circsize pt]{};
\coordinate (C) at (0,0);
\node at (C)[black,circle,fill,inner sep=\circsize pt]{};



\coordinate[label = above:$S^1(y)$]  (D) at (\ss,\a);
\coordinate[label = above:$S^1(y)$]  (D) at (\sss,\a);

\draw[->] (\rrange,\md-\tlen/2) --  (\rrange,\md+\tlen/2) node[midway,right]{time}; 
 
\node (start) at (\labelpos,\h) [below] {Initial State $\ket{\Psi_0}$};
\node (evolution) at (\labelpos,\md+0.05) [below] {Unitary Evolution $U_{S'S_0}\ket{\Psi_0}$};
\node (final) at (\labelpos,\a) [below] {Unitary Evolution $U_{SS_0}\ket{\Psi_0}$};
%\node at (-\ss+0.17,\mn-0.18){$-a_0$};
\draw [->, shorten <= 5pt] (start) [above] -- (evolution); 
\draw [->] (evolution) -- (final); 
\end{tikzpicture}

\vspace*{2px}
\caption{The set $S^1(y)$ consists of all the events of $S$ outside of the lightcone of $y$. The $T^{\mu\nu}(y)$-beables are calculated using the initial state $\ket{\Psi_0}$ together with the values of $\tau_S(x)$ for $x\in S^1(y)$. }
\label{S2}
\end{figure}


The conditional expectation we need to calculate depends on the notion of \textbf{conditional probability}. In probability theory, the conditional probability $P(q|r)$ that a statement $q$ is true given that a statement $r$ is given by the formula
$$ P(q|r)=\frac{P(q\& r)}{P(r)}. $$
If we now define $q(\kappa)$ to be the statement that some quantity $K$  takes the value $\kappa$. Then the  \textbf{conditional expectation} of  $K$ given $r$ will be given by the formula
\begin{equation}\label{conditionalexpectation}
\ev*{K}_r\myeq\sum_\kappa  \frac{P(q(\kappa),r)\kappa}{P(r)}
\end{equation}
where the summation is over all the possible values $\kappa$ that $K$ can take.

If we let $\ev*{T^{\mu\nu}(y)}_{\tau_S}$ stand for Kent's $T^{\mu\nu}(y)$-beable, then this can be calculated from (\ref{conditionalexpectation}) by taking $r$ to be the statement that 
 $T_S(x)=\tau_S(x)$ for all $x\in S^1(y)$, and $q(\tau)$ to be the statement that the universe is found to be in a quantum eigenstate of the observable $\hat{T}^{\mu\nu}(y)$ with eigenvalue $\tau$. It is these $T^{\mu\nu}(y)$-beables that give a one-world picture of reality.
 
\subsection{Kent's toy example}\label{toysection}
To get a feel for how all the elements of Kent's interpretation fit together, it is helpful to consider his toy model example that he discusses in his 2014 paper.\footnote{See \cite[p.3--4]{Kent2014}.} In his toy model, Kent considers a system in one spatial dimension which is the superposition of two localized states $\psi_0^\text{sys}=a \psi_1^\text{sys}+b\psi_2^\text{sys}$ where $\psi_1^\text{sys}$ is localized at $x_1$, $\psi_2^\text{sys}$ is localized at $x_2$, and $\abs{a}^2+\abs{b}^2=1$. According to the Copenhagen interpretation, a measurement on this system would collapse the wavefunction of $\psi_0^\text{sys}$ to the wavefunction of $\psi_1^\text{sys}$ with probability $\abs{a}^2$, and to the wavefunction of $\psi_2^\text{sys}$ with probability $\abs{b}^2$. The purpose of Kent's toy model is to show that within his interpretation, there is something analogous to wavefunction collapse.  In order for this ``collapse'' to happen, one needs to consider how the system interacts with light. Thus Kent supposes that a photon (which is modelled as a point particle) comes in from the left, and as it interacts with the two states $\psi_1^\text{sys}$ and $\psi_2^\text{sys}$, the photon enters in a superposition of states, corresponding to whether the photon reflects off the localized $\psi_1^\text{sys}$-state at time $t_1$ or the localized $\psi_2^\text{sys}$-state at time $t_2$. The photon in superposition then travels to the right and eventually reaches the one dimensional hypersurface $S$ at locations $\gamma_1$ and $\gamma_2$ as shown in figure  \ref{TM1}.

 \begin{figure}[ht!]
\captionsetup{justification=justified}
\centering
\tikzmath{
\a=5.3;  
\psione=0;
\psitwo=1;
\e = 0.1;
\h=-0.8;
\phstartx=-2.9;
\phstarty=-.8;
\tbeg=\phstarty;
\ca=\phstartx-\tbeg;
\ttwo=\psitwo-\ca;
\cb=\ttwo+\ca;
\xend=\ttwo-\a+\cb;
\tone=\psione-\ca;
\cc=\tone+\ca;
\xendz=\tone-\a+\cc;
\tthree=\cc+\tone-\psitwo;
\circsize=0.05;
\md = (\a+\h)/2;
\tlen=0.75;
\textscale = 0.8;
\picscale = 0.95;
\nudge=0.1;
\tnudge=(\ttwo-\tone)/2;
\ttesta=2*\tone-\ttwo-\tnudge;
\ttestb=2*\tone-\ttwo+\tnudge;
\ttestc=\ttwo-\tnudge;
\ttestd=\ttwo+\tnudge;
\sonea=\a+\psione-\ttesta;
\sadd=0.5;
\lrange = -(\psione-\a+\ttesta)+\sadd;
\rrange =\a+\psitwo-\ttesta+\sadd; 
\timex=\rrange-0.7;
} 
\begin{tikzpicture}[scale=1.2,
declare function={
	testxonep(\ps,\t)=\a+\ps-\t;
	testxonem(\ps,\t)=\ps-\a+\t; 
},
 ] 

\definecolor{tempcolor}{RGB}{250,190,0}
\definecolor{darkgreen}{RGB}{40,190,40}
\draw[<->] (-\lrange, \h) node[left, scale=\textscale] {$S_0$} -- (\rrange, \h) node[right, scale=\textscale] {$S_0$};
\draw[<->] (-\lrange, \a) node[left, scale=\textscale] {$S$} -- (\rrange, \a) node[right, scale=\textscale] {$S$};

              
\draw[->, shorten <= 5pt,  shorten >= 1pt] (\psione,\h) node[below, scale=\textscale]{$\psi_1^{\text{sys}}$} node[above left, scale=\textscale]{$Z=z_1$}-- (\psione,\a);
\draw[->,  shorten <= 5pt,  shorten >= 1pt] (\psitwo,\h) node[below, scale=\textscale]{$\psi_2^{\text{sys}}$} node[above right, scale=\textscale]{$Z=z_2$}-- (\psitwo,\a);

\draw[dashed, tempcolor, ultra thick](\phstartx,\tbeg) node[below left=-2,scale=\textscale]{}--(\psitwo,\ttwo ) node[above, pos=0.3, rotate=45,scale=0.7,black] {$Z=c(t-t_1)+z_1$} node[below, pos=0.3, rotate=45,scale=0.7,black] {photon};
\draw[dashed, tempcolor, ultra thick](\psitwo,\ttwo)--(\xend,\a) node[above, pos=0.48, rotate=-45,scale=0.7,black] {$Z=c(t_2-t)+z_2$} ;
\draw[dashed, tempcolor, ultra thick](\psione,\tone)--(\xendz,\a)node[above, pos=0.45, rotate=-45,scale=0.7,black] {$Z=c(t_1-t)+z_1$} ;

\draw [black,fill] (\xendz,\a) circle [radius=\circsize] node [black,above,scale=\textscale] {$\gamma_1$}; 
\draw [black,fill] (\xend,\a) circle [radius=\circsize] node [black,above,scale=\textscale] {$\gamma_2$}; 
%\draw[dashed, darkgreen, ultra thick](\psione,\tone)--(\psitwo,\tthree);
%\draw [black,fill] (\psitwo,\tthree) circle [radius=\circsize] node [black,below=4,right,scale=\textscale] {$t=2t_1-t_2$}; 


\draw [black,fill] (\psione,\tone) circle [radius=\circsize] node [black,left=4,scale=\textscale] {$t_1$}; 
\draw [black,fill](\psitwo,\ttwo)circle [radius=\circsize] node [black,right,scale=\textscale, align=left] {$t_2=t_1+\frac{z_2-z_1}{c}$.}; 

%\draw [decorate, decoration = {calligraphic brace}] (\psitwo+\nudge,\ttwo) --  (\psitwo+\nudge,\tone+\nudge/4) node[midway,right, scale=\textscale]{$t_2-t_1$}; 
%\draw [decorate, decoration = {calligraphic brace}] (\psitwo+\nudge,\tone-\nudge/4) --  (\psitwo+\nudge,2*\tone-\ttwo) node[midway,right, scale=\textscale]{$t_2-t_1$}; 

\draw[->] (\timex,\md-\tlen/2) --  (\timex,\md+\tlen/2) node[midway,right, scale=\textscale]{time}; 
 
%\draw[dotted](\psione,\ttesta)--({testxonep(\psione,\ttesta)},\a);
%\draw[dotted](\psione,\ttesta)--({testxonem(\psione,\ttesta)},\a);
%\draw [black,fill](\psione,\ttesta) circle [radius=\circsize] node [black,below=5,right,scale=\textscale] {$y_a$}; 

%\draw[magenta,->,ultra thick] ({testxonem(\psione,\ttesta)},\a)--(-\lrange,\a);
%\draw[magenta,->,ultra thick] ({testxonep(\psione,\ttesta)},\a)--(\rrange,\a);

\end{tikzpicture}% pic 1

\vspace*{2px}
\caption{Kent's toy model}
\label{TM1}
\end{figure}
We now suppose that when the mass-energy density $S$ is ``measured'' the energy of the photon is found to be at $\gamma_1$ rather than at $\gamma_2$. We then consider the mass-density at early spacetime locations $y^a_1=(z_1,t_d)$ and $y^a_2=(z_2,t_d)$ as show in figure \ref{TM2} (a) and (b). 
 
 
  \begin{figure}[ht!]
\captionsetup{justification=justified}
\centering
\tikzmath{
\a=5.3;  
\psione=0;
\psitwo=1;
\e = 0.1;
\h=-0.8;
\labelx=(\psione+\psitwo)/2;
\labely=-1.5;
\phstartx=-2.9;
\phstarty=-.8;
\tbeg=\phstarty;
\ca=\phstartx-\tbeg;
\ttwo=\psitwo-\ca;
\cb=\ttwo+\ca;
\xend=\ttwo-\a+\cb;
\tone=\psione-\ca;
\cc=\tone+\ca;
\xendz=\tone-\a+\cc;
\tthree=\cc+\tone-\psitwo;
\circsize=0.08;
\md = (\a+\h)/2;
\tlen=0.75;
\textscale = 0.7;
\picscale = 0.59;
\nudge=0.1;
\tnudge=(\ttwo-\tone)/2;
\ttesta=2*\tone-\ttwo-\tnudge;
\ttestb=2*\tone-\ttwo+\tnudge;
\ttestc=\ttwo-\tnudge;
\ttestd=\ttwo+\tnudge;
\sonea=\a+\psione-\ttesta;
\sadd=0.5;
\lrange = -(\psione-\a+\ttesta)+\sadd;
\rrange =\a+\psitwo-\ttesta+\sadd; 
\timex=\rrange-1.5;
} 
\begin{tikzpicture}[scale=\picscale,
declare function={
	testxonep(\ps,\t)=\a+\ps-\t;
	testxonem(\ps,\t)=\ps-\a+\t; 
},
 ] 
\definecolor{tempcolor}{RGB}{250,190,0}
\definecolor{darkgreen}{RGB}{40,190,40}
\draw[<->] (-\lrange, \h) node[left, scale=\textscale] {$S_0$} -- (\rrange, \h) node[right, scale=\textscale] {$S_0$};
\draw[<->] (-\lrange, \a) node[left, scale=\textscale] {$S$} -- (\rrange, \a) node[right, scale=\textscale] {$S$};
              
\draw[->, shorten <= 5pt,  shorten >= 1pt] (\psione,\h) node[below, scale=\textscale]{$\psi_1^{\text{sys}}$} node[above left, scale=\textscale]{$z_1$}-- (\psione,\a);
\coordinate[label = below: (a)]  (D) at (\labelx,\labely); 
\draw[->,  shorten <= 5pt,  shorten >= 1pt] (\psitwo,\h) node[below, scale=\textscale]{$\psi_2^{\text{sys}}$} node[above right, scale=\textscale]{$z_2$}-- (\psitwo,\a);

\draw[dashed, tempcolor, ultra thick](\phstartx,\tbeg) node[below left=-2,scale=\textscale]{}--(\psione,\tone) node[above, pos=0.3, rotate=45,scale=0.7,black] {} node[below, pos=0.3, rotate=45,scale=0.7,black] {};
\draw[dashed, gray](\psione,\tone) node[below left=-2,scale=\textscale]{}--(\psitwo,\ttwo );
\draw[dashed, gray](\psitwo,\ttwo)--(\xend,\a); 
\draw[dashed, tempcolor, ultra thick](\psione,\tone)--(\xendz,\a);

\draw [black,fill] (\xendz,\a) circle [radius=\circsize] node [black,above,scale=\textscale] {$\gamma_1$}; 

\draw[dashed, darkgreen, ultra thick](\psione,\tone)--(\psitwo,\tthree);
\draw [black,fill] (\psitwo,\tthree) circle [radius=\circsize] node [black,below=4,right,scale=\textscale] {$2t_1-t_2$}; 


\draw [black,fill] (\psione,\tone) circle [radius=\circsize] node [black,left=4,scale=\textscale] {$t_1$}; 
\draw [black,fill](\psitwo,\ttwo)circle [radius=\circsize] node [black,above right,scale=\textscale, align=left] {$t_2$}; 

\draw [decorate, decoration = {calligraphic brace}] (\psitwo+\nudge,\ttwo) --  (\psitwo+\nudge,\tone+\nudge/4) node[midway,right, scale=\textscale]{$t_2-t_1$}; 
\draw [decorate, decoration = {calligraphic brace}] (\psitwo+\nudge,\tone-\nudge/4) --  (\psitwo+\nudge,2*\tone-\ttwo) node[midway,right, scale=\textscale]{$t_2-t_1$}; 

\draw[->] (\timex,\md-\tlen/2) --  (\timex,\md+\tlen/2) node[midway,right, scale=\textscale]{time}; 
 
\draw[dotted](\psione,\ttesta)--({testxonep(\psione,\ttesta)},\a);
\draw[dotted](\psione,\ttesta)--({testxonem(\psione,\ttesta)},\a);
\draw [black,fill](\psione,\ttesta) circle [radius=\circsize] node [black,below=5,right,scale=\textscale] {$y^a_1$}; 

\draw[magenta,->,ultra thick] ({testxonem(\psione,\ttesta)},\a)--(-\lrange,\a);
\draw[magenta,->,ultra thick] ({testxonep(\psione,\ttesta)},\a)--(\rrange,\a);

\end{tikzpicture}% pic 1
 % <----------------- SPACE BETWEEN PICTURES
\begin{tikzpicture}[scale=\picscale,  %[x={10.0pt},y={10.0pt}]
declare function={
	testxonep(\ps,\t)=\a+\ps-\t;
	testxonem(\ps,\t)=\ps-\a+\t; 
},
 ] 
\definecolor{tempcolor}{RGB}{250,190,0}
\definecolor{darkgreen}{RGB}{40,190,40}
\draw[<->] (-\lrange, \h) node[left, scale=\textscale] {$S_0$} -- (\rrange, \h) node[right, scale=\textscale] {$S_0$};
\draw[<->] (-\lrange, \a) node[left, scale=\textscale] {$S$} -- (\rrange, \a) node[right, scale=\textscale] {$S$};
              
\draw[->, shorten <= 5pt,  shorten >= 1pt] (\psione,\h) node[below, scale=\textscale]{$\psi_1^{\text{sys}}$} node[above left, scale=\textscale]{$z_1$}-- (\psione,\a);
\coordinate[label = below: (b)]  (D) at (\labelx,\labely); 
\draw[->,  shorten <= 5pt,  shorten >= 1pt] (\psitwo,\h) node[below, scale=\textscale]{$\psi_2^{\text{sys}}$} node[above right, scale=\textscale]{$z_2$}-- (\psitwo,\a);

\draw[dashed, tempcolor, ultra thick](\phstartx,\tbeg) node[below left=-2,scale=\textscale]{}--(\psione,\tone) node[above, pos=0.3, rotate=45,scale=0.7,black] {} node[below, pos=0.3, rotate=45,scale=0.7,black] {};
\draw[dashed, gray](\psione,\tone) node[below left=-2,scale=\textscale]{}--(\psitwo,\ttwo );
\draw[dashed, gray](\psitwo,\ttwo)--(\xend,\a); 
\draw[dashed, tempcolor, ultra thick](\psione,\tone)--(\xendz,\a);

\draw [black,fill] (\xendz,\a) circle [radius=\circsize] node [black,above,scale=\textscale] {$\gamma_1$}; 

\draw[dashed, darkgreen, ultra thick](\psione,\tone)--(\psitwo,\tthree);
\draw [black,fill] (\psitwo,\tthree) circle [radius=\circsize] node [black,below=4,right,scale=\textscale] {$2t_1-t_2$}; 


\draw [black,fill] (\psione,\tone) circle [radius=\circsize] node [black,left=4,scale=\textscale] {$t_1$}; 
\draw [black,fill](\psitwo,\ttwo)circle [radius=\circsize] node [black,above right,scale=\textscale, align=left] {$t_2$}; 

\draw [decorate, decoration = {calligraphic brace}] (\psitwo+\nudge,\ttwo) --  (\psitwo+\nudge,\tone+\nudge/4) node[midway,right, scale=\textscale]{$t_2-t_1$}; 
\draw [decorate, decoration = {calligraphic brace}] (\psitwo+\nudge,\tone-\nudge/4) --  (\psitwo+\nudge,2*\tone-\ttwo) node[midway,right, scale=\textscale]{$t_2-t_1$}; 

\draw[->] (\timex,\md-\tlen/2) --  (\timex,\md+\tlen/2) node[midway,right, scale=\textscale]{time}; 
 
\draw[dotted](\psitwo,\ttesta)--({testxonep(\psitwo,\ttesta)},\a);
\draw[dotted](\psitwo,\ttesta)--({testxonem(\psitwo,\ttesta)},\a);
\draw [black,fill](\psitwo,\ttesta) circle [radius=\circsize] node [black,below=5,right,scale=\textscale] {$y^a_2$}; 

\draw[magenta,->,ultra thick] ({testxonem(\psitwo,\ttesta)},\a)--(-\lrange,\a);
\draw[magenta,->,ultra thick] ({testxonep(\psitwo,\ttesta)},\a)--(\rrange,\a);


\end{tikzpicture}% pic 1


\vspace*{2px}
\caption{(a) highlights the part of $S$ used to calculate the energy density at $y^a_1$ whose time is less than $2t_1-t_2$. (b) highlights the part of $S$ used to calculate the energy density at $y^a_2$ whose time is greater less $2t_1-t_2$.}
\label{TM2}
\end{figure}

By early, we mean that $t_d<2t_1-t_2$. This will mean that the possible detection locations $\gamma_1$ and $\gamma_2$ will be outside the forward light cones of $y^a_1$ and $y^a_2$. Hence $S^1(y^a_1)\cap S$ and $S^1(y^a_2)\cap S$  contain no additional information beyond orthodox quantum theory by which we could calculate the conditional expectation values of the energy at $y^a_1$  and $y^a_2$. Hence, according to Kent's interpretation, the total energy will be divided between the two locations with a proportion of $\abs{a}^2$ at $y^a_1$  and a proportion of $\abs{b}^2$ at $y^a_2$.

However, the situation is different for two events slightly after $2t_1-t_2$ as depicted in figure \ref{TM3}.

\begin{figure}[ht!]
\captionsetup{justification=justified}
\centering
\tikzmath{
\a=5.3;  
\psione=0;
\psitwo=1;
\e = 0.1;
\h=-0.8;
\labelx=(\psione+\psitwo)/2;
\labely=-1.5;
\phstartx=-2.9;
\phstarty=-.8;
\tbeg=\phstarty;
\ca=\phstartx-\tbeg;
\ttwo=\psitwo-\ca;
\cb=\ttwo+\ca;
\xend=\ttwo-\a+\cb;
\tone=\psione-\ca;
\cc=\tone+\ca;
\xendz=\tone-\a+\cc;
\tthree=\cc+\tone-\psitwo;
\circsize=0.08;
\md = (\a+\h)/2;
\tlen=0.75;
\textscale = 0.7;
\picscale = 0.59;
\nudge=0.1;
\tnudge=(\ttwo-\tone)/2;
\ttesta=2*\tone-\ttwo-\tnudge;
\ttestb=2*\tone-\ttwo+\tnudge;
\ttestc=\ttwo-\tnudge;
\ttestd=\ttwo+\tnudge;
\sonea=\a+\psione-\ttesta;
\sadd=0.5;
\lrange = -(\psione-\a+\ttesta)+\sadd;
\rrange =\a+\psitwo-\ttesta+\sadd; 
\timex=\rrange-1.5;
} 
\begin{tikzpicture}[scale=\picscale,
declare function={
	testxonep(\ps,\t)=\a+\ps-\t;
	testxonem(\ps,\t)=\ps-\a+\t; 
},
 ] 
\definecolor{tempcolor}{RGB}{250,190,0}
\definecolor{darkgreen}{RGB}{40,190,40}
\draw[<->] (-\lrange, \h) node[left, scale=\textscale] {$S_0$} -- (\rrange, \h) node[right, scale=\textscale] {$S_0$};
\draw[<->] (-\lrange, \a) node[left, scale=\textscale] {$S$} -- (\rrange, \a) node[right, scale=\textscale] {$S$};
              
\draw[->, shorten <= 5pt,  shorten >= 1pt] (\psione,\h) node[below, scale=\textscale]{$\psi_1^{\text{sys}}$} node[above left, scale=\textscale]{$z_1$}-- (\psione,\a);
\coordinate[label = below: (a)]  (D) at (\labelx,\labely); 
\draw[->,  shorten <= 5pt,  shorten >= 1pt] (\psitwo,\h) node[below, scale=\textscale]{$\psi_2^{\text{sys}}$} node[above right, scale=\textscale]{$z_2$}-- (\psitwo,\a);

\draw[dashed, tempcolor, ultra thick](\phstartx,\tbeg) node[below left=-2,scale=\textscale]{}--(\psione,\tone) node[above, pos=0.3, rotate=45,scale=0.7,black] {} node[below, pos=0.3, rotate=45,scale=0.7,black] {};
\draw[dashed, gray](\psione,\tone) node[below left=-2,scale=\textscale]{}--(\psitwo,\ttwo );
\draw[dashed, gray](\psitwo,\ttwo)--(\xend,\a); 
\draw[dashed, tempcolor, ultra thick](\psione,\tone)--(\xendz,\a);

\draw [black,fill] (\xendz,\a) circle [radius=\circsize] node [black,above,scale=\textscale] {$\gamma_1$}; 

\draw[dashed, darkgreen, ultra thick](\psione,\tone)--(\psitwo,\tthree);
\draw [black,fill] (\psitwo,\tthree) circle [radius=\circsize] node [black,below=4,right,scale=\textscale] {$2t_1-t_2$}; 


\draw [black,fill] (\psione,\tone) circle [radius=\circsize] node [black,left=4,scale=\textscale] {$t_1$}; 
\draw [black,fill](\psitwo,\ttwo)circle [radius=\circsize] node [black,above right,scale=\textscale, align=left] {$t_2$}; 

%\draw [decorate, decoration = {calligraphic brace}] (\psitwo+\nudge,\ttwo) --  (\psitwo+\nudge,\tone+\nudge/4) node[midway,right, scale=\textscale]{$t_2-t_1$}; 
%\draw [decorate, decoration = {calligraphic brace}] (\psitwo+\nudge,\tone-\nudge/4) --  (\psitwo+\nudge,2*\tone-\ttwo) node[midway,right, scale=\textscale]{$t_2-t_1$}; 

\draw[->] (\timex,\md-\tlen/2) --  (\timex,\md+\tlen/2) node[midway,right, scale=\textscale]{time}; 
 
\draw[dotted](\psione,\ttestb)--({testxonep(\psione,\ttestb)},\a);
\draw[dotted](\psione,\ttestb)--({testxonem(\psione,\ttestb)},\a);
\draw [black,fill](\psione,\ttestb) circle [radius=\circsize] node [black,below=6,left,scale=\textscale] {$y^b_1$}; 

\draw[magenta,->,ultra thick] ({testxonem(\psione,\ttestb)},\a)--(-\lrange,\a);
\draw[magenta,->,ultra thick] ({testxonep(\psione,\ttestb)},\a)--(\rrange,\a);

\end{tikzpicture}% pic 1
 % <----------------- SPACE BETWEEN PICTURES
\begin{tikzpicture}[scale=\picscale,  %[x={10.0pt},y={10.0pt}]
declare function={
	testxonep(\ps,\t)=\a+\ps-\t;
	testxonem(\ps,\t)=\ps-\a+\t; 
},
 ] 
\definecolor{tempcolor}{RGB}{250,190,0}
\definecolor{darkgreen}{RGB}{40,190,40}
\draw[<->] (-\lrange, \h) node[left, scale=\textscale] {$S_0$} -- (\rrange, \h) node[right, scale=\textscale] {$S_0$};
\draw[<->] (-\lrange, \a) node[left, scale=\textscale] {$S$} -- (\rrange, \a) node[right, scale=\textscale] {$S$};
              
\draw[->, shorten <= 5pt,  shorten >= 1pt] (\psione,\h) node[below, scale=\textscale]{$\psi_1^{\text{sys}}$} node[above left, scale=\textscale]{$z_1$}-- (\psione,\a);
\coordinate[label = below: (b)]  (D) at (\labelx,\labely); 
\draw[->,  shorten <= 5pt,  shorten >= 1pt] (\psitwo,\h) node[below, scale=\textscale]{$\psi_2^{\text{sys}}$} node[above right, scale=\textscale]{$z_2$}-- (\psitwo,\a);

\draw[dashed, tempcolor, ultra thick](\phstartx,\tbeg) node[below left=-2,scale=\textscale]{}--(\psione,\tone) node[above, pos=0.3, rotate=45,scale=0.7,black] {} node[below, pos=0.3, rotate=45,scale=0.7,black] {};
\draw[dashed, gray](\psione,\tone) node[below left=-2,scale=\textscale]{}--(\psitwo,\ttwo );
\draw[dashed, gray](\psitwo,\ttwo)--(\xend,\a); 
\draw[dashed, tempcolor, ultra thick](\psione,\tone)--(\xendz,\a);



\draw[dashed, darkgreen, ultra thick](\psione,\tone)--(\psitwo,\tthree);
\draw [black,fill] (\psitwo,\tthree) circle [radius=\circsize] node [black,below=4,right,scale=\textscale] {$2t_1-t_2$}; 


\draw [black,fill] (\psione,\tone) circle [radius=\circsize] node [black,left=4,scale=\textscale] {$t_1$}; 
\draw [black,fill](\psitwo,\ttwo)circle [radius=\circsize] node [black,above right,scale=\textscale, align=left] {$t_2$}; 

%\draw [decorate, decoration = {calligraphic brace}] (\psitwo+\nudge,\ttwo) --  (\psitwo+\nudge,\tone+\nudge/4) node[midway,right, scale=\textscale]{$t_2-t_1$}; 
%\draw [decorate, decoration = {calligraphic brace}] (\psitwo+\nudge,\tone-\nudge/4) --  (\psitwo+\nudge,2*\tone-\ttwo) node[midway,right, scale=\textscale]{$t_2-t_1$}; 

\draw[->] (\timex,\md-\tlen/2) --  (\timex,\md+\tlen/2) node[midway,right, scale=\textscale]{time}; 
 
\draw[dotted](\psitwo,\ttestb)--({testxonep(\psitwo,\ttestb)},\a);
\draw[dotted](\psitwo,\ttestb)--({testxonem(\psitwo,\ttestb)},\a);
\draw [black,fill](\psitwo,\ttestb) circle [radius=\circsize] node [black,right,scale=\textscale] {$y^b_2$}; 

\draw[magenta,->,ultra thick] ({testxonem(\psitwo,\ttestb)},\a)--(-\lrange,\a);
\draw[magenta,->,ultra thick] ({testxonep(\psitwo,\ttestb)},\a)--(\rrange,\a);
\draw [black,fill] (\xendz,\a) circle [radius=\circsize] node [black,above,scale=\textscale] {$\gamma_1$}; 

\end{tikzpicture}% pic 1
\vspace*{2px}
\caption{(a) highlights the part of $S$ used to calculate the energy density at $y^b_1$ whose time is greater than $2t_1-t_2$. (b) highlights the part of $S$ used to calculate the energy density at $y^b_2$ whose time is greater than $2t_1-t_2$.}
\label{TM3}
\end{figure}
In this situation, when we consider the location $y^b_1$, there is no additional information in $S^1(y^b_1)\cap S$ beyond standard quantum theory, so there will be a proportion of $\abs{b}^2$ of the total initial energy of the system at $y^b_1$. But at location $y^b_2$, the information in $S^1(y^b_2)\cap S$ shows that the photon has reflected from the localized $\psi_1^\text{sys}$-state, and so this additional information tells us that the photon didn't reflect the localized $\psi_2^\text{sys}$-state. So it is as though the information of $S^1(y^b_2)\cap S$ has determined that we are in a world in which there is an energy density of zero at $y^b_2$, and there are no other worlds in which energy density  at $y^b_2$ is non-zero since all worlds have to be consistent with the notional measurement made on $S$. So for a short time the total energy of the system is reduced by a factor of $\abs{b}^2$.  But the total energy of the system is once again restored to the initial energy at times greater than $t_1$ as shown in figure \ref{TM4}.

  \begin{figure}[ht!]
\captionsetup{justification=justified}
\centering
\tikzmath{
\a=5.3;  
\psione=0;
\psitwo=1;
\e = 0.1;
\h=-0.8;
\labelx=(\psione+\psitwo)/2;
\labely=-1.5;
\phstartx=-2.9;
\phstarty=-.8;
\tbeg=\phstarty;
\ca=\phstartx-\tbeg;
\ttwo=\psitwo-\ca;
\cb=\ttwo+\ca;
\xend=\ttwo-\a+\cb;
\tone=\psione-\ca;
\cc=\tone+\ca;
\xendz=\tone-\a+\cc;
\tthree=\cc+\tone-\psitwo;
\circsize=0.08;
\md = (\a+\h)/2;
\tlen=0.75;
\textscale = 0.7;
\picscale = 0.59;
\nudge=0.1;
\tnudge=(\ttwo-\tone)/2;
\ttesta=2*\tone-\ttwo-\tnudge;
\ttestb=2*\tone-\ttwo+\tnudge;
\ttestc=\ttwo-\tnudge;
\ttestd=\ttwo+\tnudge;
\sonea=\a+\psione-\ttesta;
\sadd=0.5;
\lrange = -(\psione-\a+\ttesta)+\sadd;
\rrange =\a+\psitwo-\ttesta+\sadd; 
\timex=\rrange-1.5;
} 
\begin{tikzpicture}[scale=\picscale,
declare function={
	testxonep(\ps,\t)=\a+\ps-\t;
	testxonem(\ps,\t)=\ps-\a+\t; 
},
 ] 
\definecolor{tempcolor}{RGB}{250,190,0}
\definecolor{darkgreen}{RGB}{40,190,40}
\draw[<->] (-\lrange, \h) node[left, scale=\textscale] {$S_0$} -- (\rrange, \h) node[right, scale=\textscale] {$S_0$};
\draw[<->] (-\lrange, \a) node[left, scale=\textscale] {$S$} -- (\rrange, \a) node[right, scale=\textscale] {$S$};
              
\draw[->, shorten <= 5pt,  shorten >= 1pt] (\psione,\h) node[below, scale=\textscale]{$\psi_1^{\text{sys}}$} node[above left, scale=\textscale]{$z_1$}-- (\psione,\a);
\coordinate[label = below: (a)]  (D) at (\labelx,\labely); 
\draw[->,  shorten <= 5pt,  shorten >= 1pt] (\psitwo,\h) node[below, scale=\textscale]{$\psi_2^{\text{sys}}$} node[above right, scale=\textscale]{$z_2$}-- (\psitwo,\a);

\draw[dashed, tempcolor, ultra thick](\phstartx,\tbeg) node[below left=-2,scale=\textscale]{}--(\psione,\tone) node[above, pos=0.3, rotate=45,scale=0.7,black] {} node[below, pos=0.3, rotate=45,scale=0.7,black] {};
\draw[dashed, gray](\psione,\tone) node[below left=-2,scale=\textscale]{}--(\psitwo,\ttwo );
\draw[dashed, gray](\psitwo,\ttwo)--(\xend,\a); 
\draw[dashed, tempcolor, ultra thick](\psione,\tone)--(\xendz,\a);


\draw[dashed, darkgreen, ultra thick](\psione,\tone)--(\psitwo,\tthree);
\draw [black,fill] (\psitwo,\tthree) circle [radius=\circsize] node [black,below=4,right,scale=\textscale] {$2t_1-t_2$}; 


\draw [black,fill] (\psione,\tone) circle [radius=\circsize] node [black,left=4,scale=\textscale] {$t_1$}; 
\draw [black,fill](\psitwo,\ttwo)circle [radius=\circsize] node [black,above right,scale=\textscale, align=left] {$t_2$}; 

%\draw [decorate, decoration = {calligraphic brace}] (\psitwo+\nudge,\ttwo) --  (\psitwo+\nudge,\tone+\nudge/4) node[midway,right, scale=\textscale]{$t_2-t_1$}; 
%\draw [decorate, decoration = {calligraphic brace}] (\psitwo+\nudge,\tone-\nudge/4) --  (\psitwo+\nudge,2*\tone-\ttwo) node[midway,right, scale=\textscale]{$t_2-t_1$}; 

\draw[->] (\timex,\md-\tlen/2) --  (\timex,\md+\tlen/2) node[midway,right, scale=\textscale]{time}; 
 
\draw[dotted](\psione,\ttestc)--({testxonep(\psione,\ttestc)},\a);
\draw[dotted](\psione,\ttestc)--({testxonem(\psione,\ttestc)},\a);
\draw [black,fill](\psione,\ttestc) circle [radius=\circsize] node [black,right,scale=\textscale] {$y^c_1$}; 

\draw[magenta,->,ultra thick] ({testxonem(\psione,\ttestc)},\a)--(-\lrange,\a);
\draw[magenta,->,ultra thick] ({testxonep(\psione,\ttestc)},\a)--(\rrange,\a);

\draw [black,fill] (\xendz,\a) circle [radius=\circsize] node [black,above,scale=\textscale] {$\gamma_1$}; 

\end{tikzpicture}% pic 1
 % <----------------- SPACE BETWEEN PICTURES
\begin{tikzpicture}[scale=\picscale,  %[x={10.0pt},y={10.0pt}]
declare function={
	testxonep(\ps,\t)=\a+\ps-\t;
	testxonem(\ps,\t)=\ps-\a+\t; 
},
 ] 
\definecolor{tempcolor}{RGB}{250,190,0}
\definecolor{darkgreen}{RGB}{40,190,40}
\draw[<->] (-\lrange, \h) node[left, scale=\textscale] {$S_0$} -- (\rrange, \h) node[right, scale=\textscale] {$S_0$};
\draw[<->] (-\lrange, \a) node[left, scale=\textscale] {$S$} -- (\rrange, \a) node[right, scale=\textscale] {$S$};
              
\draw[->, shorten <= 5pt,  shorten >= 1pt] (\psione,\h) node[below, scale=\textscale]{$\psi_1^{\text{sys}}$} node[above left, scale=\textscale]{$z_1$}-- (\psione,\a);
\coordinate[label = below: (b)]  (D) at (\labelx,\labely); 
\draw[->,  shorten <= 5pt,  shorten >= 1pt] (\psitwo,\h) node[below, scale=\textscale]{$\psi_2^{\text{sys}}$} node[above right, scale=\textscale]{$z_2$}-- (\psitwo,\a);

\draw[dashed, tempcolor, ultra thick](\phstartx,\tbeg) node[below left=-2,scale=\textscale]{}--(\psione,\tone) node[above, pos=0.3, rotate=45,scale=0.7,black] {} node[below, pos=0.3, rotate=45,scale=0.7,black] {};
\draw[dashed, gray](\psione,\tone) node[below left=-2,scale=\textscale]{}--(\psitwo,\ttwo );
\draw[dashed, gray](\psitwo,\ttwo)--(\xend,\a); 
\draw[dashed, tempcolor, ultra thick](\psione,\tone)--(\xendz,\a);



\draw[dashed, darkgreen, ultra thick](\psione,\tone)--(\psitwo,\tthree);
\draw [black,fill] (\psitwo,\tthree) circle [radius=\circsize] node [black,below=4,right,scale=\textscale] {$2t_1-t_2$}; 


\draw [black,fill] (\psione,\tone) circle [radius=\circsize] node [black,left=4,scale=\textscale] {$t_1$}; 
\draw [black,fill](\psitwo,\ttwo)circle [radius=\circsize] node [black,above right,scale=\textscale, align=left] {$t_2$}; 

%\draw [decorate, decoration = {calligraphic brace}] (\psitwo+\nudge,\ttwo) --  (\psitwo+\nudge,\tone+\nudge/4) node[midway,right, scale=\textscale]{$t_2-t_1$}; 
%\draw [decorate, decoration = {calligraphic brace}] (\psitwo+\nudge,\tone-\nudge/4) --  (\psitwo+\nudge,2*\tone-\ttwo) node[midway,right, scale=\textscale]{$t_2-t_1$}; 

\draw[->] (\timex,\md-\tlen/2) --  (\timex,\md+\tlen/2) node[midway,right, scale=\textscale]{time}; 
 
\draw[dotted](\psitwo,\ttestc)--({testxonep(\psitwo,\ttestc)},\a);
\draw[dotted](\psitwo,\ttestc)--({testxonem(\psitwo,\ttestc)},\a);
\draw [black,fill](\psitwo,\ttestc) circle [radius=\circsize] node [black,below=5,right,scale=\textscale] {$y^c_2$}; 

\draw[magenta,->,ultra thick] ({testxonem(\psitwo,\ttestc)},\a)--(-\lrange,\a);
\draw[magenta,->,ultra thick] ({testxonep(\psitwo,\ttestc)},\a)--(\rrange,\a);
\draw [black,fill] (\xendz,\a) circle [radius=\circsize] node [black,above,scale=\textscale] {$\gamma_1$}; 

\end{tikzpicture}% pic 1


\vspace*{2px}
\caption{(a) highlights the part of $S$ used to calculate the energy density at $y^b_1$ whose time is greater than $t_1$. (b) highlights the part of $S$ used to calculate the energy density at $y^b_2$ whose time is greater than $t_1$.}
\label{TM4}
\end{figure}

In this situation, there is now information in $S^1(y^c_1)\cap S$ that determines that the photon reflected off the localized $\psi_1^\text{sys}$-state. This means that when the conditional expectation of the energy density of $y^c_1$ is calculated, the extra information in $S^1(y^c_1)\cap S$ determines that all the energy of the system is located at location $z_1$ for times greater than $t_1$, and the energy is equal to the initial energy of the system so that energy is conserved.
\section{Evaluating Kent's Interpretation}
\subsection{The Empirical Adequacy of Kent's interpretation}

We will need to express $\ev*{T^{\mu\nu}(y)}_{\tau_S}$ in terms of the observable $\hat{T}^{\mu\nu}(y)$ and the initial state $\ket{\Psi_0}$ in order to show that Kent's addition to quantum orthodoxy rather contradicting it. to find such an expression we would ideally like to find a hypersurface $S'$ that contains both $S^1(y)$ and $y$. Then we could consider how the observables $\hat{T}_S(x)$ and $\hat{T}^{\mu\nu}(y)$ act on the state $\ket{\Psi'}=U_{S'S_0}\ket{\Psi_0}$ and use this action to determine the probabilities $P(q(\tau),r)$ and $P(r)$ needed to define the conditional expectation $P(q(\kappa)|r)$. However, since by definition a hypersurface must be continuous with any two events of it being space-like separated, it is going to be impossible to find a hypersurface $S'$ with the desired properties. Nevertheless, what we can do is find a sequence of hypersurfaces $S_i(y)$ such that\label{siydef} $S_i(y)\subset S_j(y)$ for $i<j$, and that for any $x\in S^1(y)$, there exists $i$ such that $x\in S_i(y)$. An example of one such $S_i(y)$ is shown in figure \ref{S3}. When there is no ambiguity, we will drop the $y$ and write $S_i$ instead of $S_i(y)$. 

 \begin{figure}[ht!]
\captionsetup{justification=justified}
\centering

\tikzmath{
\a= 1;  
\e = 0.1;
\lam=0.9;
\h=-1;
\hae=(3*\a*\a+6*\a*\e+7*\e*\e-3*\a*sqrt(\a*\a+4*\e*\e)-4*\e*sqrt(\a*\a+4\e*\e))/(4*\a+4*\e-2*sqrt(\a*\a+4*\e*\e));
\hae=0.205678;
\circsize=1.2;
\md = (\a+\h)/2;
\lrange = 4;
\rrange=2;
\fictlabel=(\rrange-\lrange)/2;
\ss=(-\lrange-\a)/2;
\sss=\a+(\rrange-\a)/2;
\tlen=0.75;
\labelpos=(-\lrange-\a)/2;
} 

\begin{tikzpicture}[thick, scale=2]

\def\dotsize{0.7}

\definecolor{tempcolor}{RGB}{0,151,76}
\draw[<->] (-\lrange, \h) node[left] {$S_0$} -- (\rrange, \h) node[right] {$S_0$};
\filldraw (0,0) circle (\dotsize pt) node [below right] {$y$} ;
              
\draw[->] (\rrange,\md-\tlen/2) --  (\rrange,\md+\tlen/2) node[midway,right]{time}; 

\draw[->,blue, thick] [domain=-\a/2:-\lrange, samples=150]   plot (\x, {\a-\e/2-1/2*(sqrt(\lam*\lam*pow(\x+\hae+\a,2)+\e*\e)-\e+\lam*(\x+\hae+\a))}) node[left, black]{$S_i(y)$}  ;
\draw[blue, thick] [domain=-\a/2:\a/2, samples=150] plot (\x, {sqrt(\lam*\lam*\x*\x+\e*\e)-\e})   node[right, black]{$S_i(y)$};
\draw[->,blue, thick] [domain=\a/2:\rrange, samples=150]   plot (\x, {\a-\e/2-1/2*(sqrt(\lam*\lam*pow(\x-\hae-\a,2)+\e*\e)-\e-\lam*(\x-\hae-\a))}) node[right, black]{$S_i(y)$}  ;
\draw[gray] (-\lrange, \a)  -- (\rrange, \a)  {};
\draw[gray, dashed] (-\a, \a) -- (0,0) {};
\draw[gray, dashed](0,0) -- (\a, \a) {};
\draw[gray](\a, \a) --  (\rrange, \a)  ;         
\coordinate (B) at (\a,\a);
\node at (B)[red,circle,fill,inner sep=\circsize pt]{};
\coordinate (A) at (-\a,\a);
\node at (A)[red,circle,fill,inner sep=\circsize pt]{};
\coordinate (C) at (0,0);
\node at (C)[black,circle,fill,inner sep=\circsize pt]{};

\coordinate[label = above:$S$]  (D) at (0,\a);

\coordinate[label = above:$S$]  (D) at (\sss,\a);

\filldraw (\ss,\a) circle (\dotsize pt) node [above] {$x\in S_i(y)\cap S$} ;


 
\node (start) at (\labelpos,\h) [below] {Initial State $\ket{\Psi_0}$};
\node (evolution) at (\labelpos,\md+0.05) [below] {Unitary Evolution $\ket{\Psi_i}=U_{S_iS_0}\ket{\Psi_0}$};
\node (final) at (\labelpos,\a) [below] {Unitary Evolution $U_{SS_0}\ket{\Psi_0}$};
%\node at (-\ss+0.17,\mn-0.18){$-a_0$};
\draw [->, shorten <= 5pt] (start) [above] -- (evolution); 
\draw [->] (evolution) -- (final); 
\end{tikzpicture}

\vspace*{2px}
\caption{$S_i\myeq S_i(y)$ is a hypersurface containing $y$ and all of $S^1(y)$ in the limit as $i\rightarrow\infty$.   }
\label{S3}
\end{figure}
 
 Now if $r_i$ is the statement that  $T_S(x)=\tau_S(x)$ for all $x\in S_i(y)\cap S$, then 
 $$P(q(\tau)|r)=\lim_{i\rightarrow\infty}P(q(\tau)|r_i),$$
 and therefore from the definition of $\ev*{T^{\mu\nu}(y)}_{\tau_S}$ together with equation (\ref{conditionalexpectatio}), we have 
\begin{equation}\label{beable1}
\ev*{T^{\mu\nu}(y)}_{\tau_S}=\lim_{i\rightarrow\infty}\sum_\tau\frac{P(q(\tau),r_i)\tau}{P(r_i)}.
\end{equation} 
 To calculate $P(q(\tau)|r_i)$, we note that since $S_i$ is a hypersurface,  then there will exist a unitary operator operator $U_{S_iS_0}$ which maps the Hilbert space of states $H_{S_0}$ describing $S_0$ to the Hilbert space of states $H_{S_i}$\label{HSidef} describing $S_i$ in accord with how the states of $H_{S_0}$  evolve over time. Now let $H_{S_i,\tau_S}\subset H_{S_i}$ be subspace of states $\ket{\xi}$ for which  $T_S(x)\ket{\xi}=\tau_S(x)\ket{\xi}$  for all $x\in S_i\cap S$, and  let $\{\ket{\xi_1},\ket{\xi_2},\ldots\}$ be an orthonormal basis of the states of $H_{S_i,\tau_S}$. Given that the initial state of the world is $\ket{\Psi_0}$, the probability $P(r_i)$ of ``measuring'' the value of $T_S(x)$ on $S_i\cap S$ to be $\tau_S(x)$ will be 
\begin{equation}\label{Pri}
P(r_i)=\sum_j \abs{ \ip{\xi_j}{\Psi_i}}^2,
\end{equation}
where $\ket{\Psi_i}=U_{S_iS_0}$, and this probability will be independent of the particular orthonormal basis  $\{\ket{\xi_j}:j\}$ of $H_{S_i,\tau_S}$.\footnote{To see why this is, we note that we can extend the orthonormal set $\{\ket{\xi_1},\ket{\xi_2},\ldots\}$ to an orthonormal basis  $\{\ket{\xi_1},\ket{\xi_2},\ldots\}\cup\{\ket{\zeta_1},\ket{\zeta_2},\ldots\}$ which consists entirely of $\hat{T}_S$-eigenstates. We can think of each of the states of this orthonormal basis as the possible measurement outcomes when making the notional measurement of $T_S(x)$ on $S_i\cap S$. By the Born rule, it therefore follows that $P(r_i)=\sum_j \abs{ \ip{\xi_j}{\Psi_i}}^2$. But to see that this probability is independent of the particular basis, we can uniquely write $\ket{\Psi_i}$ as a sum $\ket{\Psi_i}=\ket{\xi}+\ket{\zeta}$ where $\ket{\xi}$ belongs to the span of $\{\ket{\xi_j}:j\}$ and $\ket{\zeta}$ belongs to the span of $\{\ket{\zeta_j}:j\}$.  Then since $\ket{\xi}=\sum_j\ip{\xi_j}{\Psi_i}\ket{\xi_j}$, it follows that $$\ip{\xi}{\xi}=\sum_j\abs{ \ip{\xi_j}{\Psi_i}}^2=P(r_i).$$ Therefore, since  $\ip{\xi}{\xi}$ is independent of the particular basis chosen, then so is $P(r_i)$.  \label{priproof} } If we define $\pi_i=\sum_j\dyad{\xi_j},$
then it is easy to see that
$$P(r_i)=\ev*{\pi_i}{\Psi_i}.$$
Turning to the calculation of $P(q(\tau), r_i)$, note that for the Tomogana-Schwinger formulation of relativistic quantum physics, the operators $\hat{T}_S(x)$ and $\hat{T}^{\mu\nu}(y)$ for fixed $\mu,\nu$ commute when $x$ and $y$ are spacelike separated. It therefore follows that we can express any state of $H_{S_i}$ as a superposition of simultaneous eigenstates of $\hat{T}^{\mu\nu}(y)$ and $\hat{T}_S(x)$ for $x\in S_i\cap S$.\footnote{cf. page \pageref{simultaneous} and footnote \ref{glosssim}.}  For a particular choice of $\mu,\nu$, we can then form an orthonormal basis $\{\ket{\eta_j}:j\}$ of $H_{S_i}$ consisting of simultaneous $\hat{T}^{\mu\nu}(y)$, $\hat{T}_S(x)$-eigenstates so that $\hat{T}^{\mu\nu}(y)\ket{\eta_j}=\tau^{(j)}\ket{\eta_j}$ and $\hat{T}_{S}(x)\ket{\eta_j}=\tau_S^{(j)}(x)\ket{\eta_j}$ for $x\in S_i\cap S$, where $\tau^{(j)}$ and $\tau_S^{(j)}(x)$ are the corresponding eigenstates. If we define  $\pi_{i,\tau}=\sum_j\dyad{\chi_{j,\tau}}$ where $\{\ket{\chi_{j,\tau}}:j\}$ is the subset of $\{\ket{\eta_j}:j\}$ such that $\hat{T}^{\mu\nu}(y)\ket{\chi_{j,\tau}}=\tau\ket{\chi_{j,\tau}}$ and $\hat{T}_S(x)\ket{\chi_{j,\tau}}=\tau_S(x)\ket{\chi_{j,\tau}}$ for all $x\in S_i\cap S$, then 
\begin{equation}\label{pqtauri}
P(q(\tau), r_i)=\sum_j \abs{ \ip{\chi_{j,\tau}}{\Psi_i}}^2=\ev*{\pi_{i,\tau}}{\Psi_i}.\protect\footnotemark
\end{equation}
\footnotetext{The proof of this is very similar to the proof given in footnote \ref{priproof}.}
But if we define $\pi_\tau=\sum_j\dyad{\eta_{j,\tau}}$ where $\{\ket{\eta_{j,\tau}}:j\}$ is the subset of  $\{\ket{\eta_j}:j\}$ with $\hat{T}^{\mu\nu}(y)\ket{\eta_{j,\tau}}=\tau\ket{\eta_{j,\tau}}$, then we also have  $\pi_{i,\tau}=\pi_i\pi_\tau$.\footnote{To see why, 
we first show that $\pi_i=\sum_j\dyad{\eta_{i,j}}$ where $\{\eta_{i,j}:j\}$ is the subset of $\{\eta_j:j\}$  for which $\ket{\eta_{i,j}}\in H_{S_i,\tau_S}$. 
To see why this holds, note that $\pi_i\ket{\eta_{i,j}}=\ket{\eta_{i,j}}$    since $\{\ket{\xi_j}:j\}$ is a basis for $H_{S_i,\tau_S}$ and $\ket{\eta_{i,j}}\in H_{S_i,\tau_S}$. 
Therefore $\pi_i\pi_{i,\eta}=\pi_{i,\eta}$  where  $\pi_{i,\eta}=\sum_j\dyad{\eta_{i,j}}$. 
But  $\pi_{i,\eta}\ket{\xi_j}=\ket{\xi_j}$ since $\{\ket{\eta_{i,j}}:j\}$ is a basis for $H_{S_i,\tau_S}$ and $\ket{\xi_j}\in H_{S_i,\tau_S}$. 
Therefore $\pi_{i,\eta}\pi_i=\pi_i.$ But $\pi_{i,\eta}\pi_i= \pi_i\pi_{i,\eta}$ since $\pi_i$ and $\pi_{i,\eta}$ are Hermitian. Hence $\pi_i= \pi_{i,\eta}$.

Now the summands of $\pi_i\pi_\tau$ are only going to consist of those $\dyad{\eta_j}$ for which $\hat{T}^{\mu\nu}(y)\ket{\eta_j}=\tau\ket{\eta_j}$ and for which $\hat{T}_S(x)\ket{\eta_j}=\tau_S(x)\ket{\eta_j}$ for all $x\in S_i\cap S$, and these are just the $\dyad*{\chi_{j,\tau}}$ which are the summands of  $\pi_{i,\tau}$. Hence  $\pi_i\pi_\tau=\pi_{i,\tau}.$} 
  Hence
\begin{equation}\label{pqtauri2}
P(q(\tau), r_i)=\ev*{\pi_i\pi_\tau}{\Psi_i}.
\end{equation}
But clearly $\hat{T}^{\mu\nu}(y)=\sum_\tau \tau \pi_\tau.$ Therefore combining (\ref{beable1}) and (\ref{pqtauri2}), we have 
\begin{equation}\label{kentconsistency0}
\ev*{T^{\mu\nu}(y)}_{\tau_S}=\lim_{i\rightarrow\infty}\frac{\sum_\tau \ev*{\pi_i\pi_\tau}{\Psi_i}\tau}{\ev*{\pi_i}{\Psi_i}}=\lim_{i\rightarrow\infty}\frac{\ev*{\pi_i\hat{T}^{\mu\nu}(y)}{\Psi_i}}{\ev*{\pi_i}{\Psi_i}}.
\end{equation}
We are now in a position to show that Kent's theory is consistent with standard quantum orthodoxy. First let us consider what we need to show. 

In the pilot-wave interpretation, its consistency with standard quantum orthodoxy requires that if one averages the expectation values of an observable over the hidden variables (i.e. the positions and the momenta of all the particles) then one obtains the expectation value of the observable given by standard quantum orthodoxy as indicated in equation (\ref{bohmconsistency}). 

Now in Kent's interpretation, the hidden variables on which Kent's beables $\ev*{T^{\mu\nu}(y)}_{\tau_S}$ are the values $\tau_S(x)$ of $T_S(x)$ for $x\in S^1(y)\cap S$. The operator $\pi_i$ in equation (in the limit as $i\rightarrow\infty$) encapsulates this hidden information. To remind ourselves of $\pi_i$'s dependency on $\tau_S$ restricted to $S_i\cap S$, we will now write $\pi_i(\tau_{S_i\cap S})$ for $\pi_i$ where $\tau_{S_i\cap S}$ is the function $\tau_S$ restricted to $S_i\cap S$. Likewise, we will now write  $r_i(\tau_{S_i\cap S})$ for $r_i$, the statement that $T_S(x)=\tau_S(x)$ for all $x\in S_i(y)\cap S$. If we let $j$ index all possible functions $\tau^{(j)}_{S_i\cap S}$ taking real values on $S_i\cap S$, then the analogue of (\ref{bohmconsistency}) requires us to show that 
\begin{equation}\label{kentconsistency}
\ev*{\hat{T}^{\mu\nu}(y)}=\lim_{i\rightarrow\infty}\sum_{j}P\big(r_i(\tau^{(j)}_{S_i\cap S})\big)\ev*{T^{\mu\nu}(y)}_{\tau_S}
\end{equation}
for all $y$ lying between $S_0$ and $S$. Equation (\ref{kentconsistency}) is sufficient to establish consistency with quantum orthodoxy because ultimately, all observables are going to be reducible to expressions dependent on $\hat{T}^{\mu\nu}(y)$, since once we know what to expect for $\hat{T}^{\mu\nu}(y)$ we will know what to expect for the energy and momentum densities for all measuring apparatus readouts etc. and hence what to expect for all measurement outcomes. But from (\ref{kentconsistency0}), we have 
\begin{equation}\label{kentconsistency1}
\lim_{i\rightarrow\infty}\sum_jP\big(r_i(\tau^{(j)}_{S_i\cap S})\big)\ev*{T^{\mu\nu}(y)}_{\tau^{(j)}_{S_i\cap S}}=\lim_{i\rightarrow\infty}\sum_{j}{\ev*{\pi_{i}(\tau^{(j)}_{S_i\cap S})\hat{T}^{\mu\nu}(y)}{\Psi_i}}
\end{equation}
Since there is an orthonormal basis $\{\ket{\eta_j}:j\}$ of $H_{S_i}$ consisting of simultaneous $\hat{T}_S(x)$-eigenstates so that $\hat{T}_S(x)\ket{\eta_j}=\tau^{(j)}_{S_i\cap S}(x)\ket{\eta_j}$ for all $x\in S_i\cap S$, it follows that $\sum_j \pi_{i}(\tau^{(j)}_{S_i\cap S})=I$. Therefore equation (\ref{kentconsistency}) follows from (\ref{kentconsistency1}) which is what we were aiming to show for orthodox quantum consistency to hold.
\subsection{Parameter Independence in Kent's interpretation}

\subsection{Kent's interpretation and the Colbeck Renner theorem}

\subsection{Kent's interpretation and Lorentz Invariance\label{massenergydensity}}
In order to explain what it means for Kent's interpretation to be compatible with Special Relativity, we first need to explain how spacetime coordinates look to different observers. 

A spacetime location is represented by a four-tuples $(x^0, x^1, x^2, x^3)$ where $(x^i)_{i=1}^3$ are spatial coordinates, and where $x^0=ct$ with $c$ being equal to the speed of light and $t$ being the time. If $(1,0,0,0)$ corresponds to the spacetime location $\hat{e}_0$, $(0,1,0,0)$ corresponds to the spacetime location $\hat{e}_1$, etc., then we can express any other spacetime location  as a sum $\sum_{\mu=0}^3x^\mu\hat{e}_\mu$. We will use the so-called Einstein convention of dropping the summation sign and implicitly assume there is a summation whenever an upper index and a lower index are the same so that we can write $x^\mu\hat{e}_\mu$ instead of $\sum_{\mu=0}^3x^\mu\hat{e}_\mu$.  

Now suppose an observer $O$ expresses spacetime locations in terms of $\{\hat{e}_\mu\}_{\mu=0}^3$ and hence uses the coordinates $(x^0, x^1, x^2, x^3)$ to describe various spacetime locations. For another observer $O'$, it may be more natural to express spacetime locations in terms of a different set of spacetime locations $\{\hat{e'}_\mu\}_{\mu=0}^3$ so that the location described by $O$ as $(x^0, x^1, x^2, x^3)$ would be described by $O'$ as $({x'}^0, {x'}^1, {x'}^2, {x'}^3)$ where ${x'}^\mu{\hat{e}'}_\mu=x^\mu\hat{e}_\mu$.  For instance if $O$ and $O'$ are moving with respect to each other, they may both want to use coordinates in which their own spatial coordinates are fixed and in which the spatial coordinates of the other observer are changing. As another example, figure \ref{rotfigure} shows how the $(x^1, x^2)$-coordinates transform under a spatial rotation. 


\begin{figure}[ht!]
\captionsetup{justification=justified}
\centering
\tikzmath{
\textscale = 0.7;
\picscale = 0.59;
\circsize=3.5;
\px=3;
\py=3.5;
\pr=sqrt(\px*\px+\py*\py);
\th=33;
\thd=atan(\py/\px)-\th;
\pyd=\pr*sin(\thd);
\pxd=\pr*cos(\thd);
\rrange =7; 
\labelx= \rrange/2;
\labely=-0.3;
\vr=3;
\vth=75;
\vx=\vr*cos(\vth);
\vy=\vr*sin(\vth);
\vxt=\vx+\px;
\vyt=\vy+\py;
\vrt=sqrt(\vxt*\vxt+\vyt*\vyt);
\vthd=atan(\vyt/\vxt)-\th;
\vxtd=\vrt*cos(\vthd);
\vytd=\vrt*sin(\vthd);
\vxd=\vr*cos(\vth-\th);
\vyd=\vr*sin(\vth-\th);
} 
\begin{tikzpicture}[scale=\picscale] 
    \draw[-latex] (0,0) -- (\rrange,0)  node[right,scale=\textscale, text width=5em] {$\hat{e}_1$};
    \draw[-latex] (0,0) -- (0,\rrange)  node[right,scale=\textscale, text width=5em] {$\hat{e}_2$};
    \draw[dotted, thick] (\px,0) --  (\px,\py) node[midway,right, scale=\textscale]{${x}^2$}; 
     \draw[dotted, thick] (0,\py) --  (\px,\py)  node[midway,above, scale=\textscale]{${x}^1$};  

    \begin{scope}[rotate=\th,draw=red, text=red]
       \draw[-latex] (0,0) -- (\rrange,0)  node[right,scale=\textscale, text width=5em]  {$\hat{e}'_1$};
   	   \draw[-latex] (0,0) -- (0,\rrange)  node[right,scale=\textscale, text width=5em] {$\hat{e}'_2$};
   	   \draw[dotted, thick] (\pxd,0) --  (\pxd,\pyd) node[midway, above=4,right=1,scale=\textscale]{${x'}^2$}; 
   	   \draw[dotted, thick] (0,\pyd) --  (\pxd,\pyd)  node[midway,above, scale=\textscale]{${x'}^1$};  
    \end{scope}

  \draw [black,fill] (\px,\py) circle [radius=\circsize pt] ;
    
    \coordinate[label = below: (a)]  (D) at (\labelx,\labely); 
\end{tikzpicture}% pic 1
\vspace*{2px}
\caption{Shows how a location (marked as $\bullet$) can be expressed either  in coordinates $(x^1, x^2)$ with respect to the basis $\{\hat{e}_1,\hat{e}_2\}$ or in coordinates $({x'}^1,{x'}^2)$ with respect to the basis $\{\hat{e}'_1,\hat{e}'_2\}$.}\label{rotfigure}
\end{figure}

Now the key fact about all observer is that they must always observe light to have a constant speed $c$. Thus,  for a photon that goes through the spacetime locations $(0,0,0,0)$ and $(x^0, x^1, x^2, x^3)$ in the coordinates of $O$, we must have $(x^0, x^1, x^2, x^3)=(ct,tv^1,tv^2,tv^3)$ where 
$$\sqrt{(v^1)^2 +(v^2)^2+(v^3)^2}=c.$$ But if $(0,0,0,0)$ and $(x^0, x^1, x^2, x^3)$ corresponds to $(0,0,0,0)$ and $({x'}^0, {x'}^1, {x'}^2, {x'}^3)$ respecetively in the coordinates of another observer $O'$, then we must also have $({x'}^0, {x'}^1, {x'}^2, {x'}^3)=(ct',t'{v'}^1,t'{v'}^2,t'{v'}^3)$ where 
$$\sqrt{({v'}^1)^2 +({v'}^2)^2+({v'}^3)^2}=c.$$ 
In either case, we must have 
\begin{equation}\label{invariant}
(x^0)^2- (x^1)^2- (x^2)^2 - (x^3)^2=({x'}^0)^2- ({x'}^1)^2- ({x'}^2)^2 - ({x'}^3)^2=0.
\end{equation}
If we define $\eta_{00}=1$, $\eta_{ii}=-1$ for $i=1,2,3$ and $\eta_{\mu\nu}=0$ for $\mu\neq\nu$, then using the Einstein summation convention as well as the convention of lowering indices so that we define $x_\mu=\eta_{\mu\nu}x^\nu$, then (\ref{invariant}) is equivalent to 
$$x_\mu x^\nu={x'}_\mu {x'}^\nu=0.$$ 
Thus, for any coordinate transformation $x\rightarrow x'$ such that  $x_\mu x^\mu={x'}_\mu{x'}^\mu$,  if the speed of light is $c$ in the $x$-coordinates, then the speed of light is also guaranteed to be $c$ in the $x'$-coordinates.  A \textbf{Lorentz Transformatin} $\Lambda$ is any coordinate transformation of the form ${x'}^\mu=\Lambda\indices{^\mu_\nu}x^\nu$ such that $x_\mu x^\mu={x'}_\mu{x'}^\mu$. Since a Lorentz transformation must satisfy
$$x_\mu x^\mu=\eta_{\mu\rho}\Lambda\indices{^\rho_\sigma}x^\sigma\Lambda\indices{^\mu_\nu}x^\nu$$
for all $x$, it follows that  
\begin{equation}\label{lorentztrans}
\Lambda\indices{^\rho_\mu}\eta_{\rho\sigma}\Lambda\indices{^\sigma_\nu}=\eta_{\mu\nu}.\protect\footnotemark
\end{equation}
\footnotetext{To see why this is, note that if  $x_\mu x^\mu={x'}_\mu{x'}^\mu$ for all $x$, then putting for any other spacetime location $y$, we have $(x+y)_\mu (x+y)^\mu={(x'+y')}_\mu{(x'+y')}^\mu$. If we expand this out and cancel $x_\mu x^\mu$ with ${x'}_\mu{x'}^\mu$ and cancel $y_\mu y^\mu$ with ${y'}_\mu{y'}^\mu$, and using the fact that $y_\mu x^\mu=x_\mu y^\mu$, etc. we find that  $x_\mu y^\mu={x'}_\mu{y'}^\mu$ for all $x$ and $y$. Hence
$$\eta_{\nu\mu}x^\mu y^\nu = x_\mu y^\mu=\eta_{\sigma\rho}\Lambda\indices{^\rho_\mu}\Lambda\indices{^\sigma_\nu}x^\mu y^\nu.$$  
Since we can choose $x$ such that $x^\mu=1$ and $x^\alpha = 0$ for $\alpha\neq\mu$, and choose $y$ such that $y^\nu=1$ and $y^\beta=0$ for $\beta\neq\nu$. Then we get
$$\eta_{\mu\nu} = \eta_{\sigma\rho}\Lambda\indices{^\rho_\mu}\Lambda\indices{^\sigma_\nu}, $$ and hence the result follows.}
Having considered how the coordinates of a spacetime location viewed by one observers relate to the coordinates of the same spacetime location viewed by a different observer, we can now consider how physical quantities viewed by different observers relate to each other. The simplest kind of physical quantity is called a \textbf{scalar}. A scalar defined at a particular spacetime location has the same value no matter what frame of reference an observer uses. One example of a scalar is an object's \textbf{rest mass} which is the mass an object would have if it had no velocity. There is still a transformation rule for scalars since the spacetime location at which the scalar is measured is usually expressed in terms of an observer's coordinate system, and the coordinates of  such a location  will differ for different observers. Thus, if $\phi(x)\myeq\phi(x^0, x^1, x^2, x^3)$ is the value of a scalar defined at the spacetime location $(x^0, x^1, x^2, x^3)$ as described by an observer $O$, then another observer $O'$ using a different set of coordinate $({x'}^0, {x'}^1, {x'}^2, {x'}^3)$ to describe the location $(x^0, x^1, x^2, x^3)$ will describe this same scalar as $\phi'(x')\myeq\phi'({x'}^0, {x'}^1, {x'}^2, {x'}^3)$  where $\phi'(x')=\phi(x)$. Since $\phi'$ is just a function of the four numbers ${x'}^0, {x'}^1, {x'}^2,$ and ${x'}^3$, we can rename these numbers ${x}^0, {x}^1, {x}^2,$ and ${x}^3$, and then 
\begin{equation}\label{lorentzscalar}
\phi'(x)=\phi(\Lambda^{-1}x)
\end{equation} 
where $\Lambda$ is the inverse Lorentz transformation that takes $({x'}^0, {x'}^1, {x'}^2, {x'}^3)$ to $(x^0, x^1, x^2, x^3)$. Thus, equation (\ref{lorentzscalar}) shows us how a scalar transforms under a Lorentz transformation $\Lambda$. 

Many physical quantities, however, are not scalars and so will look different to different observers. For instance, the energy of an object has a kinetic component that depends on the velocity the object has relative to an observer. However, it turns out that if an observer $O$ considers an object's energy $E$ together with its three components of momentum $p^1, p^2$, and $p^3$ (in the directions $\hat{e}_1$, $\hat{e}_2$, and $\hat{e}_3$ respectively) to form the four-tuple $p\myeq(E/c, p^1, p^2, p^3)$ known as the object's \textbf{four-momentum}, then $p$ transforms in the same way as spacetime coordinates transform between different observers. In other words, a different observer $O'$ whose coordinates are given by ${x'}^\mu=\Lambda\indices{^\mu_\nu}x^\nu$ would observe the object's four-momentum to be ${p'}^\mu=\Lambda\indices{^\mu_\nu}p^\nu$.\footnote{In order for $p$ to transform in this way, we have to redefine what we mean by energy and momentum. In classical mechanics, the momentum of an object is the product of the object's mass and its velocity. In the context of special relativity, however, the four-momentum of an object is defined to the product of its rest mass $m_0$ and its \textbf{four-velocity} where the four velocity of an object is a four-tuple $(u^0, u^1, u^2, u^3)$ such that the object's velocity (in the classical sense) is the vector $(c \frac{u^1}{u^0}, c \frac{u^2}{u^0}, c\frac{u^3}{u^0})$ and such that $v_\mu v^\mu=c^2$. One can work out an object's four-velocity by first considering its four-velocity relative to an observer who is stationary relative to the object. In this case, the object's four-velocity will be $(c,0,0,0)$. Now suppose the observer is moving at a constant speed $v$ in the $\hat{e}_1$ direction towards the object. Then according to the  transformation rule for four-vectors, the corresponding four-velocity must now be $(u^0, u^1, u^2, u^3)$ with $u^\mu=\Lambda\indices{^\mu_0}c$ for some Lorentz transformation $\Lambda\indices{^\mu_\nu}$ such that $(c \frac{u^1}{u^0}, c \frac{u^2}{u^0}, c\frac{u^3}{u^0})=(-v,0,0)$. From this it follows that $u^2=u^3=0$. But in terms of the $\Lambda\indices{^\mu_\nu}$ components, we must also have $(c,0,0,0)\rightarrow(\Lambda{^0_0}c, \Lambda{^1_0}c, 0, 0)$. Hence, $ \Lambda{^1_0}=-{\Lambda{^0_0}v}/{c}$. It is conventional to define $\beta={v}/{c}$ and $\gamma=\Lambda{^0_0}$ so that   $ \Lambda{^1_0}=-\gamma\beta$. Moreover, since $u_0u^0-u_1u^1=c^2$, we must also have $(\gamma c)^2-(\gamma \beta c )^2=c^2$ from which it follows that $\gamma=\frac{1}{\sqrt{1-\beta^2}}.$ Thus, in the case of an object moving with velocity $(-v,0,0)$, its four-velocity will be $(\gamma c, -\gamma \beta c,0,0)=(\gamma c, -\gamma v,0,0)$. Without loss of generality, we therefore see that in the case of an object moving with velocity $(v^1, v^2, v^3)$, then its four-velocity must be $\gamma(c,v^1,v^2,v^3)$  where 
 $\gamma=\frac{1}{\sqrt{1-\beta^2}}$ and $\beta=v/c=\sqrt{({v}^1)^2+({v}^2)^2+({v}^3)^2}/c$. Hence, the object's four-momentum will be $\gamma m_0(c,v^1,v^2,v^3).$ If the objects velocity is very small compared to the speed of light, then $\gamma\approx 1+\frac{v^2}{2c^2}$, and hence the objects four-momentum $(E/c, p^1, p^2, p^3)$ will be approximately $(m_0c+\frac{1}{2}m_0{v^2}/c, m_0v^1,m_0v^2,m_0v^3)$. Therefore, $(p^1, p^2, p^3)$ is approximately equal to the classical momentum. However, the energy is now $E=m_0c^2+\frac{1}{2}m_0{v^2}$. Thus, in addition to the kinetic energy term $\frac{1}{2}m_0{v^2}$, there is a rest mass energy $m_0c^2$. If we define the \textbf{relativistic mass} $m=\gamma m_0$, then we obtain Einstein's famous forumla $E=mc^2$.  } More generally, any list of four physical quantities $(\varphi^0, \varphi^1, \varphi^2, \varphi^3)$ that transforms as $\varphi\rightarrow\varphi'$ with  ${\varphi'}^\mu=\Lambda\indices{^\mu_\nu}\varphi^\nu$ is called a \textbf{four-vector}. Figure \ref{rotfigure} shows how (two of) the components of a four-vector $\varphi$ at a particular location will differ for different observers under a spatial rotation of the coordinates. A four-vector $\varphi^\mu(x)$ defined at at every spacetime location $x$ is called a \textbf{vector field}, and if $O$ observers this vector-field $\varphi^\mu(x)$, and $O'$ is another observer whose coordinates are related to the coordinates $O$ via the Lorentz transformation $\Lambda$, then $O'$ will describe this vector-field as ${\varphi'}^\mu(x')\myeq\Lambda\indices{^\mu_\nu}\varphi^\nu(x).$ Hence under the Lorentz transformation $\Lambda$, ${\varphi}^\mu\rightarrow {\varphi'}^\mu$ where
\begin{equation}\label{lorentzvector}
{\varphi'}^\mu(x)=\Lambda\indices{^\mu_\nu}\varphi^\nu(\Lambda^{-1}x).
\end{equation} 


\begin{figure}[ht!]
\captionsetup{justification=justified}
\centering
\tikzmath{
\textscale = 0.7;
\picscale = 0.59;
\circsize=3.5;
\px=3;
\py=3.5;
\pr=sqrt(\px*\px+\py*\py);
\th=33;
\thd=atan(\py/\px)-\th;
\pyd=\pr*sin(\thd);
\pxd=\pr*cos(\thd);
\rrange =7; 
\labelx= \rrange/2;
\labely=-0.3;
\vr=3;
\vth=75;
\vx=\vr*cos(\vth);
\vy=\vr*sin(\vth);
\vxt=\vx+\px;
\vyt=\vy+\py;
\vrt=sqrt(\vxt*\vxt+\vyt*\vyt);
\vthd=atan(\vyt/\vxt)-\th;
\vxtd=\vrt*cos(\vthd);
\vytd=\vrt*sin(\vthd);
\vxd=\vr*cos(\vth-\th);
\vyd=\vr*sin(\vth-\th);
} 
\begin{tikzpicture}[scale=\picscale ] 
    \draw[-latex] (0,0) -- (\rrange,0)  node[right,scale=\textscale, text width=5em] {$\hat{e}_1$};
    \draw[-latex] (0,0) -- (0,\rrange)  node[right,scale=\textscale, text width=5em] {$\hat{e}_2$};
    \draw[dotted, thick] (\px,0) --  (\px,\py) node[midway,right, scale=\textscale]{${x}^2$}; 
    \draw[dotted, thick] (0,\py) --  (\px,\py)  node[midway,above, scale=\textscale]{${x}^1$};  
    
    \draw[-latex] (\px,\py)  -- (\px+\vx,\py+\vy)  node[right=22,above=-4,scale=\textscale, text width=5em] {${\varphi}$};
    \draw[dotted, thick] (\px,\py) --  (\px,\py+\vy) node[midway,left, scale=\textscale]{${\varphi}^2$}; 
    \draw[dotted, thick] (\px,\py+\vy) --  (\px+\vx,\py+\vy) node[midway,above, scale=\textscale]{${\varphi}^1$};  

    \begin{scope}[rotate=\th,draw=red, text=red]
       \draw[-latex] (0,0) -- (\rrange,0)  node[right,scale=\textscale, text width=5em]  {$\hat{e}'_1$};
   	   \draw[-latex] (0,0) -- (0,\rrange)  node[right,scale=\textscale, text width=5em] {$\hat{e}'_2$};
    \draw[dotted, thick] (\pxd,\pyd) --  (\vxtd,\pyd) node[midway,right=3,below=-3, scale=\textscale]{${\varphi'}^1$}; 
    \draw[dotted, thick] (\vxtd,\pyd) --  (\vxtd,\vytd) node[midway,right=6,above=-4, scale=\textscale]{${\varphi'}^2$};  
    \end{scope}

  \draw [black,fill] (\px,\py) circle [radius=\circsize pt];    
    \coordinate[label = below: (b)]  (D) at (\labelx,\labely); 
\end{tikzpicture}% pic 1
\vspace*{2px}
\caption{Shows how a four-vector ${\varphi}$ (of which only two components are shown) defined at a spacetime location (indicated by $\bullet$) can be expressed either as $(\varphi^1, \varphi^2)$ with respect to the basis $\{\hat{e}_1,\hat{e}_2\}$ or as $({\varphi'}^1,{\varphi'}^2)$ with respect to the basis $\{\hat{e}'_1,\hat{e}'_2\}$.}\label{rotfigure2}
\end{figure}
If $\varphi^\mu$ is a four-vector, then we refer to $\varphi_\mu\myeq\eta_{\mu\nu}\varphi^\nu$ as a \textbf{four-covector}. To see how covectors transform under a Lorentz transformation $\Lambda$, it will be helpful to define $\Lambda\indices{_\mu^\nu}\myeq\eta_{\mu\rho}\eta^{\nu\sigma}\Lambda\indices{^\rho_\sigma}$ where $\eta^{\nu\sigma}=\eta_{\nu\sigma}$. If we also define the \textbf{Kronecker-delta} $\delta^\nu_\mu$ such $\delta^\nu_\mu=1$ when $\mu=\nu$ and $\delta^\nu_\mu=0$ otherwise. Then using the fact that $\eta_{\mu\rho}\eta^{\nu\rho}=\delta^\nu_\mu$ together with equation (\ref{lorentztrans}), we have 
\begin{equation}\label{lambdainverse}
\Lambda\indices{^\rho_\mu}\Lambda\indices{_\rho^\nu}=\delta^\nu_\mu.
\end{equation}
By definition, the inverse of $\Lambda^{-1}$ satisfies 
$(\Lambda^{-1})\indices{^\nu_\rho}\Lambda\indices{^\rho_\mu}=\delta^\nu_\mu,$
so we have $(\Lambda^{-1})\indices{^\nu_\rho}=\Lambda\indices{_\rho^\nu}.$  From (\ref{lorentztrans}), we see that under a Lorentz transformation $\Lambda$, $\varphi_\mu\rightarrow\varphi'_\mu$
where
\begin{equation}\label{lorentzcovector}
\varphi'_\mu(x)=\Lambda\indices{_\mu^\nu}\varphi_\nu(\Lambda^{-1}x)
\end{equation}
 

Besides scalars, vectors, and covectors we also need to consider physical quantities called rank two tensors. The stress-energy tensor $T^{\mu\nu}$ mentioned on page \ref{stressenergy} is an example of a rank two tensor. The defining property of a rank two tensor $\varphi^{\mu\nu}(x)$ is that under a Lorentz transformation $\Lambda$, $\varphi^{\mu\nu}\rightarrow{\varphi'}^{\mu\nu}$ where
\begin{equation}\label{lorentztensor}
{\varphi'}^{\mu\nu}(x)=\Lambda\indices{^\mu_\rho}\Lambda\indices{^\nu_\sigma}\varphi^{\rho\sigma}(\Lambda^{-1}x).
\end{equation}
On page \pageref{massenergydensity}, we introduced the mass-energy density $T_S(x)$ on a hypersurface $S$. As explained in section \ref{massenergydensity}, the values of $T_S(x)$ are the additional values that Kent uses to supplement standard quantum orthodoxy.  It was mentioned in passing that $T_S(x)$ does not depend on which frame of reference one is in. In other words, $T_S(x)$ is a scalar. I will now explain why this is so. 

We first need to consider the precise definition of $T_S(x)$. At each spacetime location on the hypersurface $S$ which an observer $O$ describes as having coordinates $x=(x^\mu)_{\mu=0}^3$, we define  $\eta^\mu(x)$ to be the future-directed  unit four-vector at $x$ that is orthogonal to $S$. In other words, $\eta^0(x)>0$, $\eta_\mu(x)\eta^\mu(x)=1$, and if $y\in S$ is very close to $x$, then $\frac{(x-y)_\mu\eta^\mu(x)}{\sqrt{(x-y)_\nu(x-y)^\nu}}\approx 0.$  $T_S(x)$ is then given by the formula 
\begin{equation}\label{TSdef}
T_S(x)=T^{\mu\nu}(x)\eta_{\mu}(x)\eta_{\nu}(x).
\end{equation}
For example, if $S$ was the hypersurface consisting of all spacetime locations $(0,x^1,x^2,x^3)$, then $\big(\eta^{0}(x),\eta^{1}(x),\eta^{3}(x),\eta^{3}(x)\big) =(1,0,0,0),$ and hence $T_S(x)=T^{00}(x)$ which is the density of relativistic mass at $x$, i.e. the energy density at $x$ divided by $c^2$. 

Let us now show that $T_S(x)$ is a scalar. So suppose that $\Lambda$ is a Lorentz transformation such that $\Lambda\indices{^0_\mu}\eta^\mu>0$ for any future-directed  unit four-vector vector $\eta^\mu$. We refer to a $\Lambda$ with this property as a \textbf{orthochronous} Lorentz transformation. Also suppose that $O$ and $O'$ are two observers such that spacetime locations that observer $O$ describes as having coordinates $x=(x^\mu)_{\mu=0}^3$ are described by $O'$ as having coordinates $x'=(\Lambda\indices{^\mu_\nu}x^\nu)_{\mu=0}^3$. Then since ${x'}_\mu{y'}^\mu= x_\mu y^\mu$, it follows that the future-directed unit four-vector orthogonal to $S$ at $x$ which $O$ describes as $\eta^\mu(x)$ will be described by $O'$ as  ${\eta'}^\mu(x')=\Lambda\indices{^\mu_\nu}\eta^\nu(x)$. Thus, for any location in $S$ that $O'$ describes as having coordinates $x'$ with corresponding  future-directed $S$-orthogonal unit four-vector ${\eta'}^\mu(x')$, $O'$ can construct a function $T'_S(x')$  with 
\begin{equation}\label{TSprimedef}
T'_S(x')=T'^{\mu\nu}(x')\eta'_{\mu}(x')\eta'_{\nu}(x').
\end{equation}
Then using (\ref{lorentzvector}), (\ref{lorentzcovector}) and (\ref{lorentztensor}) on the right hand side of (\ref{TSprimedef}),  we have
\begin{equation}\label{invariantTS1}
\begin{split}
T'_S(x')&=\Lambda\indices{^\mu_\rho}\Lambda\indices{^\nu_\sigma}T^{\rho\sigma}(x)\Lambda\indices{_\mu^\alpha}\eta_{\alpha}(x)\Lambda\indices{_\nu^\beta}\eta_{\beta}(x)\\
&=\Lambda\indices{^\mu_\rho}\Lambda\indices{_\mu^\alpha} \Lambda\indices{^\nu_\sigma}\Lambda\indices{_\nu^\beta}T^{\rho\sigma}(x)\eta_{\alpha}(x)\eta_{\beta}(x)\\
&=\delta^\alpha_\rho\delta^\beta_\sigma T^{\rho\sigma}(x)\eta_{\alpha}(x)\eta_{\beta}(x)\\
&=T^{\alpha\beta}(x)\eta_{\alpha}(x)\eta_{\beta}(x)\\
&=T_S(x)
\end{split}
\end{equation}
where on the third line we have used (\ref{lambdainverse}) and on the last line we have used (\ref{TSdef}). To obtain (\ref{invariantTS1}), we assumed that $\Lambda$ is orthochronous, but if $\Lambda$ is non-orthochronous, we would need to take the negations of ${\eta'}^\mu(x')$ to get the future-directed $S$-orthogonal unit four-vector. But clearly this will not affect the equality in (\ref{invariantTS1}), so (\ref{invariantTS1}) holds for all Lorentz transformation, whether they are orthochronous or non-orthochronous.  We thus see that   $T_S(x)$ is a scalar.

Let us now consider the Hilbert space $H_{S_i}$ as defined on page \pageref{HSidef} for a hypersurface $S_i$. Two observers $O$ and $O'$ will typically assign different physical states to $S_i$ based on their frame of reference. E.g. if $O$ and $O'$ are traveling at different speeds, they will attribute different energy levels and momenta to to the spacetime locations of $S_i$. For the Lorentz transformation that relates the coodinates of $O'$ to the coordinates of $O$, i.e. $x'=\Lambda x$,  there  will then be a unitary operator $U(\Lambda):H_{S_i}\rightarrow H_{S_i}$ such that if
$O$ observes  $S_i$ to be in state $\ket{\psi_i}\in H_{S_i}$, then $O'$ will observe $S_i$ to be in state $U(\Lambda)\ket{\psi_i}$. Also, if $\hat{T}^{\mu\nu}(x)$ is the observable whose eigenstates with eigenvalues $\tau$ are the states of $S_i$ for which $O$ observes the stress-energy tensor $T^{\mu\nu}(x)$ to take the value $\tau$ at $x$, then 
\begin{equation}\label{TUrelation}
U(\Lambda)^{-1}\hat{T}^{\mu\nu}(x)U(\Lambda)=\Lambda\indices{^\mu_\rho}\Lambda{^\nu_\sigma}\hat{T}^{\rho\sigma}(\Lambda^{-1}x).
\end{equation}
We insist on this identity because it makes it the case that  $\hat{T}^{\mu\nu}(x')$ will be the observable whose eigenstates with eigenvalues $\tau'$ are the states of $S_i$ for which $O'$ observes the stress-energy tensor $T^{\prime\mu\nu}(x')$ to take the value $\tau'$ at $x'$.

We also insist that $U(\Lambda)$ is unitary because this means that if $O$ calculates the probability $S_i$ transitions from state $\ket{\psi_i}$ to state $\ket{\chi_i}$ , then $O'$ would calculate the same probability for the corresponding transition from the state $\ket{\psi_i'}=U(\Lambda)\ket{\psi_i}$ to state $\ket{\chi_i'}=U(\Lambda)\ket{\chi_i}$\footnote{This follows from (\ref{unitarycond}) which implies 
$\abs{\ip{\chi'_i}{\psi'_i}}^2=\abs{\ip{\chi_i}{\psi_i}}^2$, together with the Born rule given on page \pageref{bornrule}.}

Now in order to show that Kent's model is consistent with special relativity, we need to show that (\ref{kentconsistency0}) defines a rank 2 tensor. In other words, if $\{\ket{\xi_j}\}_{j=1}^\infty$ is an orthonormal basis of the Hilbert space of states $H_{S_i,\tau_S}$ for which $O$ observes $T_S(x)$ to be $\tau_S(x)$ for all $x\in S_i(y)\cap S$, and if $\{\ket{\xi_j'}\}_{j=1}^\infty$ is an orthonormal basis of the Hilbert space of states $H_{S_i,\tau_S'}$ for which $O'$ observes $T'_S(x')$ to be $\tau'_S(x')$ for all $x'\in S_i(y')\cap S$, then
\begin{equation}\label{kentlorentz}
\lim_{i\rightarrow\infty}\frac{\ev{\pi_i'\hat{T}^{\mu\nu}(y')}{\Psi_i'}}{\ev{\pi_i'}{\Psi_i'}}=\Lambda\indices{^\mu_\rho}\Lambda\indices{^\nu_\sigma} \lim_{i\rightarrow\infty}\frac{\ev{\pi_i\hat{T}^{\rho\sigma}(y)}{\Psi_i}}{\ev{\pi_i}{\Psi_i}}
\end{equation}
where $\pi_i=\sum_j\dyad{\xi_j}$, $\pi_i'=\sum_j\dyad{\xi_j'}$, and $\ket{\Psi_i'}=U(\Lambda)\ket{\Psi_i}$. To see why (\ref{kentlorentz}) holds, we first recall that $\pi_i'$ will be independent of which orthonormal basis we choose for $H_{S_i,\tau_S'}$.\footnote{We showed this was the case for $\pi_i$ in footnote \ref{priproof} on page \pageref{priproof}.} Therefore, if we can show that $\{\ket{\xi_j'}\myeq U(\Lambda)\ket{\xi_j}\}_{j=1}^\infty$ is an orthonormal basis of $H_{S_i,\tau_S'}$, it will follow that $\pi_i'=U(\Lambda)\pi_iU(\Lambda)^{-1}$. 

That the elements of $\{U(\Lambda)\ket{\xi_j}\}_{j=1}^\infty$ are orthonormal follows from the unitarity of $U(\Lambda)$ together with the orthormality of  $\{\ket{\xi_j}\}_{j=1}^\infty$.  Since $\hat{T}^{\mu\nu}(x')$ is the observable whose eigenstates with eigenvalue $\tau'$ are the states of $S_i(y')$ for which $O'$ observes the stress-energy tensor $T^{\prime\mu\nu}(x')$ to take the value $\tau'$ at $x'$, it follows that $\hat{T}'_S(x')\myeq\eta_\mu'(x')\eta_\nu'(x')\hat{T}^{\mu\nu}(x')$ will be the observable whose eigenstates with eigenvalue $\tau'_S$ are the states of $S_i(y')$ for which $O'$ observes $T'_S(x')$ to take the value $\tau'_S$ at $x'$, where as usual, $\eta^{\prime\mu}(x')$ is the unit four-vector orthogonal to $S_i(y')$ at $x'$. Now if $x'\in S_i(y')\cap S$, then $x=\Lambda^{-1}x'\in S_i(y)\cap S$. Using the same calculation as in (\ref{invariantTS1}) together with (\ref{lorentzcovector}), we have
\begin{equation}\label{TSLambda}
\begin{split}
\hat{T}_S(x)&=\eta_\mu(x)\eta_\nu(x)\hat{T}^{\mu\nu}(x)\\
&=\eta_{\mu}'(x')\eta_{\nu}'(x') \Lambda\indices{^\mu_\rho}\Lambda\indices{^\nu_\sigma}\hat{T}^{\rho\sigma}(x)
\end{split}
\end{equation}
Using (\ref{TSLambda}) together with (\ref{TUrelation}), we therefore have
\begin{equation}\label{TSU}
\begin{split}
\hat{T}_S(x)U(\Lambda)^{-1}&=\eta_{\mu}'(x')\eta_{\nu}'(x')\Lambda\indices{^\mu_\rho}\Lambda\indices{^\nu_\sigma}\hat{T}^{\rho\sigma}(x)U(\Lambda)^{-1}\\
&=U(\Lambda)^{-1} \eta_{\mu}'(x')\eta_{\nu}'(x')\hat{T}^{\mu\nu}(x')\\
&=U(\Lambda)^{-1} \hat{T}_S'(x').
\end{split}
\end{equation}
Now suppose that $\ket{\xi'}$ is a state for which $O'$ observes $T'_S(x')$ to be $\tau_S(x')$ for all $x'\in S_i(y')\cap S$. Then $\hat{T}_S'(x')\ket{\xi'}=\tau_S'(x'),$ and so by (\ref{TSU}), 
\begin{equation}\label{TSUxi}
\begin{split}
\hat{T}_S(x)U(\Lambda)^{-1}\ket{\xi'}&= U(\Lambda)^{-1} \hat{T}_S'(x')\ket{\xi'}\\
&=\tau_S'(x')U(\Lambda)^{-1}\ket{\xi'}\\
&=\tau_S(x)U(\Lambda)^{-1}\ket{\xi'}
\end{split}
\end{equation}
where on the last line we have used the fact that $T_S(x)$ is a scalar. Therefore, $U(\Lambda)^{-1}\ket{\xi'}$ can be expressed as a linear combination of basis elements $\{\ket{\xi_j}\}_{j=1}^\infty$, and hence  $\ket{\xi'}$ is can be expressed as a linear combination of $\{U(\Lambda)\ket{\xi_j}\}_{j=1}^\infty$. From (\ref{TSU}) we also see that  $U(\Lambda)\hat{T}_S(x)=\hat{T}_S'(x')U(\Lambda)$, so
$$
\hat{T}_S'(x')U(\Lambda)\ket{\xi_j}=U(\Lambda)\hat{T}_S(x)\ket{\xi_j}=\tau_S(x)U(\Lambda)\ket{\xi_j}=\tau_S'(x')U(\Lambda)\ket{\xi_j}
$$
for all $x'\in S_i(y')\cap S$. 
Therefore $\{\ket{\xi_j'}\myeq U(\Lambda)\ket{\xi_j}\}_{j=1}^\infty$ is an orthonormal basis of $H_{S_i,\tau_S'}$, and from this it follows that $\pi_i'=U(\Lambda)\pi_iU(\Lambda)^{-1}$. Therefore
\begin{equation}\label{kentlorentz2}
\begin{split}
\frac{\ev{\pi_i'\hat{T}^{\mu\nu}(y')}{\Psi_i'}}{\ev{\pi_i'}{\Psi_i'}}&=\frac{\ev{U(\Lambda)^{-1}U(\Lambda)\pi_iU(\Lambda)^{-1}\hat{T}^{\mu\nu}(y')U(\Lambda)}{\Psi_i}}{\ev{U(\Lambda)^{-1}U(\Lambda)\pi_i U(\Lambda)^{-1}U(\Lambda)}{\Psi_i}}\\
&=\frac{\ev{\pi_iU(\Lambda)^{-1}\hat{T}^{\mu\nu}(y')U(\Lambda)}{\Psi_i}}{\ev{\pi_i}{\Psi_i}}\\
&=\frac{\ev{\pi_i\Lambda\indices{^\mu_\rho}\Lambda{^\nu_\sigma}\hat{T}^{\rho\sigma}(y)}{\Psi_i}}{\ev{\pi_i }{\Psi_i}}
\end{split}
\end{equation}
where on the last line we have used (\ref{TUrelation}). Thus, equation (\ref{kentlorentz}) holds, and hence Kent's model is consistent with special relativity.





 


\subsection{Kent's Interpretation and Decoherence Theory}
In section \ref{probOutcomes} we saw that decoherence theory by itself does not offer a solution to the problem of outcomes. In this section, we consider how the additional information in Kent's interpretation is sufficient to address this problem. We suppose that $y_1$ is an event between the two hypersurfaces $S_0$ and $S$, and we consider a hypersurface $S_i=S_i(y_1)$  in a sequence of hypersurfaces that each contain $y_1$ as described on page \pageref{siydef}. To simplify our description of $S_i$ we use a coarse-grained model so that $S_i$ is treated as a mesh of tiny cells labeled by a sequence $(y_k)_{k=1}^\infty$, and for each cell $y_k$ there is a Hilbert space $H_k$ describing the state of that cell.  For any $y_k$ we denote its spatial component as $z_k$ and its time component as $t_k$. Then we suppose that the state $\ket{\Psi_i}$ describing $S_i$ can be decomposed as
\begin{equation}\label{Sistate}
\ket{\Psi_i}=\Big(\sum_{j=1}^{J} c_j\ket{\xi_{1,j}}\prod_{l=1}^{N_j}\ket{\xi_{k_{l,j},j}}\Big)\Xi
\end{equation}
where $\ket{\xi_{1,j}}\in H_1$ are normalized stares with $\ip{\xi_{1,j}}{\xi_{1,j'}}=0$ for $j\neq j'$, where $\ket{\xi_{k_{l,j},j}}\in H_{k_{l,j}}$ are normalized states with all the $k_{l,j}$ for $l=1$ to $N_j$ being non-zero and unique for a particular $j$, and where $\Xi$ is the sum of states of the form $\prod_l\ket{\xi_{\kappa_l}}$ describing all the cells of $S_i$ not included in the set $\bigcup_j\bigcup_{l=1}^{N_j}\{k_{l,j}\}.$ We also assume each summand $c_j\ket{\xi_{1,j}}\prod_{l=1}^{N_j}\ket{\xi_{k_{l,j},j}}\Xi$ contains a state in each $H_k$ for every cell $k$ of $S_i$. In other words if $k$ does not belong to the set $\{k_{l,j}:l\}$ then $k$ belongs to the set $\{\kappa_l:l\}$. From this it follows that $\bigcup_{l=1}^{N_j}\{k_{l,j}\}=\bigcup_{l=1}^{N_j'}\{k_{l,j'}\}$ for any $j'\neq j$. We can therefore assume $N_j=N$ and $k_{l,j}=k_l$ are independent of $j$. We can thus rewrite (\ref{Sistate}) as
\begin{equation}\label{Sistate2}
\ket{\Psi_i}=\Big(\sum_{j=1}^{J} c_j\ket{\xi_{1,j}}\prod_{l=1}^{N}\ket{\xi_{k_{l},j}}\Big)\Xi
\end{equation}
  We also assume that $\Xi$ describes as much of $S_i$ as possible, so that there is no common factor $\ket{\xi}$ among all the elements of $\{\prod_{l=1}^{N}\ket{\xi_{k_{l},j}}:j\}$. Furthermore, we assume that the $k_l$ are appropriately ordered so that there is some $M$ such that $y_{k_l}\in S\cap S_i$ for $l\geq M$ and  $y_{k_l}\not\in S\cap S_i$  for $l<M$. Finally, we will assume that if $N=0$ then $J=1$, for otherwise we can add the different $\ket{\xi_{1,j}}$ to form a single state in $H_1$.

To get a sense of the applicability of the decomposition (\ref{Sistate2}), we will consider a few different scenarios inspired by Kent's toy model, and in each scenario, we will use (\ref{Sistate2}) to calculate the partial trace enscapsulating all the information to calculate expectation values at different space-time locations. We thus suppose that a system is in a superposition $\psi_0^\text{sys} = c_1\psi_1^\text{sys}+c_2\psi_2^\text{sys}$ of two local states $\psi_1^\text{sys}$ and $\psi_2^\text{sys}$ where $\abs{c_1}^2+\abs{c_2}^2=1$ and that there is a photon coming in from the left that interacts with the system. Figure \ref{kentdeco1} depicts the hypersurface $S_i(y^a_1)$ for an event $y^a_1$ that occurs before the photon has interacted with the system.

\begin{figure}[ht!]
\captionsetup{justification=justified}
\centering
\tikzmath{
\a=5.3;  
\psione=0;
\psitwo=1.5;
\h=1;
\labelx=(\psione+\psitwo)/2;
\labely=-1.5;
\phstartx=-1.7;
\phstarty=\h;
\tbeg=\phstarty;
\ca=\phstartx-\tbeg;
\ttwo=\psitwo-\ca;
\cb=\ttwo+\ca;
\xend=\ttwo-\a+\cb;
\tone=\psione-\ca;
\cc=\tone+\ca;
\xendz=\tone-\a+\cc;
\tthree=\cc+\tone-\psitwo;
\circsize=0.08;
\md = (\a+\h)/2;
\tlen=0.75;
\textscale = 0.7;
\picscale = 0.89;
\nudge=0.1;
\tnudge=(\ttwo-\tone)/2+0.8;
\ttesta=2*\tone-\ttwo-\tnudge;
\ttestb=2*\tone-\ttwo+\tnudge;
\ttestc=\ttwo-\tnudge;
\ttestd=\ttwo+\tnudge;
\sonea=\a+\psione-\ttesta;
\sadd=0.5;
\lrange = -(\psione-\a+\ttesta)+\sadd;
\rrange =\lrange; 
\timex=\rrange-1.5;
\e = 0.4;
\ttestx=2.4;
\at=\a-\ttestx;
\ct=\ttestx;
\lam = 0.87;
\e = 0.2;
\hae=(2*pow(\at,3)*\lam*(2+\lam)+\e*\e*(2*\e-sqrt(4*\e*\e+\at*\at*\lam*\lam))-8*\at*\e*(-2*\e+sqrt(4*\e*\e+\at*\at*\lam*\lam))-2*\at*\at*(2+\lam)*(-2*\e+sqrt(4*\e*\e+\at*\at*\lam*\lam)))/(4*\at*\lam*(2*\at+2*\e-sqrt(4*\e*\e+\at*\at*\lam*\lam)))-(\e*\e/4+\at*\at*(-1+\lam))/(\at*\lam);
\mmu=(\tone-\tbeg)/(\psione-\phstartx);
\nnu=(\psione*\tbeg-\phstartx*\tone)/(\psione-\phstartx);
} 
\tikzstyle{scorestars}=[star, star points=5, star point ratio=2.25, draw, inner sep=1pt]%
\tikzstyle{scoresquare}=[draw,rectangle,minimum size=1mm,inner sep=0pt,outer sep=0pt]%
\begin{tikzpicture}[scale=\picscale,
declare function={
	testxonep(\ps,\t)=\a+\ps-\t;
	testxonem(\ps,\t)=\ps-\a+\t; 
	xa(\m,\n)=(-\ct*\m+\e*\m+\m*\n-sqrt(\ct*\ct*\lam*\lam+\e*\e*\m*\m+2*\e*\lam*\lam*\n+\lam*\lam*\n*\n-2*\ct*\lam*\lam*(\e+\n)))/(\lam*\lam-\m*\m);
	xb(\m,\n)=(-\ct*\m+\e*\m+\m*\n+sqrt(\ct*\ct*\lam*\lam+\e*\e*\m*\m+2*\e*\lam*\lam*\n+\lam*\lam*\n*\n-2*\ct*\lam*\lam*(\e+\n)))/(\lam*\lam-\m*\m);
	bl(\x)=\ct+\at-\e/2-1/2*(sqrt(\lam*\lam*pow(\x+\hae+\at,2)+\e*\e)-\e+\lam*(\x+\hae+\at));
	br(\x)=\ct+\at-\e/2-1/2*(sqrt(\lam*\lam*pow(\x-\hae-\at,2)+\e*\e)-\e-\lam*(\x-\hae-\at));
	bc(\x)=\ct+sqrt(\lam*\lam*\x*\x+\e*\e)-\e;
},
 ] 
\definecolor{tempcolor}{RGB}{250,190,0}
\definecolor{darkgreen}{RGB}{40,190,40}

\draw[->,blue, thick] [domain=-\at/2:-\lrange, samples=150]   plot (\x, {bl(\x)})  ;
\draw[blue, thick] [domain=-\at/2:\at/2, samples=150] plot (\x, {bc(\x)})   ;
\draw[->,blue, thick] [domain=\at/2:\rrange, samples=150]   plot (\x, {br(\x)})   ;
 \node[scale=\textscale]  at (2.7,4.1) {$S_i(y^a_1)$}; 

\draw[<->] (-\lrange, \h) node[left, scale=\textscale] {$S_0$} -- (\rrange, \h) node[right, scale=\textscale] {$S_0$};
\draw[<->] (-\lrange, \a) node[left, scale=\textscale] {$S$} -- (\rrange, \a) node[right, scale=\textscale] {$S$};
              
\draw[->, shorten <= 5pt,  shorten >= 1pt] (\psione,\h) node[below, scale=\textscale]{$\psi_1^{\text{sys}}$} node[above left, scale=\textscale]{$z_1$}-- (\psione,\a) ;
\draw[->,  shorten <= 5pt,  shorten >= 1pt] (\psitwo,\h) node[below, scale=\textscale]{$\psi_2^{\text{sys}}$} node[above right, scale=\textscale]{$z_2$}-- (\psitwo,\a);

\draw[dashed, tempcolor,  thick](\phstartx,\tbeg) node[below left=-2,scale=\textscale]{}--(\psione,\tone) node[above, pos=0.3, rotate=45,scale=0.7,black] {} node[below, pos=0.3, rotate=45,scale=0.7,black] {};
\draw[dashed, tempcolor](\psione,\tone) node[below left=-2,scale=\textscale]{}--(\psitwo,\ttwo );
\draw[dashed, tempcolor](\psitwo,\ttwo)--(\xend,\a); 
\draw[dashed, tempcolor,  thick](\psione,\tone)--(\xendz,\a);



%\draw[dashed, darkgreen, ultra thick](\psione,\tone)--(\psitwo,\tthree);
%\draw [black,fill] (\psitwo,\tthree) circle [radius=\circsize] node [black,below=4,right,scale=\textscale] {$2t_1-t_2$}; 


%\draw [black,fill] (\psione,\tone) circle [radius=\circsize] node [black,left=4,scale=\textscale] {$t_1$}; 
%\draw [black,fill](\psitwo,\ttwo)circle [radius=\circsize] node [black,above right,scale=\textscale, align=left] {$t_2$}; 

%\draw [decorate, decoration = {calligraphic brace}] (\psitwo+\nudge,\ttwo) --  (\psitwo+\nudge,\tone+\nudge/4) node[midway,right, scale=\textscale]{$t_2-t_1$}; 
%\draw [decorate, decoration = {calligraphic brace}] (\psitwo+\nudge,\tone-\nudge/4) --  (\psitwo+\nudge,2*\tone-\ttwo) node[midway,right, scale=\textscale]{$t_2-t_1$}; 

\draw[->] (\timex,\md-\tlen/2) --  (\timex,\md+\tlen/2) node[midway,right, scale=\textscale]{time}; 
 
\draw[dotted](\psione,\ttestx)--({testxonep(\psione,\ttestx)},\a);
\draw[dotted](\psione,\ttestx)--({testxonem(\psione,\ttestx)},\a);
%\draw [black,fill](\psione,\ttestx) circle [radius=\circsize] node [black,below=6,left,scale=\textscale] {$y^a_1$}; 
\draw (\psione,\ttestx) node[ scoresquare, fill=gray]  {} node [black,below=6,right,scale=\textscale] {$y^a_1$};
\draw (\psitwo, {bc(\psitwo)}) node[ scoresquare, fill=gray]  {} node [black,below=6,right,scale=\textscale] {$y^a_2$};
\draw ({xa(\mmu,\nnu)}, {xa(\mmu,\nnu)*\mmu+\nnu}) node[ scoresquare, fill=white]  {} node [black,left=7,below=-4,scale=\textscale] {$y^a_3$};

\draw[magenta,->,ultra thick] ({testxonem(\psione,\ttestx)},\a)--(-\lrange,\a);
\draw[magenta,->,ultra thick] ({testxonep(\psione,\ttestx)},\a)--(\rrange,\a);
%\draw [black,fill] (\xendz,\a) circle [radius=\circsize] node [black,above,scale=\textscale] {$\gamma_1$}; 
\end{tikzpicture}% pic 1

\vspace*{2px}
\caption{Depiction of a superposition of two local states at $z_1$ and $z_2$ before the photon has interacted with them. The gray squares indicate cells in $S^1(y^a_1)$ whose states are among the summands in (\ref{Sistate2}). The white square indicates a cell in $S_i(y^a_1)$ whose state is a factor in $\Xi$.}
\label{kentdeco1}
\end{figure}
The gray squares correspond to the summands that appear in (\ref{Sistate2}). If the system were in the $\psi_1^\text{sys}$-state, then the state describing $S_i(y^a_1)$ would have a factor $\ket{\psi_1^\text{sys}}\in H_1$ indicating that there is a 
non-zero mass at the $y^a_1$-cell, and there would also be a factor $\ket{0_2}\in H_2$ which we use to indicate that there is zero mass at $y^a_2$. 
There is also an incoming photon at the $y^a_3$-cell, and so we use $\ket{\gamma_3}$ to indicate that there is a photon there.
 Thus, if  the system  were in the $\psi_1^\text{sys}$-state, we would write the state of $S_i(y^a_1)$ 
 as $\ket{\Psi_i}=\ket{\psi_1^\text{sys}}\ket{0_2}\ket{\gamma_3}\Xi'$ where $\Xi'$ is describes the states of all the other cells of $S_i(y^a_1)$. 
 But on the other hand, if the system were in the state $\psi_2^\text{sys}$, then the state describing $S_i(y^a_1)$ would have a factor $\ket{\psi_2^\text{sys}}\in H_2$ 
 indicating that there is a non-zero mass at the $y^a_2$-cell, and there would also be a factor $\ket{0_1}\in H_1$ which we use to indicate that there is zero mass at $y^a_1$,
  and again the $y^a_3$-cell would be in the $\ket{\gamma_3}$, and every other cell would be described by  $\Xi'$  just as if the system had been in the $\psi_1^\text{sys}$-state. Therefore, when the system is in the state $\psi_2^\text{sys}$, we would write the state of $S_i(y^a_1)$ as $\ket{\Psi_i}=\ket{0_1}\ket{\psi_2^\text{sys}}\ket{\gamma_3}\Xi'$ 
 But since the system is actually in a supposition $\psi_0^\text{sys} = c_1\psi_1^\text{sys}+c_2\psi_2^\text{sys}$, the state of $S_i(y^a_1)$ will be 
 \begin{equation*}
 \ket{\Psi_i}=\big(c_1\ket{\psi_1^\text{sys}}\ket{0_2}+c_2\ket{0_1}\ket{\psi_2^\text{sys}}\big)\ket{\gamma_3}\Xi'=\big(c_1\ket{\psi_1^\text{sys}}\ket{0_2}+c_2\ket{0_1}\ket{\psi_2^\text{sys}}\big)\Xi
 \end{equation*}
where we have absorbed the $\ket{\gamma_3}$-state into $\Xi$ (i.e. $\Xi= \ket{\gamma_3}\Xi'$).

Now as it stands, the state $\ket{\Psi_i}$ describing $S_i(y^a_1)$ has a definite mass-energy density $\tau_S(x)$ for $x\in S_i(y^a_1)\cap S$. Thus if $\pi_i$ is the operator featuring in (\ref{kentconsistency0}) that corresponds to this definite mass-energy density, then $\pi_i\ket{\Psi_i}=\ket{\Psi_i}$. Therefore, equation (\ref{kentconsistency0}) for Kent's beables tells us that
$$\ev*{T^{\mu\nu}(y^a_1)}_{\tau_S}=\ev*{\hat{T}^{\mu\nu}(y^a_1)}{\Psi_i}.$$ 
where we have also used the fact that $\ip*{\Psi_i}{\Psi_i}=1.$

Now as we saw in section \ref{decotheory}, if we are interested only in the expectation values of observables for a system $\mathcal{S}$ contained within a universe $\mathcal{U}=\mathcal{S}+\mathcal{E}$ then the information needed to do this can be encapsulated in the reduced density matrix for $\mathcal{S}$. Thus, if the universe is described by a state 
$\ket{\Psi}=\sum_j c_j \ket{\psi_j}_\mathcal{S}\ket{E_j}$ with corresponding density matrix $\hat{\rho}=\dyad{\Psi}\in M(H_\mathcal{U})$, then the reduced density matrix $\hat{\rho}_\mathcal{S}\in M(H_\mathcal{S})$ is the operator that acts on the Hermitian operators of the state space $H_\mathcal{S}$ with the property that 
\begin{equation}\tag{\ref{reducedev} revisited}
\ev*{\hat{\Lambda}_\mathcal{U}}_\rho=\Tr_\mathcal{S}(\hat{\rho}_\mathcal{S}\hat{\Lambda}_\mathcal{S})
\end{equation}
where $\hat{\Lambda}_\mathcal{S}$ is an observable on $H_\mathcal{S}$  and $\hat{\Lambda}_\mathcal{U}$ is the corresponding observable on $H_\mathcal{U}$. Furthermore, we also have
\begin{equation}\label{reduced2}
\hat{\rho}_\mathcal{S}=\sum_j \abs{c_j}^2\dyad{\psi_j}+\sum_{j\neq k} c_j\overline{c_k}\ip{E_k}{E_j}\dyad{\psi_j}{\psi_k}.\protect\footnotemark
\end{equation}
\footnotetext{cf. (\ref{reduced})}
We can thus apply this to the situation at hand by taking $S_i$ to be our universe $\mathcal{U}$ and $y^a_1$ to be the system $\mathcal{S}$, and $S_i\setminus y^a_1$ to be the environment $\mathcal{E}$. If we assume that $\ip{0_2}{\psi_2^\text{sys}}\approx 0$, then by (\ref{reduced2}), the corresponding reduced density matrix $\hat{\rho}_{y^a_1}$ takes the form of an improper mixture
\begin{equation}\label{kentred}
\hat{\rho}_{y^a_1}\approx \abs{c_1}^2\dyad{\psi_1^\text{sys}}+\abs{c_2}^2\dyad{0_1}
\end{equation}
Kent's beables at $y^a_1$ will thus take the form 
\begin{equation}\label{kentbe}
\begin{split}
\ev*{T^{\mu\nu}(y^a_1)}_{\tau_S}&=\Tr_{y^a_1}(\hat{\rho}_{y^a_1}\hat{T}^{\mu\nu}(y^a_1))\\
&=\abs{c_1}^2\ev*{\hat{T}^{\mu\nu}(y^a_1)}{\psi_1^\text{sys}}+\abs{c_2}^2\ev*{\hat{T}^{\mu\nu}(y^a_1)}{0_1}.
\end{split}
\end{equation}

Let us now consider Kent's beables at the spacetime location $y^b_1$ depicted in figure 
 
\begin{figure}[ht!]
\captionsetup{justification=justified}
\centering
\tikzmath{
\a=5.3;  
\psione=0;
\psitwo=1.5;
\h=1;
\labelx=(\psione+\psitwo)/2;
\labely=-1.5;
\phstartx=-1.7;
\phstarty=\h;
\tbeg=\phstarty;
\ca=\phstartx-\tbeg;
\ttwo=\psitwo-\ca;
\cb=\ttwo+\ca;
\xend=\ttwo-\a+\cb;
\tone=\psione-\ca;
\cc=\tone+\ca;
\xendz=\tone-\a+\cc;
\tthree=\cc+\tone-\psitwo;
\circsize=0.08;
\md = (\a+\h)/2;
\tlen=0.75;
\textscale = 0.7;
\picscale = 0.89;
\nudge=0.1;
\tnudge=(\ttwo-\tone)/2+0.8;
\ttesta=2*\tone-\ttwo-\tnudge;
\ttestb=2*\tone-\ttwo+\tnudge;
\ttestc=\ttwo-\tnudge;
\ttestd=\ttwo+\tnudge;
\sonea=\a+\psione-\ttesta;
\sadd=0.5;
\lrange = -(\psione-\a+\ttesta)+\sadd;
\rrange =\lrange; 
\timex=\rrange-1.5;
\e = 0.4;
\ttestx=3.0;
\at=\a-\ttestx;
\ct=\ttestx;
\lam = 0.87;
\e = 0.2;
\hae=(2*pow(\at,3)*\lam*(2+\lam)+\e*\e*(2*\e-sqrt(4*\e*\e+\at*\at*\lam*\lam))-8*\at*\e*(-2*\e+sqrt(4*\e*\e+\at*\at*\lam*\lam))-2*\at*\at*(2+\lam)*(-2*\e+sqrt(4*\e*\e+\at*\at*\lam*\lam)))/(4*\at*\lam*(2*\at+2*\e-sqrt(4*\e*\e+\at*\at*\lam*\lam)))-(\e*\e/4+\at*\at*(-1+\lam))/(\at*\lam);
\mmu=(\tone-\tbeg)/(\psione-\phstartx);
\nnu=(\psione*\tbeg-\phstartx*\tone)/(\psione-\phstartx);
\muf=(\a-\tone)/(\xendz-\psione);
\nuf=(\xendz*\tone-\psione*\a)/(\xendz-\psione);
} 
\tikzstyle{scorestars}=[star, star points=5, star point ratio=2.25, draw, inner sep=1pt]%
\tikzstyle{scoresquare}=[draw,rectangle,minimum size=1mm,inner sep=0pt,outer sep=0pt]%
\begin{tikzpicture}[scale=\picscale,
declare function={
	testxonep(\ps,\t)=\a+\ps-\t;
	testxonem(\ps,\t)=\ps-\a+\t; 
	xa(\m,\n)=(-\ct*\m+\e*\m+\m*\n-sqrt(\ct*\ct*\lam*\lam+\e*\e*\m*\m+2*\e*\lam*\lam*\n+\lam*\lam*\n*\n-2*\ct*\lam*\lam*(\e+\n)))/(\lam*\lam-\m*\m);
	xb(\m,\n)=(-\ct*\m+\e*\m+\m*\n+sqrt(\ct*\ct*\lam*\lam+\e*\e*\m*\m+2*\e*\lam*\lam*\n+\lam*\lam*\n*\n-2*\ct*\lam*\lam*(\e+\n)))/(\lam*\lam-\m*\m);
	bl(\x)=\ct+\at-\e/2-1/2*(sqrt(\lam*\lam*pow(\x+\hae+\at,2)+\e*\e)-\e+\lam*(\x+\hae+\at));
	br(\x)=\ct+\at-\e/2-1/2*(sqrt(\lam*\lam*pow(\x-\hae-\at,2)+\e*\e)-\e-\lam*(\x-\hae-\at));
	bc(\x)=\ct+sqrt(\lam*\lam*\x*\x+\e*\e)-\e;
},
 ] 
\definecolor{tempcolor}{RGB}{250,190,0}
\definecolor{darkgreen}{RGB}{40,190,40}

\draw[->,blue, thick] [domain=-\at/2:-\lrange, samples=150]   plot (\x, {bl(\x)})  ;
\draw[blue, thick] [domain=-\at/2:\at/2, samples=150] plot (\x, {bc(\x)})  node[right=20, above=10,black,scale=\textscale]{}  ;
\draw[->,blue, thick] [domain=\at/2:\rrange, samples=150]   plot (\x, {br(\x)})   ;

 \node[scale=\textscale]  at (2.7,4.6) {$S_i(y^b_1)$}; 
\draw[<->] (-\lrange, \h) node[left, scale=\textscale] {$S_0$} -- (\rrange, \h) node[right, scale=\textscale] {$S_0$};
\draw[<->] (-\lrange, \a) node[left, scale=\textscale] {$S$} -- (\rrange, \a) node[right, scale=\textscale] {$S$};
              
\draw[->, shorten <= 5pt,  shorten >= 1pt] (\psione,\h) node[below, scale=\textscale]{$\psi_1^{\text{sys}}$} node[above left, scale=\textscale]{$z_1$}-- (\psione,\a) ;
\draw[->,  shorten <= 5pt,  shorten >= 1pt] (\psitwo,\h) node[below, scale=\textscale]{$\psi_2^{\text{sys}}$} node[above right, scale=\textscale]{$z_2$}-- (\psitwo,\a);

\draw[dashed, tempcolor,  thick](\phstartx,\tbeg) node[below left=-2,scale=\textscale]{}--(\psione,\tone) node[above, pos=0.3, rotate=45,scale=0.7,black] {} node[below, pos=0.3, rotate=45,scale=0.7,black] {};
\draw[dashed, tempcolor,  thick](\psione,\tone) node[below left=-2,scale=\textscale]{}--(\psitwo,\ttwo );
\draw[dashed, tempcolor,  thick](\psitwo,\ttwo)--(\xend,\a); 
\draw[dashed, tempcolor, thick](\psione,\tone)--(\xendz,\a);





\draw[->] (\timex,\md-\tlen/2) --  (\timex,\md+\tlen/2) node[midway,right, scale=\textscale]{time}; 
 
\draw[dotted](\psione,\ttestx)--({testxonep(\psione,\ttestx)},\a);
\draw[dotted](\psione,\ttestx)--({testxonem(\psione,\ttestx)},\a);
%\draw [black,fill](\psione,\ttestx) circle [radius=\circsize] node [black,below=6,left,scale=\textscale] {$y^b_1$}; 
\draw (\psione,\ttestx) node[ scoresquare, fill=gray]  {} node [black,below=6,right,scale=\textscale] {$y^b_1$};
\draw (\psitwo, {bc(\psitwo)}) node[ scoresquare, fill=gray]  {} node [black,below=6,right,scale=\textscale] {$y^b_2$};
\draw ({xa(\mmu,\nnu)}, {xa(\mmu,\nnu)*\mmu+\nnu}) node[ scoresquare, fill=gray]  {} node [black,below=3,scale=\textscale] {$y^b_4$};
\draw ({xb(\muf,\nuf)}, {xb(\muf,\nuf)*\muf+\nuf}) node[ scoresquare, fill=gray]  {} node [black,below=3,scale=\textscale] {$y^b_3$};

\draw[magenta,->,ultra thick] ({testxonem(\psione,\ttestx)},\a)--(-\lrange,\a);
\draw[magenta,->,ultra thick] ({testxonep(\psione,\ttestx)},\a)--(\rrange,\a);
%\draw [black,fill] (\xendz,\a) circle [radius=\circsize] node [black,above,scale=\textscale] {$\gamma_1$}; 
\end{tikzpicture}% pic 1

\vspace*{2px}
\caption{Depiction of a superposition of two local states at $z_1$ and $z_2$ with $S_i(y^b_1)$ being after the photon has interacted without the photon intersecting $S_i(y^b_1)\cap S$. The gray squares indicate cells in $S^1(y^b_1)$ whose states are among the summands in (\ref{Sistate2}).}
\label{kentdecoh2}
\end{figure}
The state of $S_i(y^b_1)$ will then be
 \begin{equation*}
 \ket{\Psi_i}=\big(c_1\ket{\psi_1^\text{sys}}\ket{0_2}\ket{\gamma_3}\ket{0_4}+c_2\ket{0_1}\ket{\psi_2^\text{sys}}\ket{0_3}\ket{\gamma_4}\big)\Xi
 \end{equation*}
 where the notation is analogous to that in the previous example. Since no photon detections are registered on $S_i(y^b_1)\cap S$, we again have $\pi_i\ket{\Psi_i}=\ket{\Psi_i}$ so that the reduced density matrix $\hat{\rho}_{y_1^b}$ will again be given by  (\ref{kentred}) with $y^a_1$ replaced by $y^b_1$, and likewise,  Kent's beables $\ev*{T^{\mu\nu}(y^b_1)}_{\tau_S}$ will be given by (\ref{kentbe}).

For the next example, we consider the case 


\begin{figure}[ht!]
\captionsetup{justification=justified}
\centering
\tikzmath{
\a=5.3;  
\psione=0;
\psitwo=1.5;
\h=1;
\labelx=(\psione+\psitwo)/2;
\labely=-1.5;
\phstartx=-1.7;
\phstarty=\h;
\tbeg=\phstarty;
\ca=\phstartx-\tbeg;
\ttwo=\psitwo-\ca;
\cb=\ttwo+\ca;
\xend=\ttwo-\a+\cb;
\tone=\psione-\ca;
\cc=\tone+\ca;
\xendz=\tone-\a+\cc;
\tthree=\cc+\tone-\psitwo;
\circsize=0.08;
\md = (\a+\h)/2;
\tlen=0.75;
\textscale = 0.7;
\picscale = 0.89;
\nudge=0.1;
\tnudge=(\ttwo-\tone)/2+0.8;
\ttesta=2*\tone-\ttwo-\tnudge;
\ttestb=2*\tone-\ttwo+\tnudge;
\ttestc=\ttwo-\tnudge;
\ttestd=\ttwo+\tnudge;
\sonea=\a+\psione-\ttesta;
\sadd=0.5;
\lrange = -(\psione-\a+\ttesta)+\sadd;
\rrange =\lrange; 
\timex=\rrange-1.5;
\e = 0.4;
\ttestx=4;
\at=\a-\ttestx;
\ct=\ttestx;
\lam = 0.87;
\e = 0.2;
\hae=(2*pow(\at,3)*\lam*(2+\lam)+\e*\e*(2*\e-sqrt(4*\e*\e+\at*\at*\lam*\lam))-8*\at*\e*(-2*\e+sqrt(4*\e*\e+\at*\at*\lam*\lam))-2*\at*\at*(2+\lam)*(-2*\e+sqrt(4*\e*\e+\at*\at*\lam*\lam)))/(4*\at*\lam*(2*\at+2*\e-sqrt(4*\e*\e+\at*\at*\lam*\lam)))-(\e*\e/4+\at*\at*(-1+\lam))/(\at*\lam);
\mmu=(\tone-\tbeg)/(\psione-\phstartx);
\nnu=(\psione*\tbeg-\phstartx*\tone)/(\psione-\phstartx);
\muf=(\a-\ttwo)/(\xend-\psitwo);
\nuf=(\xend*\ttwo-\psitwo*\a)/(\xend-\psitwo);
} 
\tikzstyle{scorestars}=[star, star points=5, star point ratio=2.25, draw, inner sep=1pt]%
\tikzstyle{scoresquare}=[draw,rectangle,minimum size=1mm,inner sep=0pt,outer sep=0pt]%
\begin{tikzpicture}[scale=\picscale,
declare function={
	testxonep(\ps,\t)=\a+\ps-\t;
	testxonem(\ps,\t)=\ps-\a+\t; 
	xa(\m,\n)=(-\ct*\m+\e*\m+\m*\n-sqrt(\ct*\ct*\lam*\lam+\e*\e*\m*\m+2*\e*\lam*\lam*\n+\lam*\lam*\n*\n-2*\ct*\lam*\lam*(\e+\n)))/(\lam*\lam-\m*\m);
	xb(\m,\n)=(-\ct*\m+\e*\m+\m*\n+sqrt(\ct*\ct*\lam*\lam+\e*\e*\m*\m+2*\e*\lam*\lam*\n+\lam*\lam*\n*\n-2*\ct*\lam*\lam*(\e+\n)))/(\lam*\lam-\m*\m);
	bl(\x)=\ct+\at-\e/2-1/2*(sqrt(\lam*\lam*pow(\x+\hae+\at,2)+\e*\e)-\e+\lam*(\x+\hae+\at));
	br(\x)=\ct+\at-\e/2-1/2*(sqrt(\lam*\lam*pow(\x-\hae-\at,2)+\e*\e)-\e-\lam*(\x-\hae-\at));
	bc(\x)=\ct+sqrt(\lam*\lam*\x*\x+\e*\e)-\e;
},
 ] 
\definecolor{tempcolor}{RGB}{250,190,0}
\definecolor{darkgreen}{RGB}{40,190,40}

\draw[->,blue, thick] [domain=-\at/2:-\lrange, samples=150]   plot (\x, {bl(\x)})  ;
\draw[blue, thick] [domain=-\at/2:\at/2, samples=150] plot (\x, {bc(\x)})  node[right=20, above=10,black,scale=\textscale]{}  ;
\draw[->,blue, thick] [domain=\at/2:\rrange, samples=150]   plot (\x, {br(\x)})   ;

 \node[scale=\textscale]  at (1,4.1) {$S_i(y^c_1)$}; 
\draw[<->] (-\lrange, \h) node[left, scale=\textscale] {$S_0$} -- (\rrange, \h) node[right, scale=\textscale] {$S_0$};
\draw[<->] (-\lrange, \a) node[left, scale=\textscale] {$S$} -- (\rrange, \a) node[right, scale=\textscale] {$S$};
              
\draw[->, shorten <= 5pt,  shorten >= 1pt] (\psione,\h) node[below, scale=\textscale]{$\psi_1^{\text{sys}}$} node[above left, scale=\textscale]{$z_1$}-- (\psione,\a) ;
\draw[->,  shorten <= 5pt,  shorten >= 1pt] (\psitwo,\h) node[below, scale=\textscale]{$\psi_2^{\text{sys}}$} node[above right, scale=\textscale]{$z_2$}-- (\psitwo,\a);

\draw[dashed, tempcolor,  thick](\phstartx,\tbeg) node[below left=-2,scale=\textscale]{}--(\psione,\tone) node[above, pos=0.3, rotate=45,scale=0.7,black] {} node[below, pos=0.3, rotate=45,scale=0.7,black] {};
\draw[dashed, tempcolor,  thick](\psione,\tone) node[below left=-2,scale=\textscale]{}--(\psitwo,\ttwo );
\draw[dashed, tempcolor,  thick](\psitwo,\ttwo)--(\xend,\a); 
\draw[dashed, tempcolor,  thick](\psione,\tone)--(\xendz,\a);

\draw[magenta,->,ultra thick] ({testxonem(\psione,\ttestx)},\a)--(-\lrange,\a);
\draw[magenta,->,ultra thick] ({testxonep(\psione,\ttestx)},\a)--(\rrange,\a);



\draw[->] (\timex,\md-\tlen/2) --  (\timex,\md+\tlen/2) node[midway,right, scale=\textscale]{time}; 
 
\draw[dotted](\psione,\ttestx)--({testxonep(\psione,\ttestx)},\a);
\draw[dotted](\psione,\ttestx)--({testxonem(\psione,\ttestx)},\a);
%\draw [black,fill](\psione,\ttestx) circle [radius=\circsize] node [black,below=6,left,scale=\textscale] {$y^c_1$}; 
\draw (\psione,\ttestx) node[ scoresquare, fill=gray]  {} node [black,below=6,right,scale=\textscale] {$y^c_1$};
\draw (\psitwo, {bc(\psitwo)}) node[ scoresquare, fill=gray]  {} node [black,below=6,right,scale=\textscale] {$y^c_2$};
\draw ({xb(\muf,\nuf)}, {xb(\muf,\nuf)*\muf+\nuf}) node[ scoresquare, fill=gray]  {} node [black,right=7, below=-4,scale=\textscale] {$y^c_4$};
\draw (\xendz,\a) node[ scoresquare, fill=gray]  {} node [black,below=3,scale=\textscale] {$y^c_3$};


%\draw [black,fill] (\xendz,\a) circle [radius=\circsize] node [black,above,scale=\textscale] {$\gamma_1$}; 
\end{tikzpicture}% pic 1

\vspace*{2px}
\caption{Depiction of a superposition of two local states at $z_1$ and $z_2$ with $y^c_1$ sufficiently late that the photon intersects $S_i(y^c_1)\cap S$. The gray squares indicate cells in $S^1(y^c_1)$ whose states are among the summands in (\ref{Sistate2})}
\label{kentdecoh3}
\end{figure}

In this case, the state of $S_i(y^c_1)$ will be
 \begin{equation*}
 \ket{\Psi_i}=\big(c_1\ket{\psi_1^\text{sys}}\ket{0_2}\ket{\gamma_3}\ket{0_4}+c_2\ket{0_1}\ket{\psi_2^\text{sys}}\ket{0_3}\ket{\gamma_4}\big)\Xi
 \end{equation*}
 but this time we have to consider the fact that the photon intersects $S_i(y^c_1)\cap S$. There are two possible (notional) measurements outcomes that can occur on $S_i(y^c_1)\cap S$: either $T_S=\tau_{S,1}$ where $\tau_{S,1}(y^c_3)\neq 0$ or $T_S=\tau_{S,2}$ where $\tau_{S,2}(y^c_3)=0.$ The case  $T_S=\tau_{S,1}$ indicates that there is a photon detection at $y^c_3$ so that the local state at the $y^c_3$-cell is $\ket{\gamma_3}$. Therefore, if we write $\pi_{i,1}$ for the operator $\pi_i$, we have 
 $$\pi_{i,1}\ket{\Psi_i}=c_1\ket{\psi_1^\text{sys}}\ket{0_2}\ket{\gamma_3}\ket{0_4}\Xi,$$
 Therefore 
 $\ev*{\pi_{i,1}\hat{T}^{\mu\nu}(y^c_1)}{\Psi_i}=\abs{c_1}^2\ev*{\hat{T}^{\mu\nu}(y^c_1)}{\psi_1^\text{sys}}$ and  $\ev*{\pi_{i,1}}{\Psi_i}=\abs{c_1}^2$. Hence, by (\ref{kentconsistency0}), Kent's beables at $y^c_1$ will be 
 $$\ev*{T^{\mu\nu}(y^c_1)}_{\tau_{S,1}}=\ev*{\hat{T}^{\mu\nu}(y^c_1)}{\psi_1^\text{sys}}.$$ 
 From this, it follows that the reduced density matrix at $y^c_1$ will take the form of a pure state:
 \begin{equation}
\hat{\rho}_{y^c_1}\approx \dyad{\psi_1^\text{sys}}.
\end{equation} 
 On the other hand, for the case when  $T_S=\tau_{S,2}$, this indicates that there is no photon detection at $y^c_3$, so that the local state at the $y^c_3$-cell will be $\ket{0_3}$. So if now we write $\pi_{i,2}$ for the operator $\pi_i$, we have 
 $$\pi_{i,2}\ket{\Psi_i}=c_2\ket{0_1}\ket{\psi_2^\text{sys}}\ket{0_3}\ket{\gamma_4}\Xi.$$
 Therefore 
 $\ev*{\pi_{i,2}\hat{T}^{\mu\nu}(y^c_1)}{\Psi_i}=\abs{c_2}^2\ev*{\hat{T}^{\mu\nu}(y^c_1)}{0_1}$ and  $\ev*{\pi_{i,2}}{\Psi_i}=\abs{c_2}^2$,  
  and so by (\ref{kentconsistency0}), Kent's beables at $y^c_1$ will be 
 $$\ev*{T^{\mu\nu}(y^c_1)}_{\tau_{S,2}}=\ev*{\hat{T}^{\mu\nu}(y^c_1)}{0_1}.$$
 In this case, the reduced density matrix at $y^c_1$  will be
  \begin{equation}
\hat{\rho}_{y^c_1}\approx \dyad{0_1},
\end{equation} 
which is again a pure state.

In the final example, we introduce an atom at a spatial location $z_3$ initially in its ground state, and suppose that it can't interact with the incoming photon, but that after the photon's interaction with the two local states at $z_1$ and $z_2$, the atom at spacetime location $y^c_3$ can either absorb the photon with probability $\abs{d_+}^2$ or not absorb the photon with probability  $\abs{d_-}^2$ as depicted in figure \ref{kentdecoh4}.
 
\begin{figure}[ht!]
\captionsetup{justification=justified}
\centering
\tikzmath{
\a=5.3;  
\psione=0;
\psitwo=1.5;
\psithree=-0.7;
\h=1;
\labelx=(\psione+\psitwo)/2;
\labely=-1.5;
\phstartx=-1.7;
\phstarty=\h;
\tbeg=\phstarty;
\ca=\phstartx-\tbeg;
\ttwo=\psitwo-\ca;
\cb=\ttwo+\ca;
\xend=\ttwo-\a+\cb;
\tone=\psione-\ca;
\cc=\tone+\ca;
\xendz=\tone-\a+\cc;
\tthree=\cc+\tone-\psitwo;
\circsize=0.08;
\md = (\a+\h)/2;
\tlen=0.75;
\textscale = 0.7;
\picscale = 0.89;
\nudge=0.1;
\tnudge=(\ttwo-\tone)/2+0.8;
\ttesta=2*\tone-\ttwo-\tnudge;
\ttestb=2*\tone-\ttwo+\tnudge;
\ttestc=\ttwo-\tnudge;
\ttestd=\ttwo+\tnudge;
\sonea=\a+\psione-\ttesta;
\sadd=0.5;
\lrange = -(\psione-\a+\ttesta)+\sadd;
\rrange =\lrange; 
\timex=\rrange-1.5;
\e = 0.4;
\ttestx=4;
\at=\a-\ttestx;
\ct=\ttestx;
\lam = 0.87;
\e = 0.2;
\hae=(2*pow(\at,3)*\lam*(2+\lam)+\e*\e*(2*\e-sqrt(4*\e*\e+\at*\at*\lam*\lam))-8*\at*\e*(-2*\e+sqrt(4*\e*\e+\at*\at*\lam*\lam))-2*\at*\at*(2+\lam)*(-2*\e+sqrt(4*\e*\e+\at*\at*\lam*\lam)))/(4*\at*\lam*(2*\at+2*\e-sqrt(4*\e*\e+\at*\at*\lam*\lam)))-(\e*\e/4+\at*\at*(-1+\lam))/(\at*\lam);
\mmu=(\a-\tone)/(\xendz-\psione);
\nnu=(\xendz*\tone-\psione*\a)/(\xendz-\psione);
\muf=(\a-\ttwo)/(\xend-\psitwo);
\nuf=(\xend*\ttwo-\psitwo*\a)/(\xend-\psitwo);
} 
\tikzstyle{scorestars}=[star, star points=5, star point ratio=2.25, draw, inner sep=1pt]%
\tikzstyle{scoresquare}=[draw,rectangle,minimum size=1mm,inner sep=0pt,outer sep=0pt]%
\begin{tikzpicture}[scale=\picscale,
declare function={
	testxonep(\ps,\t)=\a+\ps-\t;
	testxonem(\ps,\t)=\ps-\a+\t; 
	xa(\m,\n)=(-\ct*\m+\e*\m+\m*\n-sqrt(\ct*\ct*\lam*\lam+\e*\e*\m*\m+2*\e*\lam*\lam*\n+\lam*\lam*\n*\n-2*\ct*\lam*\lam*(\e+\n)))/(\lam*\lam-\m*\m);
	xb(\m,\n)=(-\ct*\m+\e*\m+\m*\n+sqrt(\ct*\ct*\lam*\lam+\e*\e*\m*\m+2*\e*\lam*\lam*\n+\lam*\lam*\n*\n-2*\ct*\lam*\lam*(\e+\n)))/(\lam*\lam-\m*\m);
	bl(\x)=\ct+\at-\e/2-1/2*(sqrt(\lam*\lam*pow(\x+\hae+\at,2)+\e*\e)-\e+\lam*(\x+\hae+\at));
	br(\x)=\ct+\at-\e/2-1/2*(sqrt(\lam*\lam*pow(\x-\hae-\at,2)+\e*\e)-\e-\lam*(\x-\hae-\at));
	bc(\x)=\ct+sqrt(\lam*\lam*\x*\x+\e*\e)-\e;
},
 ] 
\definecolor{tempcolor}{RGB}{250,190,0}
\definecolor{darkgreen}{RGB}{40,190,40}

\draw[->,blue, thick] [domain=-\at/2:-\lrange, samples=150]   plot (\x, {bl(\x)})  ;
\draw[blue, thick] [domain=-\at/2:\at/2, samples=150] plot (\x, {bc(\x)})  node[right=20, above=10,black,scale=\textscale]{}  ;
\draw[->,blue, thick] [domain=\at/2:\rrange, samples=150]   plot (\x, {br(\x)})   ;

 \node[scale=\textscale]  at (1,4.1) {$S_i(y^d_1)$}; 
\draw[<->] (-\lrange, \h) node[left, scale=\textscale] {$S_0$} -- (\rrange, \h) node[right, scale=\textscale] {$S_0$};
\draw[<->] (-\lrange, \a) node[left, scale=\textscale] {$S$} -- (\rrange, \a) node[right, scale=\textscale] {$S$};
              
\draw[->, shorten <= 5pt,  shorten >= 1pt] (\psione,\h) node[below, scale=\textscale]{$\psi_1^{\text{sys}}$} node[above left, scale=\textscale]{$z_1$}-- (\psione,\a) ;
\draw[->,  shorten <= 5pt,  shorten >= 1pt] (\psitwo,\h) node[below, scale=\textscale]{$\psi_2^{\text{sys}}$} node[above right, scale=\textscale]{$z_2$}-- (\psitwo,\a);
\draw[->,  shorten <= 5pt,  shorten >= 1pt] (\psithree,\h) node[below, scale=\textscale]{$\psi_{3}^{\pm}$}   node[above left, scale=\textscale]{$z_3$}-- (\psithree,\a);


\draw[dashed, tempcolor,  thick](\phstartx,\tbeg) node[below left=-2,scale=\textscale]{}--(\psione,\tone) node[above, pos=0.3, rotate=45,scale=0.7,black] {} node[below, pos=0.3, rotate=45,scale=0.7,black] {};
\draw[dashed, tempcolor,  thick](\psione,\tone) node[below left=-2,scale=\textscale]{}--(\psitwo,\ttwo );
\draw[dashed, tempcolor,  thick](\psitwo,\ttwo)--(\xend,\a); 
\draw[dashed, tempcolor,  thick](\psione,\tone)--(\xendz,\a);

\draw[magenta,->,ultra thick] ({testxonem(\psione,\ttestx)},\a)--(-\lrange,\a);
\draw[magenta,->,ultra thick] ({testxonep(\psione,\ttestx)},\a)--(\rrange,\a);



\draw[->] (\timex,\md-\tlen/2) --  (\timex,\md+\tlen/2) node[midway,right, scale=\textscale]{time}; 
 
\draw[dotted](\psione,\ttestx)--({testxonep(\psione,\ttestx)},\a);
\draw[dotted](\psione,\ttestx)--({testxonem(\psione,\ttestx)},\a);
%\draw [black,fill](\psione,\ttestx) circle [radius=\circsize] node [black,below=6,left,scale=\textscale] {$y^d_1$}; 
\draw (\psione,\ttestx) node[ scoresquare, fill=gray]  {} node [black,below=6,right,scale=\textscale] {$y^d_1$};
\draw (\psitwo, {bc(\psitwo)}) node[ scoresquare, fill=gray]  {} node [black,below=6,right,scale=\textscale] {$y^d_2$};
\draw ({xb(\muf,\nuf)}, {xb(\muf,\nuf)*\muf+\nuf}) node[ scoresquare, fill=gray]  {} node [black,right=7, below=-4,scale=\textscale] {$y^d_5$};
\draw (\xendz,\a) node[ scoresquare, fill=gray]  {} node [black,below=3,scale=\textscale] {$y^d_4$};
\draw (\psithree, {bc(\psithree)}) node[ scoresquare, fill=gray]  {} node [black,below=6,left,scale=\textscale] {$y^d_3$};

\draw [black,fill] (\psithree,\psithree*\mmu+\nnu) circle [radius=\circsize] ; 
\end{tikzpicture}% pic 1

\vspace*{2px}
\caption{Depiction of a superposition of two local states at $z_1$ and $z_2$ with $y^c_1$ sufficiently late that the photon can intersect with $S_i(y^c_1)\cap S$, but there is also an atom at $z_3$ that can absorb the photon. The gray squares indicate cells in $S^1(y^d_1)$ whose states are among the summands in (\ref{Sistate2})} 
\label{kentdecoh4}
\end{figure}
If the  atom at $y^d_3$ absorbs the photon it will go into a higher energy state $\ket{\psi^{+}_{3}}$, whereas if it  does not absorb the photon, it will remain in its lower energy state $\ket{\psi^{-}_{3}}$. The state of $S_i(y^d_1)$ will thus be
 \begin{equation*}
 \ket{\Psi_i}=\big(c_1\ket{\psi_1^\text{sys}}\ket{0_2}\big(d_+\ket{\psi^{+}_{3}}\ket{0_4}+d_-\ket{\psi^{-}_{3}}\ket{\gamma_4}\big)\ket{0_5}+c_2\ket{0_1}\ket{\psi_2^\text{sys}}\ket{\psi^{-}_{3}}\ket{0_4}\ket{\gamma_5}\big)\Xi.
 \end{equation*}
As in the previous example,  there are two (notional) measurements that can occur $S_i(y^d_1)\cap S$: either $T_S=\tau_{S,1}$ where $\tau_{S,1}(y^d_4)\neq 0$ or $T_S=\tau_{S,2}$ where $\tau_{S,2}(y^d_4)=0.$ The case  $T_S=\tau_{S,1}$ indicates that there is a photon detection at $y^d_4$ so that the local state at the $y^d_3$-cell is $\ket{\gamma_4}$. Therefore, if we write $\pi_{i,1}$ for the operator $\pi_i$, we have 
 $$\pi_{i,1}\ket{\Psi_i}=c_1d_-\ket{\psi_1^\text{sys}}\ket{0_2}\ket{\psi^{-}_{3}}\ket{\gamma_4}\ket{0_5}\Xi.$$
 Therefore  
 $\ev*{\pi_{i,1}\hat{T}^{\mu\nu}(y^d_1)}{\Psi_i}=\abs{c_1 d_-}^2\ev*{\hat{T}^{\mu\nu}(y^d_1)}{\psi_1^\text{sys}}$ and  $\ev*{\pi_{i,1}}{\Psi_i}=\abs{c_1d_-}^2$,  
  and so by (\ref{kentconsistency0}), Kent's beables at $y^d_1$ will be 
 $$\ev*{T^{\mu\nu}(y^d_1)}_{\tau_{S,1}}=\ev*{\hat{T}^{\mu\nu}(y^d_1)}{\psi_1^\text{sys}}.$$ 
and the reduced density matrix at $y^d_1$ will be the pure state
 \begin{equation}
\hat{\rho}_{y^d_1}\approx \dyad{\psi_1^\text{sys}}.
\end{equation} 
 On the other hand, for the case when  $T_S=\tau_{S,2}$, writing $\pi_{i,2}$ for the operator $\pi_i$, we have 
 $$\pi_{i,2}\ket{\Psi_i}=\big(c_1\ket{\psi_1^\text{sys}}\ket{0_2}d_+\ket{\psi^{+}_{3}}\ket{0_4}\ket{0_5}+c_2\ket{0_1}\ket{\psi_2^\text{sys}}\ket{\psi^{-}_{3}}\ket{0_4}\ket{\gamma_5}\big)\Xi.$$
 Therefore 
 $\ev*{\pi_{i,2}\hat{T}^{\mu\nu}(y^c_1)}{\Psi_i}=\abs{c_1 d_+}^2\ev*{\hat{T}^{\mu\nu}(y^d_1)}{\psi_1^\text{sys}}+\abs{c_2}^2\ev*{\hat{T}^{\mu\nu}(y^c_1)}{0_1}$ and  $\ev*{\pi_{i,2}}{\Psi_i}=\abs{c_1 d_+}^2+\abs{c_2}^2$.
Hence by (\ref{kentconsistency0}), Kent's beables at $y^d_1$ will be 
 $$\ev*{T^{\mu\nu}(y^d_1)}_{\tau_{S,2}}=\frac{\abs{c_1 d_+}^2\ev*{\hat{T}^{\mu\nu}(y^d_1)}{\psi_1^\text{sys}}+\abs{c_2}^2\ev*{\hat{T}^{\mu\nu}(y^c_1)}{0_1}}{\abs{c_1 d_+}^2+\abs{c_2}^2},$$
and the reduced density matrix at $y^d_1$  will take the form of an improper mixture:
  \begin{equation}
\hat{\rho}_{y^d_1}\approx \frac{ \abs{c_1 d_+}^2\dyad{\psi_1^\text{sys}}+\abs{c_2}^2\dyad{0_1}}{\abs{c_1 d_+}^2+\abs{c_2}^2}.
\end{equation} 


\subsection{An objection to Kent's beables}
In the examples of the last subsection we have seen how the additional information concerning photon detection on $S_i(y_1)\cap S$ is able to determine whether the reduced density matrix at $y_1$ is a pure state or an improper mixture. As already mentioned, according to d'Espagnat, if the reduced density matrix for a system is an improper mixture, we are not entitled to give it an ignorance interpretation, and thus we are unable to say that an outcome has occurred. However, if the reduced density matrix of a system goes from being an improper mixture to a pure state state of the form $\dyad{\psi}$, then we can say that an outcome has occurred, namely that the system is in the state $\ket{\psi}.$  

There is still the question of why Kent decides that the beables of his theory should take the form of expectation values. As an analogy, it seems a bit like saying a six sided dice can actually come up with a $3.5$ since this is its expectation value. We can however address this objection if can find a way of having multiple throws of the dice, so to speak. My suggestion is to stipulate that the reduced density matrices $\hat{\rho}_y$ as calculated in the previous section are more fundamental beables than the conditional expectation values of $\hat{T}_{\mu,\nu}(y)$, and that the determinate value of $T_S$ is more fundamental still. There are a few things I need to explain here such as what I mean fundamental, what I mean by saying a beable is a reduced density matrix, and how the beable of a reduced density matrix can give rise to Kent's expectation value beables.

By saying that the determinate value of $T_S$ is more fundamental than the reduced density matrices,  I mean that if we have a statements of the form ``the beable at $y$ is $\hat{\rho}_y$'', then such a statement is reducible to statements about $T_S$. Such statements might be simple factual statements such as ``there is photon is at $x_1$, and $x_2$ but not at $x_3$ or $x_4$'' where the locations are indicated in figure \ref{kentdecoh5}.

\begin{figure}[ht!]
\captionsetup{justification=justified}
\centering
\tikzmath{
\a=5.3;  
\psione=0;
\psitwo=1.5;
\psithree=-0.7;
\h=1;
\labelx=(\psione+\psitwo)/2;
\labely=-1.5;
\phstartx=-1.7;
\phstartxx=-0.9;
\phstarty=\h;
\tbeg=\phstarty;
\ca=\phstartx-\tbeg;
\caa=\phstartxx-\tbeg;
\ttwo=\psitwo-\ca;
\ttwoo=\psitwo-\caa;
\cb=\ttwo+\ca;
\cbb=\ttwoo+\caa;
\xend=\ttwo-\a+\cb;
\xendd=\ttwoo-\a+\cbb;
\tone=\psione-\ca;
\tonee=\psione-\caa;
\cc=\tone+\ca;
\ccc=\tonee+\caa;
\xendz=\tone-\a+\cc;
\xendzz=\tonee-\a+\ccc;
\tthree=\cc+\tone-\psitwo;
\circsize=0.08;
\md = (\a+\h)/2;
\tlen=0.75;
\textscale = 0.7;
\picscale = 0.89;
\nudge=0.1;
\tnudge=(\ttwo-\tone)/2+0.8;
\ttesta=2*\tone-\ttwo-\tnudge;
\ttestb=2*\tone-\ttwo+\tnudge;
\ttestc=\ttwo-\tnudge;
\ttestd=\ttwo+\tnudge;
\sonea=\a+\psione-\ttesta;
\sadd=0.5;
\lrange = -(\psione-\a+\ttesta)+\sadd;
\rrange =\lrange; 
\timex=\rrange-1.5;
\e = 0.4;
\ttestx=4;
\at=\a-\ttestx;
\ct=\ttestx;
\lam = 0.87;
\e = 0.2;
\hae=(2*pow(\at,3)*\lam*(2+\lam)+\e*\e*(2*\e-sqrt(4*\e*\e+\at*\at*\lam*\lam))-8*\at*\e*(-2*\e+sqrt(4*\e*\e+\at*\at*\lam*\lam))-2*\at*\at*(2+\lam)*(-2*\e+sqrt(4*\e*\e+\at*\at*\lam*\lam)))/(4*\at*\lam*(2*\at+2*\e-sqrt(4*\e*\e+\at*\at*\lam*\lam)))-(\e*\e/4+\at*\at*(-1+\lam))/(\at*\lam);
\mmu=(\tone-\tbeg)/(\psione-\phstartx);
\nnu=(\psione*\tbeg-\phstartx*\tone)/(\psione-\phstartx);
\muf=(\a-\ttwo)/(\xend-\psitwo);
\nuf=(\xend*\ttwo-\psitwo*\a)/(\xend-\psitwo);
} 
\tikzstyle{scorestars}=[star, star points=5, star point ratio=2.25, draw, inner sep=1pt]%
\tikzstyle{scoresquare}=[draw,rectangle,minimum size=1mm,inner sep=0pt,outer sep=0pt]%
\begin{tikzpicture}[scale=\picscale,
declare function={
	testxonep(\ps,\t)=\a+\ps-\t;
	testxonem(\ps,\t)=\ps-\a+\t; 
	xa(\m,\n)=(-\ct*\m+\e*\m+\m*\n-sqrt(\ct*\ct*\lam*\lam+\e*\e*\m*\m+2*\e*\lam*\lam*\n+\lam*\lam*\n*\n-2*\ct*\lam*\lam*(\e+\n)))/(\lam*\lam-\m*\m);
	xb(\m,\n)=(-\ct*\m+\e*\m+\m*\n+sqrt(\ct*\ct*\lam*\lam+\e*\e*\m*\m+2*\e*\lam*\lam*\n+\lam*\lam*\n*\n-2*\ct*\lam*\lam*(\e+\n)))/(\lam*\lam-\m*\m);
	bl(\x)=\ct+\at-\e/2-1/2*(sqrt(\lam*\lam*pow(\x+\hae+\at,2)+\e*\e)-\e+\lam*(\x+\hae+\at));
	br(\x)=\ct+\at-\e/2-1/2*(sqrt(\lam*\lam*pow(\x-\hae-\at,2)+\e*\e)-\e-\lam*(\x-\hae-\at));
	bc(\x)=\ct+sqrt(\lam*\lam*\x*\x+\e*\e)-\e;
},
 ] 
\definecolor{tempcolor}{RGB}{250,190,0}
\definecolor{darkgreen}{RGB}{40,190,40}

%\draw[->,blue, thick] [domain=-\at/2:-\lrange, samples=150]   plot (\x, {bl(\x)})  ;
%\draw[blue, thick] [domain=-\at/2:\at/2, samples=150] plot (\x, {bc(\x)})  node[right=20, above=10,black,scale=\textscale]{}  ;
%\draw[->,blue, thick] [domain=\at/2:\rrange, samples=150]   plot (\x, {br(\x)})   ;

% \node[scale=\textscale]  at (1,4.1) {$S_i(y^c_1)$}; 
\draw[<->] (-\lrange, \h) node[left, scale=\textscale] {$S_0$} -- (\rrange, \h) node[right, scale=\textscale] {$S_0$};
\draw[<->] (-\lrange, \a) node[left, scale=\textscale] {$S$} -- (\rrange, \a) node[right, scale=\textscale] {$S$};
              
\draw[->, shorten <= 5pt,  shorten >= 1pt] (\psione,\h) node[below, scale=\textscale]{$\psi_1^{\text{sys}}$} node[above left, scale=\textscale]{$z_1$}-- (\psione,\a) ;
\draw[->,  shorten <= 5pt,  shorten >= 1pt] (\psitwo,\h) node[below, scale=\textscale]{$\psi_2^{\text{sys}}$} node[above right, scale=\textscale]{$z_2$}-- (\psitwo,\a);
\draw[->,  shorten <= 5pt,  shorten >= 1pt] (\psithree,\h) node[below, scale=\textscale]{$\psi_{3}^{\pm}$}   node[above left, scale=\textscale]{$z_3$}-- (\psithree,\a);


\draw[dashed, tempcolor,  thick](\phstartx,\tbeg) node[below left=-2,scale=\textscale]{}--(\psione,\tone) ;
\draw[dashed, tempcolor,  thick](\psione,\tone) node[below left=-2,scale=\textscale]{}--(\psitwo,\ttwo );
\draw[dashed, tempcolor,  thick](\psitwo,\ttwo)--(\xend,\a); 
\draw[dashed, tempcolor,  thick](\psione,\tone)--(\xendz,\a);

\draw[dashed, tempcolor,  thick](\phstartxx,\tbeg) node[below left=-2,scale=\textscale]{}--(\psione,\tonee) ;
\draw[dashed, tempcolor,  thick](\psione,\tonee) node[below left=-2,scale=\textscale]{}--(\psitwo,\ttwoo );
\draw[dashed, tempcolor,  thick](\psitwo,\ttwoo)--(\xendd,\a); 
\draw[dashed, tempcolor,  thick](\psione,\tonee)--(\xendzz,\a);

\draw[magenta,<->,ultra thick] (\rrange,\a)--(-\lrange,\a);



\draw[->] (\timex,\md-\tlen/2) --  (\timex,\md+\tlen/2) node[midway,right, scale=\textscale]{time}; 

\draw [black,fill] (\xendzz,\a) circle [radius=\circsize] node [black,above,scale=\textscale] {$x_1$}; 
\draw [black,fill] (\xend,\a) circle [radius=\circsize] node [black,above,scale=\textscale] {$x_4$}; 
\draw [black,fill] (\xendz,\a) circle [radius=\circsize] node [black,above,scale=\textscale] {$x_2$}; 
\draw [black,fill] (\xendd,\a) circle [radius=\circsize] node [black,above,scale=\textscale] {$x_3$}; 
 
%\draw[dotted](\psione,\ttestx)--({testxonep(\psione,\ttestx)},\a);
%\draw[dotted](\psione,\ttestx)--({testxonem(\psione,\ttestx)},\a);
\draw [black,fill] (\psione,\tone) circle [radius=\circsize] node [black,left=4,scale=\textscale] {$y_1$}; 
\draw [black,fill](\psitwo,\ttwo)circle [radius=\circsize] node [black,above right,scale=\textscale, align=left] {$y_2$}; 

%\draw (\psione,\ttestx) node[ scoresquare, fill=gray]  {} node [black,below=6,right,scale=\textscale] {$y^c_1$};
%\draw (\psitwo, {bc(\psitwo)}) node[ scoresquare, fill=gray]  {} node [black,below=6,right,scale=\textscale] {$y^c_2$};
%\draw ({xb(\muf,\nuf)}, {xb(\muf,\nuf)*\muf+\nuf}) node[ scoresquare, fill=gray]  {} node [black,right=7, below=-4,scale=\textscale] {$y^c_4$};
%\draw (\xendz,\a) node[ scoresquare, fill=gray]  {} node [black,below=3,scale=\textscale] {$y^c_3$};


%\draw [black,fill] (\xendz,\a) circle [radius=\circsize] node [black,above,scale=\textscale] {$\gamma_1$}; 
\end{tikzpicture}% pic 1

\vspace*{2px}
\caption{Depiction of a superposition of two local states at $z_1$ and $z_2$ with $y^c_1$ sufficiently late that the photon intersects $S_i(y^c_1)\cap S$. With enough photon detections on $S$ we can make statements about }
\label{kentdecoh5}
\end{figure}


 With enough such factual statements, we would have enough information on $T_S$ to say that there is a local state $\psi_1^\text{sys}$ at spacetime location $y_1$ and hence conclude that the statement p=``the beable at $y_1$ is $\dyad{\psi_1^\text{sys}}$'' is true. But we would very likely need quite a lot more information than knowledge of the fact that a photon is at $x_1$, and $x_2$, to conclude p since we would need to be able to work out something about time at which the incoming arrived in the vicinity of the system, and this would depend on physics of photon creation. But it seems plausible that from all the information in $T_S$ one could make statements such as p that involve pure states. It is no more controversial than the assumption that we can draw valid conclusions about the physical world based on which cells in our retina are excited. What is controversial is my (and Kent's) suggestion   that the information contained in $T_S$ determines the state of physical reality on earlier hypersurfaces rather than the physical state of the earlier hypersurfaces determining the the information contained in $T_S$. In the final chapter, I will aim to justify this suggestion and show that it is not quite as alien to common sense as it might first seem. 
 
As for statements that involve improper mixtures, for example statements of the form q=``the beable at $y_1$ is $\abs{c_1}^2\dyad{\psi_1^\text{sys}}+\abs{c_2}^2\dyad{0_1}$'') we could take these to be expressible in terms of modal statement about such as ``it's possible that a photon could have been detected at either $x_1$ or $x_3$ but not both'' as depicted in figure \ref{kentdecoh5}. As in the case for pure states, we would also need other modal statements and declarative propositions about $T_S$ in order to say enough about the times at which incoming photons would arrive at the $z_1$ and $z_2$. But with enough information on $T_S$ it seems plausible that we could build up a picture of such photon interaction on earlier hypersurfaces. Also, by comparing the values of $T_S$ over different region of $S$, we could detect similar configurations from which a superintelligent being could conclude that these similar configurations correspond to some kind of activity such as a human being performing an experiment.   But these multiple configurations would also have differences, some of which would correspond to different measurement outcomes. By surveying many of these configurations, the superintelligent being could assign probabilities to these outcomes and hence calculate expectation values for observables and the reduced density matrices that would give rise to these expectation values and hence make statements like $q$ which involve improper mixtures. 

At this point it is worth reminding ourselves that Kent is not saying that an actual measurement of $T_S$ on $S$ is made, but only a notional measurement which is to say if a measurement were made on $T_S$ it would have a determinate value $\tau_S$, say. One could choose a hypersurface $S'$ even later than $S$, but Kent supposes that the description of physical reality between $S_0$ and $S$ is not going to be significantly different if the one used the notional measurements for $T_{S'}$ on $S'$ rather than those on $T_S$.

So let's now consider how the understanding of beables in terms of reduced density matrices can give rise to Kent's beables as conditional expectation values of $T_{\mu,\nu}(y)$. In this section we have $S_i$ we been using a coarse-grained model so that $S_i$ is treated as a mesh of tiny cells labeled. The state of these one of these tiny cells, $y_k$ would not in general be pure eigenstates of $T_{\mu,\nu}(y_k)$


\nocite{Shimony93}
\nocite{Bell}
\printbibliography
\end{document}