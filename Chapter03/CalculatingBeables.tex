
\section{Calculating Kent's $T^{\mu\nu}(y)$-beables\textsuperscript{*} \label{kentcalculation}}
Having given a qualitative description in the last section of how a measurement outcome on $S$ determines which facts obtain in reality such as whether Schr\"{o}dinger's cat is alive or dead, we now give a more quantitative description of how Kent's beables are calculated. Kent's beables specify $T^{\mu\nu}(y)$ values for all $y$ between $S_0$ and $S$, and for all $\mu,\nu = 0, 1, 2,$ and $3$. Kent's $T^{\mu\nu}(y)$-beables are conditional expectation values, and the conditional expectation that we need to calculate depends on the notion of \textbf{conditional probability}\index{conditional probability}. In probability theory, the conditional probability $P(q|r)$  %
\nomenclature{$P(q|r)$}{the conditional probability that a statement $q$ is true given that a statement $r$ is true, \nomrefpage}%
that a statement $q$ is true given that a statement $r$ is true is given by the formula
\begin{equation} \label{conditionalprobability}
  P(q|r)=\frac{P(q\, \&\,  r)}{P(r)},
\end{equation}
where $P(r)$  %
\nomenclature{$P(r)$}{the probability a statement $r$ is true, \nomrefpage}%
is the probability $r$ is true, and $P(q\, \&\,  r)$ is the probability both $q$ and $r$ are true.
If we now define $q(\tau)$ to be %
\nomenclature{$q(\tau)$}{the statement that some quantity $T$  takes the value $\tau$, \nomrefpage}%
 the statement that some quantity $T$  takes the value $\tau$, then the  \textbf{conditional expectation}\index{conditional expectation} of  $T$ given $r$ will be given by the formula
\begin{equation}\label{conditionalexpectation}
\ev*{T}_r\myeq\sum_\tau P(q(\tau)|r)\tau
\end{equation} %
\nomenclature{$\ev*{T}_r$}{The conditional expectation of $T$ given the statement $r$, see equation (\ref{conditionalexpectation}), \nomrefpage}%
where the summation is over all the possible values $\tau$ that $T$ can take.

The recipe for defining Kent's $T^{\mu\nu}(y)$-beable is first to select an outcome $\tau_S$ that is defined over all of $S$. The outcome $\tau_S$ is selected with probability determined by the Born rule using equation (\ref{bornpsi}).\footnote{If there is only one state $\ket*{\Psi}$ such that $\hat{T}_S(x)\ket*{\Psi}=\tau_S(x)\ket*{\Psi}$ for all $x\in S$, then the probability $P(\tau_S)$ that $\tau_S$ is selected will be precisely the probability given by equation (\ref{bornpsi}). But if there are several states $\{\ket*{\Psi_\alpha}:\alpha\}$ such that  $\hat{T}_S(x)\ket*{\Psi_\alpha}=\tau_S(x)\ket*{\Psi_\alpha}$, then the probability $P(\tau_S)$ that $\tau_S$ is selected will be 
$$P(\tau_S)=\sum_\alpha \abs{\mel{\Psi_\alpha}{U_{SS_0}}{\Psi_0}}^2=\sum_\alpha \abs{\ip{\Psi_\alpha}{\Psi_S}}^2.$$ 
Also note that while no one outcome for $\tau_S$ is going to be very likely, having the outcome $\tau_S$ shouldn't be highly improbable relative to other possible mass-energy density outcomes. That is, if $P(\tau_S)\ll P(\tau_S')$, then $\tau_S$ shouldn't be selected.} Then Kent's $T^{\mu\nu}(y)$-beable for any $y$ between $S_0$ and $S$ is defined to be
\begin{equation}\label{Kentbeable} 
  \ev*{T^{\mu\nu}(y)}_{\tau_S}\myeq \ev*{T^{\mu\nu}(y)}_{r(\tau_S,y)}
\end{equation} %
\nomenclature{$\ev*{T^{\mu\nu}(y)}_{\tau_S}$}{Kent's beable, see equation (\ref{Kentbeable}), \nomrefpage}%
where $r(\tau_S, y)$ is %
\nomenclature{$r(\tau_S, y)$}{The statement that $T_S(x)$ has the determinate value $\tau_S(x)$ for all $x\in S^1(y)$, \nomrefpage}%
 the statement that $T_S(x)$ has the determinate value $\tau_S(x)$ for all $x\in S^1(y)$,\footnote{Strictly speaking, we should say that $r(\tau_S, y)$ is the statement that the approximation of the mass-energy density $T_S(x)$ given by equation (\ref{tauapproxformula}) has the value $\tau_S(c_x)$ for every cell $c_x$ in $S$ outside the light cone of $y$.} and where $q(\tau)$ in equation (\ref{conditionalexpectation}) is %
 \nomenclature{$q(\tau)$}{The statement that $T^{\mu\nu}(y)$ (understood in the conventional non-Kentian sense) takes the value $\tau$, \nomrefpage}%
  the statement that $T^{\mu\nu}(y)$ (understood in the conventional non-Kentian sense) takes the value $\tau$.\footnote{\label{cyfootnote}Again, we assume that $T^{\mu\nu}(y)$ is averaged over a small three-dimensional cell $c_y$ of spacelike separated spacetime locations (with $y\in c_y$), and approximated to a finite pool of values as in equation  (\ref{tauapproxformula}).} It is these $T^{\mu\nu}(y)$-beables $\ev*{T^{\mu\nu}(y)}_{\tau_S}$ that give a one-world picture of reality in Kent's theory. 

We can see how the formula (\ref{conditionalexpectation}) relates to the Sch\"{o}dinger's cat scenario. The distribution of light reflected off the cat that intersects $S^1(y)$ when ``measured'' will determine a definite statement $r(\tau_S, y)$ about the mass-energy density on $S^1(y)$. This in turn will determine the range of $\tau$ for which $P(q(\tau)|r(\tau_S,y))$ is not close to zero, and hence where the stress-energy distribution $\ev*{T^{\mu\nu}(y)}_{\tau_S}$ is not zero. This stress-energy distribution will then correspond either to that of  a living cat or to that of a dead cat, but not both.  

 Coming back to the question of why we don't include any information about $\tau_S(x)$ for $x\in S$ from within the light cone of $y$, we need to consider in more detail how we would calculate $\ev*{T^{\mu\nu}(y)}_{\tau_S}$. From (\ref{conditionalprobability}) and (\ref{conditionalexpectation}), we will be able to perform this calculation so long as we can calculate $P(q(\tau) \, \&\,  r(\tau_S,y))$ and $P(r(\tau_S,y))$. 
 
 Calculating $P(r(\tau_S,y))$ is relatively straightforward. As described on page \pageref{simultaneous}, we can find an orthonormal basis $\{\ket*{\Psi^{(i)}}:i\}$ of $H_S$ consisting of simultaneous $\hat{T}_S$-eigenstates and simultaneous $\hat{T}_S$-eigenvalues $\tau^{(i)}_S$ respectively. The probability $P(r(\tau_S,y))$ will then be  
 \begin{equation}\label{rProb}
 P(r(\tau_S,y))=\sum_{\substack{i \text{ such that} \\ \tau_S^{(i)}(x)=\tau_S(x)\\ \text{ for all }x\in S^1(y)}}\abs{\mel{\Psi^{(i)}}{U_{SS_0}}{\Psi_0}}^2
 \end{equation} where we have used equation (\ref{bornpsi}).

 But calculating $P(q(\tau) \, \&\,  r(\tau_S,y))$ is a bit more involved because in the Tomonaga-Schwinger picture, the definition of observables via 
 \begin{equation}\tag{\ref{tsobservable} revisted}
  \hat{O}(x)=U[S]\hat{\bm{O}}(x)U[S]^{-1}
\end{equation}
requires that $x\in S$.
This means that we can't define $\hat{T}^{\mu\nu}(y)$ according to (\ref{tsobservable}) since $y\not\in S$.\footnote{If we did attempt to use (\ref{tsobservable}) to define $\hat{T}^{\mu\nu}(y)=U[S]\hat{\bm{T}}^{{\mu\nu}}(y)U[S]^{-1}$, then $\hat{T}^{\mu\nu}(y)$ would have a (non-local) dependence on $S$, and such a dependence would not be desirable.} However, we do not face such restrictions in the Heisenberg picture, so one approach would be to calculate $P(q(\tau) \, \&\,  r(\tau_S,y))$ in the Heisenberg picture. As we will see shortly, this is not the approach that Kent takes, but nevertheless, in the Heisenberg picture, it is easier to see why we don't include information from $S$ within the light cone (without begging the question of why we don't) when calculating $P(q(\tau) \, \&\,  r(\tau_S,y))$. To see why this is so, consider the simpler case of just two measurable quantities ${F}$ and ${G}$ which we assume to have a discrete range of possible values and for which we wish to calculate the joint probability $P((F=f)\, \&\, (G=g))$. To do this in the Heisenberg picture, we need an orthonormal basis of the state space $\{\ket*{\Phi^{(i)}}:i\}$ consisting of simultaneous eigenstate of the observables $\hat{\bm{F}}$ and $\hat{\bm{G}}$ with eigenvalues $f^{(i)}$ and $g^{(i)}$ respectively so that $\hat{\bm{F}}\ket*{\Phi^{(i)}}=f^{(i)}\ket*{\Phi^{(i)}}$ and $\hat{\bm{G}}\ket*{\Phi^{(i)}}=g^{(i)}\ket*{\Phi^{(i)}}$, and when the system is in the state $\ket*{\Phi^{(i)}}$, the quantity $F$ will have the value $f^{(i)}$, and the quantity $G$ will have the value $g^{(i)}$. Given that the system is in the state $\ket*{\Phi}$, the joint probability $P((F=f)\, \&\, (G=g))$ can then be calculated using the Born rule to get
$$P((F=f)\, \&\, (G=g))=\sum_{\substack{i \text{ such that} \\ f^{(i)}=f \text{ and } g^{(i)}=g}}\abs{\ip{\Phi^{(i)}}{\Phi}}^2.$$
But  in order for such an orthonormal basis to exist, it is necessary that $\hat{F}$ and $\hat{G}$ commute.\footnote{This is because given such an orthonormal basis $\{\ket*{\Phi^{(i)}}:i\}$ of simultaneous eigenstates of $\hat{\bm{F}}$ and $\hat{\bm{G}}$, we have 
$$\hat{\bm{F}}\hat{\bm{G}}\ket*{\Phi^{(i)}}=f^{(i)}g^{(i)}\ket*{\Phi^{(i)}}=g^{(i)}f^{(i)}\ket*{\Phi^{(i)}}=\hat{\bm{G}}\hat{\bm{F}}\ket*{\Phi^{(i)}}$$ so for any arbitrary state $\ket*{\Phi}=\sum_i c_i \ket*{\Phi^{(i)}},$ we have 
$$\hat{\bm{F}}\hat{\bm{G}}\ket*{\Phi}=\sum_i c_i \hat{\bm{F}}\hat{\bm{G}}\ket*{\Phi^{(i)}}= \sum_i c_i \hat{\bm{G}}\hat{\bm{F}}\ket*{\Phi^{(i)}}=\hat{\bm{G}}\hat{\bm{F}}\ket*{\Phi}.$$ 
} This means that if $\hat{F}$ and $\hat{G}$ do not commute, then we cannot define the joint probability $P((F=f)\, \&\, (G=g)).$

Now quantum field theory is so constructed that $\hat{\bm{T}}^{{00}}(x)$ and $\hat{\bm{T}}^{{\mu\nu}}(y)$ will not commute when $x$ and $y$ are not spacelike separated, but $\hat{\bm{T}}^{{\mu'\nu'}}(x)$ and $\hat{\bm{T}}^{{\mu\nu}}(y)$ will commute when $x$ and $y$ are spacelike separated.\footnote{The proof of this statement need not concern us, but one can see that this is the case by considering the four potential commutation relations and the decomposition of the stress-energy tensors in terms of the four-potentials  -- see \cite[p. 1443--1444]{SchwingerJulianI}.} As we will see on page \pageref{TSdef}, $T_S(x)$ will have a $T^{00}(x)$ component, and so we can only be sure that $\hat{\bm{T}}_S(x)$ will commute with  $\hat{\bm{T}}^{{\mu\nu}}(y)$ if $x$ and $y$ are spacelike separated. In other words, $\hat{\bm{T}}_S(x)$ and $\hat{\bm{T}}^{{\mu\nu}}(y)$ will commute if $x$ is outside the light cone of $y$. Extending this argument to multiple $x\in S$, we see that we can only guarantee that the conditional expectation of $T^{\mu\nu}(y)$ is definable if we restrict our conditioning on the value of $T_S(x)$ to $x\in S^1(y)$, that is, to $x$ in $S$ outside the light cone of $y$.

Having explained why we don't include any information about $\tau_S(x)$ for $x\in S$ from within the light cone of $y$, we can now proceed to calculate  $P(q(\tau) \, \&\,  r(\tau_S,y))$. Now although there is no hypersurface that contains both $y$ and $S^1(y)$, we can find a sequence of hypersurfaces $S_n(y)$ each  %
\nomenclature{$S_n(y)$}{One of a sequence of hypersurfaces which contain $y$ and intersect $S$, \nomrefpage}%
 of which contains\footnote{More precisely, we should say each hypersurface $S_n(y)$ contains $c_y$ where $c_y$ is the cell containing $y$ mentioned in footnote \ref{cyfootnote}. We make $c_y$ sufficiently small so that the $c_x$ cells of $S$ outside the light cone of $y$ are identical to the $c_x$ cells of $S$ outside the light cone of $c_y$. We can do this on the assumption that $c_y$ and the $c_x$ are closed sets, since outside the light cone of $y$ is an open set, so none of the $c_x$ will touch the boundary of the light cone in $S$. } $y$ such that\label{siydef} $S_n(y)\subset S_{n'}(y)$ for $n<n'$, and such that for any $x\in S^1(y)$, there exists $n$ and an open subset $U_n(x)\subset S$ containing $x$ such that $U_n(x)\subset S_n(y)$. It will also be convenient to require that $S\setminus S_n(y)$ is bounded. An example of one such $S_n(y)$ is shown in figure \ref{S3}. When there is no ambiguity,  %
 \nomenclature{$S_n$}{Shorthand for $S_n(y)$, \nomrefpage}%
 we will drop the $y$ and write $S_n$ instead of $S_n(y)$. 
 \begin{figure}[ht!]
\captionsetup{justification=justified}
\centering

\tikzmath{
\a= 1;  
\e = 0.1;
\lam=0.9;
\h=-1;
\hae=(3*\a*\a+6*\a*\e+7*\e*\e-3*\a*sqrt(\a*\a+4*\e*\e)-4*\e*sqrt(\a*\a+4\e*\e))/(4*\a+4*\e-2*sqrt(\a*\a+4*\e*\e));
\hae=0.205678;
\circsize=1.2;
\md = (\a+\h)/2;
\lrange = 4;
\rrange=2;
\fictlabel=(\rrange-\lrange)/2;
\ss=(-\lrange-\a)/2;
\sss=\a+(\rrange-\a)/2;
\tlen=0.75;
\labelpos=(-\lrange-\a)/2;
} 

\begin{tikzpicture}[thick, scale=2]

\def\dotsize{0.7}

\definecolor{tempcolor}{RGB}{0,151,76}
\draw[<->] (-\lrange, \h) node[left] {$S_0$} -- (\rrange, \h) node[right] {$S_0$};
\filldraw (0,0) circle (\dotsize pt) node [below right] {$y$} ;
              
\draw[->] (\rrange,\md-\tlen/2) --  (\rrange,\md+\tlen/2) node[midway,right]{time}; 

\draw[->,blue, thick] [domain=-\a/2:-\lrange, samples=150]   plot (\x, {\a-\e/2-1/2*(sqrt(\lam*\lam*pow(\x+\hae+\a,2)+\e*\e)-\e+\lam*(\x+\hae+\a))}) node[left, black]{$S_n(y)$}  ;
\draw[blue, thick] [domain=-\a/2:\a/2, samples=150] plot (\x, {sqrt(\lam*\lam*\x*\x+\e*\e)-\e})   node[right, black]{$S_n(y)$};
\draw[->,blue, thick] [domain=\a/2:\rrange, samples=150]   plot (\x, {\a-\e/2-1/2*(sqrt(\lam*\lam*pow(\x-\hae-\a,2)+\e*\e)-\e-\lam*(\x-\hae-\a))}) node[right, black]{$S_n(y)$}  ;
\draw[gray] (-\lrange, \a)  -- (\rrange, \a)  {};
\draw[gray, dashed] (-\a, \a) -- (0,0) {};
\draw[gray, dashed](0,0) -- (\a, \a) {};
\draw[gray](\a, \a) --  (\rrange, \a)  ;         
\coordinate (B) at (\a,\a);
\node at (B)[red,circle,fill,inner sep=\circsize pt]{};
\coordinate (A) at (-\a,\a);
\node at (A)[red,circle,fill,inner sep=\circsize pt]{};
\coordinate (C) at (0,0);
\node at (C)[black,circle,fill,inner sep=\circsize pt]{};

\coordinate[label = above:$S$]  (D) at (0,\a);

\coordinate[label = above:$S$]  (D) at (\sss,\a);

\filldraw (\ss,\a) circle (\dotsize pt) node [above] {$x\in S_n(y)\cap S$} ;


 
\node (start) at (\labelpos,\h) [below] {Initial State $\ket{\Psi_0}$};
\node (evolution) at (\labelpos,\md+0.05) [below] {Unitary Evolution $U_{S_nS_0}\ket{\Psi_0}$};
\node (final) at (\labelpos,\a) [below] {Unitary Evolution $U_{SS_0}\ket{\Psi_0}$};
%\node at (-\ss+0.17,\mn-0.18){$-a_0$};
\draw [->, shorten <= 5pt] (start) [above] -- (evolution); 
\draw [->] (evolution) -- (final); 
\end{tikzpicture}

\vspace*{2px}
\caption{$S_n\myeq S_n(y)$ is a hypersurface containing $y$ and all of $S^1(y)$ in the limit as $n\rightarrow\infty$.   }
\label{S3}
\end{figure}Such a sequence $S_n$ of hypersurfaces will be sufficient to calculate  $P(q(\tau) \, \&\,  r(\tau_S,y))$. So let us define $r_n$  %
\nomenclature{ $r_n$ }{The statement that  $T_S(x)$ has the determinate value $\tau_S(x)$ for all $x\in S_n\cap S$, \nomrefpage}%
to be the statement that  $T_S(x)$ has the determinate value $\tau_S(x)$ for all $x\in S_n\cap S$.\footnote{\label{tangentialnote}Strictly speaking, we should say the condition of $r_n$ holds for all $x\in S_n\cap S$ at which $S_n$ and $S$ are tangential to each other. For a possible worry someone might have about the statement $r_n$ without this qualification is that $\tau_S(x)$ is the value of the beable $T_S(x)$ for $x$ in $S^1(y)\cap S$ but it's not the value of the beable $T_{S_n}(x)$ for $x$ in $S_n\cap S$. Such a worry would be valid if the beable $T_S(x)$ depended on the whole of $S$ and the beable $T_{S_n}(x)$ depended on the whole of $S_n$. However, as we shall see on page \pageref{localdependenceS} in section \ref{LorentzInvariance}, the physical quantity $T_S(x)$ which is defined by equation (\ref{TSdef}) to be $T_S(x)=T^{\mu\nu}(x)\eta_{\mu}(x)\eta_{\nu}(x)$ will only have a local dependence on $S$ via the future directed four-vector $\eta^\mu(x)$. Therefore, so long as the future directed four-vector for $S_n$ at $x$ is the same as the one for $S$ at $x$, then the beables $T_{S}(x)$ and  $T_{S_n}(x)$ will be identical. We therefore require that $S_n$ and $S$ are tangential to each other at $x$ since this is a necessary and sufficient condition for the respective future directed four-vectors of $S_n$ and $S$ to be identical.
\newline
\newline
Nevertheless, we might still worry that the observables $\hat{T}_{S}(x)$ and  $\hat{T}_{S_n}(x)$ corresponding to these two beables aren't identical because $\hat{T}_{S}(x)$ acts on the Hilbert space $H_S$ whereas $\hat{T}_{S_n}(x)$ acts on the Hilbert space $H_{S_n}$. However, at this point we need to recall footnote \ref{HSclarification} on page \pageref{HSclarification} that $H_{S}$ and $H_{S_n}$ are really the same Hilbert space, but just interpreted differently. Now on this one Hilbert space, it turns out that $\hat{T}_{S}(x)$ and  $\hat{T}_{S_n}(x)$ are identical. To see why this is, let $\hat{\bm{T}}_S(x)$ and $\hat{\bm{T}}_{S_n}(x)$ be the Heisenberg picture observables. Since $T_S(x)=T^{\mu\nu}(x)\eta_{\mu}(x)\eta_{\nu}(x)=T_{S_n}(x)$ for $x\in S_n\cap S$ where $S_n$ and $S$ are tangential to one another, we must have $\hat{\bm{T}}_S(x)=\hat{\bm{T}}^{\mu\nu}(x)\eta_{\mu}(x)\eta_{\nu}(x)=\hat{\bm{T}}_{S_n}(x)$. Now by definition (see equation (\ref{tsobservable})), $\hat{T}_S(x)=U[S]\hat{\bm{T}}_S(x)U[S]^{-1}$, and $\hat{T}_{S_n}(x)=U[S_n]\hat{\bm{T}}_{S_n}(x)U[S_n]^{-1}$.  But as Schwinger shows, under conditions that are readily satisfied (see footnote \ref{Sindepedence} for details), for any Heisenberg operator $\hat{\bm{F}}(x)$, as long as $x$ belongs to $S$ the operator $\hat{F}(x)=U[S]\hat{\bm{F}}(x)U[S]^{-1}$ is independent of $S$. Therefore, since $x\in S_n\cap S$ where $S_n$ and $S$ are tangential to one another, we not only have $\hat{\bm{T}}_S(x)=\hat{\bm{T}}_{S_n}(x)$, but we must also have $\hat{T}_S(x)=\hat{T}_{S_n}(x)$.} We recall that in the Tomonaga-Schwinger formulation of relativistic quantum physics, the operators $\hat{T}_S(x)$ and $\hat{T}^{\mu\nu}(y)$ for fixed $\mu,\nu$ commute when $x$ and $y$ are spacelike-separated. It therefore follows that we can express any state of $H_{S_n}$ as a superposition of simultaneous eigenstates of $\hat{T}^{\mu\nu}(y)$ and $\hat{T}_S(x)$ for $x\in S_n\cap S$.\footnote{Strictly \label{snapprox} speaking we should say simultaneous eigenstates of $\hat{T}^{\mu\nu}(c_y)$ and $\hat{T}_S(c_x)$ for all $c_x\subset S_n\cap S$.}  For a particular choice of $\mu,\nu$, we can then form an orthonormal basis $\{\ket*{\Psi_{n}^{(i)}}:i\}$ of $H_{S_n}$ consisting of simultaneous $\hat{T}^{\mu\nu}(y)$, $\hat{T}_S(x)$-eigenstates so that $\hat{T}^{\mu\nu}(y)\ket*{\Psi_{n}^{(i)}}=\tau^{(i)}\ket*{\Psi_{n}^{(i)}}$ and $\hat{T}_{S}(x)\ket*{\Psi_{n}^{(i)}}=\tau_S^{(i)}(x)\ket*{\Psi_{n}^{(i)}}$ for $x\in S_n\cap S$, where $\tau^{(i)}$ and $\tau_S^{(i)}(x)$ are the corresponding eigenvalues. The probability $P(q(\tau) \, \&\,  r_n)$ will then be
$$P(q(\tau) \, \&\,  r_n) =\sum_{\substack{i \text{ such that } \tau^{(i)}=\tau \\ \text{and }\tau_S^{(i)}(x)=\tau_S(x)\\ \text{ for all }x\in S_n\cap S }}\abs{\mel{\Psi_n^{(i)}}{U_{SS_0}}{\Psi_0}}^2.$$
Taking the limit as $n$ tends to infinity, we can calculate the probability $P(q(\tau) \, \&\,  r(\tau_S,y))$ to be
\begin{equation}\label{qrProb}
P(q(\tau) \, \&\,  r(\tau_S,y))=\lim_{n\rightarrow\infty}P(q(\tau) \, \&\,  r_n).\protect\footnotemark
\end{equation}\footnotetext{In fact, there will be a finite $n'$ such that $P(q(\tau) \, \&\,  r(\tau_S,y))=P(q(\tau) \, \&\,  r_{n'}).$ This is because for any $n$ we are assuming $S\setminus S_{n}$ is bounded, so there will be a finite number of $c_x$ cells of $S$ outside the light cone of $c_y$ that are not contained in $S_n$, and so the union of all these cells $U$ will be compact. But for any $x\in U$, we can find $n''$ such that the open set $U_{n''}(x)$ containing $x$ with $U_{n''}(x)\subset S$ and $U_{n''}(x)\subset S_n$. These $U_{n''}(x)$ will then form an open cover of $U$, and by the definition of compactness, every open cover has a finite subcover. If we therefore choose $n'$ to be the maximum $n''$ of this finite subcover, then $S_{n'}$ will contain all of $U$ since $S_{n''}\subset S_{n'}$ for $n''<n'$. Then by definition of the statements $r(\tau_S,y)$ and $r_n$, it follows that $r(\tau_S,y)=r_{n'}.$}Assuming $\tau_S$ is selected in accordance with the Born rule so that $P(r)>0$, we can plug (\ref{rProb}) and (\ref{qrProb}) into (\ref{conditionalprobability}) to calculate the conditional probability $P(q(\tau) | r(\tau_S,y))$,  and hence calculate the conditional expectation  $\ev*{T^{\mu\nu}(y)}_{\tau_S}\myeq \ev*{T^{\mu\nu}(y)}_{r(\tau_S,y)}$ via equation (\ref{conditionalexpectation}). We thus obtain
\begin{equation}\label{beable1}
  \ev*{T^{\mu\nu}(y)}_{\tau_S}=\sum_\tau P(q(\tau) | r(\tau_S,y))\tau=\lim_{n\rightarrow\infty}\sum_\tau\frac{P(q(\tau) \, \& \, r_n)\tau}{P(r_n)}.
  \end{equation} 
In section \ref{kentinterpretationconsistency}, we will give a more detailed description of this calculation in order to show that the predictions Kent's theory makes are consistent with standard quantum theory.
 
