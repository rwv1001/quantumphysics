\chapter{Evaluating Kent's Theory\label{KentEval}}
In order to evaluate Kent's theory of quantum physics, it will first be helpful to remind ourselves of the problem we are trying to solve. 

In chapter \ref{BellChapter}, we discussed the EPR-Bohm paradox and the problem of explaining  the mysterious correlations between measurement outcomes of spin singlets in a way consistent with special relativity and the predictions of standard quantum theory. We saw that the Copenhagen interpretation does not seem to be consistent with special relativity. We also discussed Shimony's distinction between Outcome Independence (OI) and Parameter Independence (PI) and Shimony's idea that we should only accept a theory in which OI is false and PI is true. Since PI is false in the pilot-wave theory, we should reject it according to Shimony's criterion. 

But although Shimony's criterion is a promising line of inquiry, by itself, it is not sufficient to resolve the  EPR-Bohm paradox. This is because Shimony's criterion doesn't address the controversial issue of what is meant by an outcome. In chapter \ref{measprobchap}, we discussed this controversy over outcomes and why the many-worlds interpretation that denies the reality of outcomes is unsatisfactory. This motivated the discussion of Kent's theory in chapter \ref{measprobchap} in the hope that it might provide a satisfactory solution to the EPR-Bohm paradox. In the previous chapter, we only got as far as describing the key features of Kent's theory such as it being a one-world theory which posits additional variables to standard quantum theory. 

So having now reminded ourselves of the problem at hand, we see that there are several issues that we need to consider in order to evaluate whether Kent's theory provides a satisfactory solution to this problem. Firstly, we should consider whether the predictions of Kent's theory are consistent with the  predictions of quantum theory that have been experimentally validated. Since standard quantum theory (that is a theory of states whose evolution is determined by the Schr\"{o}dinger equation) predicts the correlations observed in the EPR-Bohm paradox, then if Kent's theory is consistent with standard quantum theory, these EPR-Bohm correlations will also be exhibited in Kent's theory. 

Secondly, since a satisfactory solution to our problem must be consistent with special relativity, we need to consider whether such consistency holds in Kent's theory. Consistency with special relativity is guaranteed in a theory if and only if it is invariant under a group of symmetries called Lorentz transformations. We therefore need to consider whether Kent's theory satisfies Lorentz invariance. 

Thirdly, since a satisfactory theory must be one in which there are outcomes, we need to consider whether Kent succeeds in giving us a convincing account of what an outcome is. In doing this, we will examine how Kent's theory ties in with decoherence theory and d'Espagnat's objection about improper mixtures. 

Butterfield has also emphasized the need to understand Kent's theory in the light of an important theorem proved in recent years, the so-called Collbeck-Renner Theorem\footnote{See \cite{LeegwaterGijs2016Aitf}, \cite{ColbeckRoger2011Neoq}, \cite{ColbeckRoger2012Tcoq}, \cite{LandsmanK2015OtCt}, and \cite{Landsman}.} which says that if a theory satisfies PI together with what is called a `no conspiracy' criterion, then this theory is reducible to standard quantum theory without any hidden variables. On the assumption that a violation of `no conspiracy' would not be acceptable,  this then suggests that any theory that satisfactorily addresses the  EPR-Bohm paradox can't be a hidden-variables theory. We will therefore need to consider whether Kent's model can be an interpretation of quantum physics without it being a hidden-variables theory.

I will argue that in the light all these considerations, Kent's theory does provide a satisfactory solution to the EPR-Bohm paradox. There are still questions concerning the nature of Kent's beables, and Kent's theory may also strike us as rather counter-intuitive given that his theory posits that present events should be conditioned on far-distant future states of affairs. We will therefore conclude this chapter by discussing how Kent's theory could be made to appear less counter-intuitive.

\section{Consistency of Kent's Theory with Standard Quantum Physics\textsuperscript{*}\label{kentinterpretationconsistency}}
\renewcommand{\thefootnote}{\fnsymbol{footnote}}
\footnotetext[1]{As mentioned in the introduction on page \pageref{asteriskmeaning}, sections marked with an asterisk may be challenging to readers who do not have a  background in physics.}\label{LorentzInvarianceSection}\renewcommand*{\thefootnote}{\arabic{footnote}}If we are to take Kent's theory seriously, it should be just as good at making predictions as standard quantum theory, and it had better not contradict empirical observations. Over the last century, standard quantum theory has been firmly established scientifically, and so far, it has not been contradicted by any experimental observations. Standard quantum theory allows us to form a quantum state description of a physical system based on how the system was set up in an experimental environment, and then Schr\"{o}dinger's equation can be used to evolve this state forwards in time, and finally, we can calculate expectation values for various physical quantities belonging to this physical system, and these agree with the average values measured on the system when the experiment is performed many times. In other words, standard quantum theory is \textbf{empirically adequate}\index{empirical adequacy!informal definition}\footnote{See p. \pageref{adeq} for a more formal definition of empirical adequacy.} in its domain of applicability. Thus, if we can show that Kent's theory is just as good at making predictions as standard quantum theory, then it too will be empirically adequate to the same degree. This doesn't necessarily mean that Kent's theory will make exactly the same predictions as standard quantum physics, for the additional information that Kent's theory requires beyond standard quantum theory may alter these predictions. Indeed, if this additional information made absolutely no difference to the predictions of standard quantum theory, then it would seem rather redundant. But we should nevertheless be able to derive the predictions of standard quantum theory from Kent's theory by averaging over the unknown variables that describe the additional information in Kent's theory. 

In order to show that Kent's theory is just as good as standard quantum theory, we recall the preliminary calculation of $\ev*{T^{\mu\nu}(y)}_{\tau_S}$ given in section \ref{kentcalculation}:
\begin{equation}\tag{\ref{beable1} revisited}
	\ev*{T^{\mu\nu}(y)}_{\tau_S}=\sum_\tau P(q(\tau) | r(\tau_S,y))\tau=\lim_{n\rightarrow\infty}\sum_\tau\frac{P(q(\tau) \, \& \, r_n)\tau}{P(r_n)}.
\end{equation}
We proceed to calculate $P(r_n)$ and $P(q(\tau)\, \& \,r_n)$ in order to calculate  $\ev*{T^{\mu\nu}(y)}_{\tau_S}$. We first note that since $S_n$ is a spacelike hypersurface,   there will exist a unitary operator $U_{S_nS_0}$ defined by equation (\ref{SchwingerUnitaryOP}) which maps the Hilbert space\footnote{The Hilbert space $H_S$ for any spacelike hypersurface $S$ is defined on page \pageref{HSdef}.} of states $H_{S_0}$ describing $S_0$ to the Hilbert space of states $H_{S_n}$\label{HSidef} describing $S_n$ in accord with how the states of $H_{S_0}$  evolve over time. Now let $H_{S_n,\tau_S}\label{HStau}\subset H_{S_n}$ be the subspace of states $\ket{\xi}$ for which  $\hat{T}_S(x)\ket{\xi}=\tau_S(x)\ket{\xi}$  for all $x\in S_n\cap S$, and  let $\{\ket{\xi_1},\ket{\xi_2},\ldots\}$ be an orthonormal basis of $H_{S_n,\tau_S}$. Given that the initial state of the world is $\ket{\Psi_0}$, the probability $P(r_n)$ of ``measuring'' the value of $T_S(x)$ on $S_n\cap S$ to be $\tau_S(x)$ will be 
\begin{equation}\label{Pri}
P(r_n)=\sum_j \abs{ \ip{\xi_j}{\Psi_n}}^2,
\end{equation}
where $\ket{\Psi_n}=U_{S_nS_0}\ket{\Psi_0}$, and this probability will be independent of the particular orthonormal basis  $\{\ket{\xi_j}:j\}$ of $H_{S_n,\tau_S}$.\footnote{To see why this is, we note that we can extend the orthonormal set $\{\ket{\xi_1},\ket{\xi_2},\ldots\}$ to an orthonormal basis  $\{\ket{\xi_1},\ket{\xi_2},\ldots\}\cup\{\ket{\zeta_1},\ket{\zeta_2},\ldots\}$ of $H_{S_n}$ which consists entirely of $\hat{T}_S(x)$-eigenstates for all $x\in S_n\cap S$. We can think of each of the states of this orthonormal basis as the possible measurement outcomes when making the notional measurement of $T_S(x)$ on $S_n\cap S$. By the Born Rule, it therefore follows that $P(r_n)=\sum_j \abs{ \ip{\xi_j}{\Psi_n}}^2$. But to see that this probability is independent of the particular basis, we can uniquely write $\ket{\Psi_n}$ as a sum $\ket{\Psi_n}=\ket{\xi}+\ket{\zeta}$ where $\ket{\xi}$ belongs to the span of $\{\ket{\xi_j}:j\}$ and $\ket{\zeta}$ belongs to the span of $\{\ket{\zeta_j}:j\}$.  Then since $\ket{\xi}=\sum_j\ip{\xi_j}{\Psi_n}\ket{\xi_j}$, it follows that $$\ip{\xi}{\xi}=\sum_j\abs{ \ip{\xi_j}{\Psi_n}}^2=P(r_n).$$ Therefore, since  $\ip{\xi}{\xi}$ is independent of the particular basis chosen of $H_{S_n,\tau_S}$, so is $P(r_n)$.  \label{priproof} } If we define 
\begin{equation}\label{tauprojection}
\pi_n=\sum_j\dyad{\xi_j},
\end{equation}
then it is easy to see that
\begin{equation}\label{Prn}
	P(r_n)=\ev*{\pi_n}{\Psi_n}.
\end{equation}
We also see that $\pi_n$ is Hermitian (i.e. has real eigenvalues) and that $\pi_n \pi_n = \pi_n$. Any Hermitian operator $\pi$ with $\pi^2=\pi$ is called a \textbf{projection}\index{projection}. We thus see that $\pi_n$ is a projection.

Turning to the calculation of $P(q(\tau)\, \& \, r_n)$, note that for the Tomonaga-Schwinger formulation of relativistic quantum physics, the operators $\hat{T}_S(x)$ and $\hat{T}^{\mu\nu}(y)$ for fixed $\mu,\nu$ commute when $x$ and $y$ are spacelike-separated. It therefore follows that we can express any state of $H_{S_n}$ as a superposition of simultaneous eigenstates of $\hat{T}^{\mu\nu}(y)$ and $\hat{T}_S(x)$ for $x\in S_n\cap S$.\footnote{We make the same approximation as depicted in figure \ref{tauSapprox} on page \pageref{tauSapprox}.}  For a particular choice of $\mu,\nu$, we can then form an orthonormal basis $\{\ket{\eta_j}:j\}$ of $H_{S_n}$ consisting of simultaneous $\hat{T}^{\mu\nu}(y)$, $\hat{T}_S(x)$-eigenstates so that $\hat{T}^{\mu\nu}(y)\ket{\eta_j}=\tau^{(j)}\ket{\eta_j}$ and $\hat{T}_{S}(x)\ket{\eta_j}=\tau_S^{(j)}(x)\ket{\eta_j}$ for $x\in S_n\cap S$, where $\tau^{(j)}$ and $\tau_S^{(j)}(x)$ are the corresponding eigenvalues. If we define  $\pi_{n,\tau}=\sum_j\dyad{\chi_{j,\tau}}$ where $\{\ket{\chi_{j,\tau}}:j\}$ is the subset of $\{\ket{\eta_j}:j\}$ such that $\hat{T}^{\mu\nu}(y)\ket{\chi_{j,\tau}}=\tau\ket{\chi_{j,\tau}}$ and $\hat{T}_S(x)\ket{\chi_{j,\tau}}=\tau_S(x)\ket{\chi_{j,\tau}}$ for all $x\in S_n\cap S$, then 
\begin{equation}\label{pqtauri}
P(q(\tau)\, \& \,r_n)=\sum_j \abs{ \ip{\chi_{j,\tau}}{\Psi_n}}^2=\ev*{\pi_{n,\tau}}{\Psi_n}.\protect\footnotemark
\end{equation}
\footnotetext{The proof of this is very similar to the proof given in footnote \ref{priproof}.}But if we define $\pi_\tau=\sum_j\dyad{\eta_{j,\tau}}$ where $\{\ket{\eta_{j,\tau}}:j\}$ is the subset of  $\{\ket{\eta_j}:j\}$ with $\hat{T}^{\mu\nu}(y)\ket{\eta_{j,\tau}}=\tau\ket{\eta_{j,\tau}}$, then we also have  $\pi_{n,\tau}=\pi_n\pi_\tau$.\footnote{To see why this is, 
we first show that $\pi_n=\sum_j\dyad{h_{n,j}}$ where $\{\ket{h_{n,j}}:j\}$ is the subset of $\{\ket{\eta_j}:j\}$  for which $\ket{h_{n,j}}\in H_{S_n,\tau_S}$. 
Note that $\pi_n\ket{h_{n,j}}=\ket{h_{n,j}}$    since $\{\ket{\xi_j}:j\}$ is a basis for $H_{S_n,\tau_S}$ and $\ket{h_{n,j}}\in H_{S_n,\tau_S}$. 
Therefore, $\pi_n\pi_{n,h}=\pi_{n,h}$  where  $\pi_{n,h}=\sum_j\dyad{h_{n,j}}$. 
But  $\pi_{n,h}\ket{\xi_j}=\ket{\xi_j}$ since $\{\ket{h_{n,j}}:j\}$ is a basis for $H_{S_n,\tau_S}$ and $\ket{\xi_j}\in H_{S_n,\tau_S}$. 
Therefore, $\pi_{n,h}\pi_n=\pi_n.$ But $\pi_{n,h}\pi_n= \pi_n\pi_{n,h}$ since $\pi_n$ and $\pi_{n,h}$ are Hermitian. Hence, $\pi_n= \pi_{n,h}$. Now the summands of $\pi_n\pi_\tau$ are only going to consist of those $\dyad{\eta_j}$ for which $\hat{T}^{\mu\nu}(y)\ket{\eta_j}=\tau\ket{\eta_j}$ and for which $\hat{T}_S(x)\ket{\eta_j}=\tau_S(x)\ket{\eta_j}$ for all $x\in S_n\cap S$, and these are just the $\dyad*{\chi_{j,\tau}}$ which are the summands of  $\pi_{n,\tau}$. Hence,  $\pi_n\pi_\tau=\pi_{n,\tau}.$} 
  Hence,
\begin{equation}\label{pqtauri2}
P(q(\tau)\, \& \, r_n)=\ev*{\pi_n\pi_\tau}{\Psi_n}.
\end{equation}
But clearly $\hat{T}^{\mu\nu}(y)=\sum_\tau \tau \pi_\tau.$ Therefore, combining (\ref{beable1}), (\ref{Prn}), and (\ref{pqtauri2}), we have 
\begin{equation}\label{kentconsistency0}
\ev*{T^{\mu\nu}(y)}_{\tau_S}=\lim_{n\rightarrow\infty}\frac{\sum_\tau \ev*{\pi_n\pi_\tau}{\Psi_n}\tau}{\ev*{\pi_n}{\Psi_n}}=\lim_{n\rightarrow\infty}\frac{\ev*{\pi_n\hat{T}^{\mu\nu}(y)}{\Psi_n}}{\ev*{\pi_n}{\Psi_n}}.
\end{equation}
We are now in a position to show that Kent's theory is consistent with standard quantum theory. First let us consider what we need to show. 

In the pilot wave interpretation, its consistency with standard quantum theory requires that if one averages the expectation values of an observable over the hidden variables (i.e. the positions and the momenta of all the particles) then one obtains the expectation value of the observable given by standard quantum theory as indicated in equation (\ref{bohmconsistency}). 

Now in Kent's theory, the hidden variables on which his beables $\ev*{T^{\mu\nu}(y)}_{\tau_S}$ depend are the values $\tau_S(x)$ of $T_S(x)$ for $x\in S^1(y)\cap S$. The operator $\pi_n$ in equation (\ref{kentconsistency0}) in the limit as $n\rightarrow\infty$ encapsulates this hidden information. To remind ourselves of $\pi_n$'s dependency on $\tau_S$ restricted to $S_n\cap S$, we will now write $\pi_n(\tau_{S_n\cap S})$ for $\pi_n$ where $\tau_{S_n\cap S}$ is the function $\tau_S$ restricted to $S_n\cap S$. Likewise, we will write  $r_n(\tau_{S_n\cap S})$ for $r_n$, the statement that $T_S(x)=\tau_S(x)$ for all $x\in S_n(y)\cap S$. If we let $j$ index all possible functions $\tau^{(j)}_{S_n\cap S}$ taking real values on $S_n\cap S$,\footnote{Recall that we are implicitly using an approximation scheme described by equation (\ref{tauapproxformula}), so we are really considering functions on the cells of a mesh over $S_n\cap S $ taking values from a finite pool of possible values. Also see footnote \ref{snapprox}. This is why we can use an index $j$ to index all the $\tau^{(j)}_{S_n\cap S}.$ } then the analogue of (\ref{bohmconsistency}) requires us to show that 
\begin{equation}\label{kentconsistency}
\ev*{\hat{\bm{T}}^{\mu\nu}(y)}{\Psi_0}=\lim_{n\rightarrow\infty}\sum_{j}P\big(r_n(\tau^{(j)}_{S_n\cap S})\big)\ev*{T^{\mu\nu}(y)}_{\tau^{(j)}_{S_n\cap S}}
\end{equation}
for all $y$ lying between $S_0$ and $S$, where the left-hand side of (\ref{kentconsistency}) is just the expectation value of $\hat{\bm{T}}^{\mu\nu}(y)$ in the Heisenberg picture as predicted by standard quantum theory.\footnote{Where we are using Schwinger's bold typeface convention as described in footnote \ref{boldref}.} Equation (\ref{kentconsistency}) is sufficient to establish consistency with standard quantum theory because ultimately, all observables are going to be reducible to expressions dependent on $\hat{T}^{\mu\nu}(y)$, since once we know what to expect for $\hat{T}^{\mu\nu}(y)$, we will know what to expect for the energy and momentum densities for all measuring apparatus readouts etc. and hence what to expect for all measurement outcomes. But from (\ref{Prn}) and (\ref{kentconsistency0}), we have 
\begin{equation}\label{kentconsistency1}
\lim_{n\rightarrow\infty}\sum_jP\big(r_n(\tau^{(j)}_{S_n\cap S})\big)\ev*{T^{\mu\nu}(y)}_{\tau^{(j)}_{S_n\cap S}}=\lim_{n\rightarrow\infty}\sum_{j}{\ev*{\pi_{n}(\tau^{(j)}_{S_n\cap S})\hat{T}^{\mu\nu}(y)}{\Psi_n}}
\end{equation}
Since there is an orthonormal basis $\{\ket{\eta_j}:j\}$ of $H_{S_n}$ consisting of simultaneous $\hat{T}_S(x)$-eigenstates so that $\hat{T}_S(x)\ket{\eta_j}=\tau^{(j)}_{S_n\cap S}(x)\ket{\eta_j}$ for all $x\in S_n\cap S$, it follows that $\sum_j \pi_{n}(\tau^{(j)}_{S_n\cap S})=I$. Combining this with (\ref{kentconsistency1}) we get
\begin{equation}\label{kentconsistency2}
	\lim_{n\rightarrow\infty}\sum_jP\big(r_n(\tau^{(j)}_{S_n\cap S})\big)\ev*{T^{\mu\nu}(y)}_{\tau^{(j)}_{S_n\cap S}}=\lim_{n\rightarrow\infty}\ev*{\hat{T}^{\mu\nu}(y)}{\Psi_n}
	\end{equation}
In the notation of equation (\ref{schwingerformula}), we have $\ket*{\Psi_n}=\ket*{\Psi[S_n]}$, and according to (\ref{schwingerformula}) the expectation value $\ev*{\hat{T}^{\mu\nu}(y)}{\Psi[S_n]}$ will be independent of the hypersurface $S_n$ so long as it contains $y$, and the result will be equal to the expectation value $\ev*{\hat{\bm{T}}^{\mu\nu}(y)}{\Psi_0}$ in the Heisenberg picture which is the value that is predicted by standard quantum mechanics. Therefore, equation (\ref{kentconsistency}) follows from (\ref{schwingerformula}) and (\ref{kentconsistency2}) which is what we were aiming to show for standard quantum consistency to hold.



\section{Kent's Theory and Lorentz Invariance\label{LorentzInvariance}\textsuperscript{*}}
In order to explain what it means for Kent's theory to be Lorentz invariant, we first need to explain how spacetime coordinates look to different observers. 

Up until now we have been representing a spacetime location by a four-tuple $(x^0,$ $x^1,$ $x^2,$ $x^3)$ where $(x^i)_{i=1}^3$ are spatial coordinates, and where $x^0=ct$ with $c$ being equal to the speed of light and $t$ being the time. It will be convenient to represent spacetime locations using a more concise notation. So we let $(1,0,0,0)$ correspond to the spacetime location $\hat{e}_0$, $(0,1,0,0)$ correspond to the spacetime location $\hat{e}_1$, etc.. Then we can express any other spacetime location  as a sum $\sum_{\mu=0}^3x^\mu\hat{e}_\mu$. We will use the so-called \textbf{Einstein summation convention}\index{Einstein summation convention}\label{Einsteinsum} of dropping the summation sign and implicitly assuming that there is a summation whenever an upper index and a lower index are the same so that we can write $x^\mu\hat{e}_\mu$ instead of $\sum_{\mu=0}^3x^\mu\hat{e}_\mu$. We also use the convention of letting Greek letters range over $0$, $1$, $2$, and $3$ (e.g. the $\mu$ in $x^\mu\hat{e}_\mu$), and of letting Roman letters range over $1$, $2$, and $3$ (e.g. the $i$ in $(x^i)_{i=1}^3$).

Now suppose an observer $O$ expresses spacetime locations in terms of $\{\hat{e}_\mu:\mu=0,\ldots,3\}$ and hence uses the coordinates $(x^0, x^1, x^2, x^3)$ to describe various spacetime locations. For another observer $O'$, it may be more natural to express spacetime locations in terms of a different set $\{\hat{e}'_\mu:\mu=0,\ldots,3\}$ so that the location described by $O$ as $(x^0, x^1, x^2, x^3)$ would be described by $O'$ as $({x'}^0, {x'}^1, {x'}^2, {x'}^3)$ where ${x'}^\mu{\hat{e}'}_\mu=x^\mu\hat{e}_\mu$.  For instance if $O$ and $O'$ are moving with respect to each other, they may both want to use coordinates in which their own spatial coordinates are fixed and in which the spatial coordinates of the other observer are changing. As another example, figure \ref{rotfigure} shows how the $(x^1, x^2)$-coordinates transform under a spatial rotation. 


\begin{figure}[ht!]
\captionsetup{justification=justified}
\centering
\tikzmath{	
\lrange = 4;
\rrange=2;	
\textscale = 0.7;
\picscale = 0.58;
\circsize=3.5;
\px=3;
\py=3.5;
\pr=sqrt(\px*\px+\py*\py);
\th=33;
\thd=atan(\py/\px)-\th;
\pyd=\pr*sin(\thd);
\pxd=\pr*cos(\thd);
\rrange =7; 
\labelx= \rrange/2;
\labely=-0.3;
\vr=3;
\vth=75;
\vx=\vr*cos(\vth);
\vy=\vr*sin(\vth);
\vxt=\vx+\px;
\vyt=\vy+\py;
\vrt=sqrt(\vxt*\vxt+\vyt*\vyt);
\vthd=atan(\vyt/\vxt)-\th;
\vxtd=\vrt*cos(\vthd);
\vytd=\vrt*sin(\vthd);
\vxd=\vr*cos(\vth-\th);
\vyd=\vr*sin(\vth-\th);
} 
\begin{tikzpicture}[scale=\picscale] 
    \draw[-latex] (0,0) -- (\rrange,0)  node[right,scale=\textscale, text width=5em] {$\hat{e}_1$};
    \draw[-latex] (0,0) -- (0,\rrange)  node[right,scale=\textscale, text width=5em] {$\hat{e}_2$};
    \draw[dotted, thick] (\px,0) --  (\px,\py) node[midway,right, scale=\textscale]{${x}^2$}; 
     \draw[dotted, thick] (0,\py) --  (\px,\py)  node[midway,above, scale=\textscale]{${x}^1$};  

    \begin{scope}[rotate=\th,draw=red, text=red]
       \draw[-latex] (0,0) -- (\rrange,0)  node[right,scale=\textscale, text width=5em]  {$\hat{e}'_1$};
   	   \draw[-latex] (0,0) -- (0,\rrange)  node[right,scale=\textscale, text width=5em] {$\hat{e}'_2$};
   	   \draw[dotted, thick] (\pxd,0) --  (\pxd,\pyd) node[midway, above=4,right=1,scale=\textscale]{${x'}^2$}; 
   	   \draw[dotted, thick] (0,\pyd) --  (\pxd,\pyd)  node[midway,above, scale=\textscale]{${x'}^1$};  
    \end{scope}

  \draw [black,fill] (\px,\py) circle [radius=\circsize pt] ;
    
    \coordinate[label = below: (a)]  (D) at (\labelx,\labely); 
\end{tikzpicture}% pic 1
\vspace*{2px}
\caption{Shows how a location (marked as $\bullet$) can be expressed either  in coordinates $(x^1, x^2)$ with respect to the basis $\{\hat{e}_1,\hat{e}_2\}$ or in coordinates $({x'}^1,{x'}^2)$ with respect to the basis $\{\hat{e}'_1,\hat{e}'_2\}$.}\label{rotfigure}
\end{figure}

Now the key fact about all observers is that they must always observe light in a vacuum to have a constant speed $c$. Thus,  for a photon that goes through the spacetime locations $(0,0,0,0)$ and $(x^0, x^1, x^2, x^3)$ in the coordinates of $O$, we must have $(x^0, x^1, x^2, x^3)=(ct,tv^1,tv^2,tv^3)$ where 
$$\sqrt{(v^1)^2 +(v^2)^2+(v^3)^2}=c.$$ But if $(0,0,0,0)$ and $(x^0, x^1, x^2, x^3)$ corresponds to $(0,0,0,0)$ and $({x'}^0, {x'}^1, {x'}^2, {x'}^3)$ respectively in the coordinates of another observer $O'$, then we must also have $({x'}^0, {x'}^1, {x'}^2, {x'}^3)=(ct',t'{v'}^1,t'{v'}^2,t'{v'}^3)$ where 
$$\sqrt{({v'}^1)^2 +({v'}^2)^2+({v'}^3)^2}=c.$$ 
In either case, we must have 
\begin{equation}\label{invariant}
(x^0)^2- (x^1)^2- (x^2)^2 - (x^3)^2=({x'}^0)^2- ({x'}^1)^2- ({x'}^2)^2 - ({x'}^3)^2=0.
\end{equation}
If we define $\eta_{00}=1$, $\eta_{ii}=-1$ for $i=1,2,3$ and $\eta_{\mu\nu}=0$ for $\mu\neq\nu$, then using the Einstein summation convention as well as the convention of lowering indices so that we define $x_\mu\myeq\eta_{\mu\nu}x^\nu$, then (\ref{invariant}) is equivalent to 
$$x_\mu x^\mu={x'}_\mu {x'}^\mu=0.$$ 
Thus, for any coordinate transformation $x\rightarrow x'$ such that  $x_\mu x^\mu={x'}_\mu{x'}^\mu$,  if the speed of light is $c$ in the $x$-coordinates, then the speed of light is also guaranteed to be $c$ in the $x'$-coordinates.  A \textbf{Lorentz transformation}\index{Lorentz transformation} $\Lambda$ is any coordinate transformation of the form ${x'}^\mu=\Lambda\indices{^\mu_\nu}x^\nu$\label{coordtansformation} such that $x_\mu x^\mu={x'}_\mu{x'}^\mu$. Since a Lorentz transformation must satisfy
$$x_\mu x^\mu=\eta_{\mu\rho}\Lambda\indices{^\rho_\sigma}x^\sigma\Lambda\indices{^\mu_\nu}x^\nu$$
for all $x$, it follows that  
\begin{equation}\label{lorentztrans}
\Lambda\indices{^\rho_\mu}\eta_{\rho\sigma}\Lambda\indices{^\sigma_\nu}=\eta_{\mu\nu}.\protect\footnotemark
\end{equation}
\footnotetext{To see why this is, note that if  $x_\mu x^\mu={x'}_\mu{x'}^\mu$ for all $x$, then  for any other spacetime location $y$, we have $(x+y)_\mu (x+y)^\mu={(x'+y')}_\mu{(x'+y')}^\mu$. If we expand this out and cancel $x_\mu x^\mu$ with ${x'}_\mu{x'}^\mu$ and cancel $y_\mu y^\mu$ with ${y'}_\mu{y'}^\mu$, and using the fact that $y_\mu x^\mu=x_\mu y^\mu$, etc. we find that  $x_\mu y^\mu={x'}_\mu{y'}^\mu$ for all $x$ and $y$. Hence,
$$\eta_{\nu\mu}x^\mu y^\nu = x_\mu y^\mu=\eta_{\sigma\rho}\Lambda\indices{^\rho_\mu}\Lambda\indices{^\sigma_\nu}x^\mu y^\nu.$$  
Since we can choose $x$ such that $x^\mu=1$ and $x^\alpha = 0$ for $\alpha\neq\mu$, and can choose $y$ such that $y^\nu=1$ and $y^\beta=0$ for $\beta\neq\nu$. Then we get
$$\eta_{\mu\nu} = \eta_{\sigma\rho}\Lambda\indices{^\rho_\mu}\Lambda\indices{^\sigma_\nu}, $$ and hence the result follows.}Having considered how the coordinates of a spacetime location viewed by one observer relate to the coordinates of the same spacetime location viewed by a different observer, we can now consider how physical quantities viewed by different observers relate to each other. The simplest kind of physical quantity is called a \textbf{scalar}\index{scalar}. A scalar defined at a particular spacetime location has the same value no matter what frame of reference an observer uses. One example of a scalar is an object's \textbf{rest mass}\index{rest mass} which is the mass an object would have if it had no velocity. There is still a transformation rule for scalars since the spacetime location at which the scalar is measured is usually expressed in terms of an observer's coordinate system, and the coordinates of  such a location  will differ for different observers. Thus, if $\phi(x)\myeq\phi(x^0, x^1, x^2, x^3)$ is the value of a scalar defined at the spacetime location $(x^0, x^1, x^2, x^3)$ as described by an observer $O$, then another observer $O'$ using a different set of coordinate $({x'}^0, {x'}^1, {x'}^2, {x'}^3)$ to describe the spacetime location $(x^0, x^1, x^2, x^3)$ will describe this same scalar as $\phi'(x')\myeq\phi'({x'}^0, {x'}^1, {x'}^2, {x'}^3)$  where $\phi'(x')=\phi(x)$. Therefore
\begin{equation}\label{lorentzscalar}
\phi'(x')=\phi(\Lambda^{-1}x')
\end{equation} 
where $\Lambda^{-1}$ is the inverse Lorentz transformation that takes the coordinates $x'=({x'}^0, {x'}^1, {x'}^2, {x'}^3)$ of a spacetime location to the coordinates $x=(x^0, x^1, x^2, x^3)$ describing that spacetime location. Thus, equation (\ref{lorentzscalar}) shows us how a scalar transforms under a Lorentz transformation $\Lambda$. 

Many physical quantities, however, are not scalars and so will look different to different observers. For instance, the energy of an object has a kinetic component that depends on the velocity the object has relative to an observer. However, it turns out that if an observer $O$ considers an object's energy $E$ together with its three components of momentum $p^1, p^2$, and $p^3$ (in the directions $\hat{e}_1$, $\hat{e}_2$, and $\hat{e}_3$ respectively) to form the four-tuple $p\myeq(E/c, p^1, p^2, p^3)$ known as the object's \textbf{four-momentum}\index{four-momentum}, then $p$ transforms in the same way as spacetime coordinates transform between different observers. In other words, a different observer $O'$ whose coordinates are given by ${x'}^\mu=\Lambda\indices{^\mu_\nu}x^\nu$ would observe the object's four-momentum to be ${p'}^\mu=\Lambda\indices{^\mu_\nu}p^\nu$.\footnote{In order for $p$ to transform in this way, we have to redefine what we mean by energy and momentum. In classical mechanics, the momentum of an object is the product of the object's mass and its velocity. In the context of special relativity, however, the four-momentum of an object is defined to be the product of its rest mass $m_0$ and its \textbf{four-velocity}\index{four-velocity} where the four velocity of an object is a four-tuple $(u^0, u^1, u^2, u^3)$ with $u_\mu u^\mu=c^2$ such that the object's velocity (in the classical sense) is the vector $(c \frac{u^1}{u^0}, c \frac{u^2}{u^0}, c\frac{u^3}{u^0})$. The motivation for this definition can be seen by considering an object whose classical velocity is $\vb{v}=(v^1,v^2,v^3)$ that goes through $(0,0,0,0)$. It will have a spacetime trajectory $x(t)=(ct, v^1 t, v^2 t, v^3 t)$. $u$ is just the four-vector proportional to $x(1)$ with $u_\mu u^\mu=c^2$, so if $\gamma$ is the constant of proportionality such that $u^0=\gamma c$ and $u^i=\gamma v^i$, then by eliminating $\gamma$ we get $v^i=c\frac{u^i}{u^0}$.  We can then easily work out the constant of proportionality $\gamma$ and hence the
four-velocity $u$ of an object whose classical velocity is $\vb{v}$. For we must have $u^i=\frac{v^i u^0}{c}$, for $i=1$ to $3$. Therefore, since $u_\mu u^\mu=c^2$, we must have $(u^0)^2\big(1-\frac{v^2}{c^2}\big)=c^2$ where $v=\sqrt{({v}^1)^2+({v}^2)^2+({v}^3)^2}$. Thus, if we define $\beta={v}/{c}$ and $\gamma=\frac{1}{\sqrt{1-\beta^2}}$, then $u^0=\gamma c$ and $u^i=\gamma v^i$ for $i=1$ to $3$, and hence the four-velocity of the object must be $u=\gamma(c,v^1,v^2,v^3).$ From this, we see that the object's four-momentum will be $\gamma m_0(c,v^1,v^2,v^3).$ If the object's velocity is very small compared to the speed of light, then $\gamma\approx 1+\frac{v^2}{2c^2}$, and hence the object's four-momentum $(E/c, p^1, p^2, p^3)$ will be approximately $(m_0c+\frac{1}{2}m_0{v^2}/c, m_0v^1,m_0v^2,m_0v^3)$. Therefore, $(p^1, p^2, p^3)$ is approximately equal to the classical momentum. However, the energy is now $E=m_0c^2+\frac{1}{2}m_0{v^2}$. Thus, in addition to the kinetic energy term $\frac{1}{2}m_0{v^2}$, there is a rest mass energy $m_0c^2$. If we define the \textbf{relativistic mass}\index{relativistic mass} $m=\gamma m_0$, then we obtain Einstein's famous formula $E=mc^2$.  } More generally, any list of four physical quantities $(\varphi^0, \varphi^1, \varphi^2, \varphi^3)$ that transforms as $\varphi\rightarrow\varphi'$ with  ${\varphi'}^\mu=\Lambda\indices{^\mu_\nu}\varphi^\nu$ is called a \textbf{four-vector}\index{four-vector}.   
\begin{figure}[ht!]
	\captionsetup{justification=justified}
	\centering
	\tikzmath{
	\textscale = 0.7;
	\picscale = 0.58;
	\circsize=3.5;
	\px=3;
	\py=3.5;
	\pr=sqrt(\px*\px+\py*\py);
	\th=33;
	\thd=atan(\py/\px)-\th;
	\pyd=\pr*sin(\thd);
	\pxd=\pr*cos(\thd);
	\rrange =7; 
	\labelx= \rrange/2;
	\labely=-0.3;
	\vr=3;
	\vth=75;
	\vx=\vr*cos(\vth);
	\vy=\vr*sin(\vth);
	\vxt=\vx+\px;
	\vyt=\vy+\py;
	\vrt=sqrt(\vxt*\vxt+\vyt*\vyt);
	\vthd=atan(\vyt/\vxt)-\th;
	\vxtd=\vrt*cos(\vthd);
	\vytd=\vrt*sin(\vthd);
	\vxd=\vr*cos(\vth-\th);
	\vyd=\vr*sin(\vth-\th);
	} 
	\begin{tikzpicture}[scale=\picscale ] 
		\draw[-latex] (0,0) -- (\rrange,0)  node[right,scale=\textscale, text width=5em] {$\hat{e}_1$};
		\draw[-latex] (0,0) -- (0,\rrange)  node[right,scale=\textscale, text width=5em] {$\hat{e}_2$};
		\draw[dotted, thick] (\px,0) --  (\px,\py) node[midway,right, scale=\textscale]{${x}^2$}; 
		\draw[dotted, thick] (0,\py) --  (\px,\py)  node[midway,above, scale=\textscale]{${x}^1$};  
		
		\draw[-latex] (\px,\py)  -- (\px+\vx,\py+\vy)  node[right=22,above=-4,scale=\textscale, text width=5em] {${\varphi}$};
		\draw[dotted, thick] (\px,\py) --  (\px,\py+\vy) node[midway,left, scale=\textscale]{${\varphi}^2$}; 
		\draw[dotted, thick] (\px,\py+\vy) --  (\px+\vx,\py+\vy) node[midway,above, scale=\textscale]{${\varphi}^1$};  
	
		\begin{scope}[rotate=\th,draw=red, text=red]
		   \draw[-latex] (0,0) -- (\rrange,0)  node[right,scale=\textscale, text width=5em]  {$\hat{e}'_1$};
			  \draw[-latex] (0,0) -- (0,\rrange)  node[right,scale=\textscale, text width=5em] {$\hat{e}'_2$};
		\draw[dotted, thick] (\pxd,\pyd) --  (\vxtd,\pyd) node[midway,right=3,below=-3, scale=\textscale]{${\varphi'}^1$}; 
		\draw[dotted, thick] (\vxtd,\pyd) --  (\vxtd,\vytd) node[midway,right=6,above=-4, scale=\textscale]{${\varphi'}^2$};  
		\end{scope}
	
	  \draw [black,fill] (\px,\py) circle [radius=\circsize pt];    
		\coordinate[label = below: (b)]  (D) at (\labelx,\labely); 
	\end{tikzpicture}% pic 1
	\vspace*{2px}
	\caption{Shows how a four-vector ${\varphi}$ (of which only two components are shown) defined at a spacetime location (indicated by $\bullet$) can be expressed either as $(\varphi^1, \varphi^2)$ with respect to the basis $\{\hat{e}_1,\hat{e}_2\}$ or as $({\varphi'}^1,{\varphi'}^2)$ with respect to the basis $\{\hat{e}'_1,\hat{e}'_2\}$.}\label{rotfigure2}
	\end{figure}
	Figure \ref{rotfigure2} shows how (two of) the components of a four-vector $\varphi$ at a particular location will differ for different observers under a spatial rotation of the coordinates. A four-vector $\varphi^\mu(x)$ defined at every spacetime location $x$ is called a \textbf{four-vector field}\index{four-vector field}. Thus,  at each spacetime location $x$, the four-vector field $\varphi^\mu(x)$ assigns four numbers, $\varphi^0(x)$, $\varphi^1(x)$, $\varphi^2(x)$, and $\varphi^3(x)$. If $O$ observes this vector-field $\varphi^\mu(x)$, and $O'$ is another observer whose coordinates are related to the coordinates $O$ via the Lorentz transformation $\Lambda$, then $O'$ will describe the same physical reality that $O$ describes by assigning four numbers ${\varphi'}^0(x')$, ${\varphi'}^1(x')$, ${\varphi'}^2(x')$, and ${\varphi'}^3(x')$ at every spacetime location $x'$, and the relationship between the description $O$ gives and the  description $O'$ gives will be given by the formula
	$${\varphi'}^\mu(x')=\Lambda\indices{^\mu_\nu}\varphi^\nu(x).$$
	Hence, under the Lorentz transformation $\Lambda$,  a vector field $\varphi^\mu(x)$ transforms as ${\varphi}^\mu(x)\rightarrow {\varphi'}^\mu(x')$ where
	\begin{equation}\label{lorentzvector}
	{\varphi'}^\mu(x')=\Lambda\indices{^\mu_\nu}\varphi^\nu(\Lambda^{-1}x').
	\end{equation} 



From a four-vector $\varphi^\mu$, we can also define the so-called \textbf{four-covector}\index{four-covector}: 
\begin{equation}\label{covector}
	\varphi_\mu\myeq\eta_{\mu\nu}\varphi^\nu.
\end{equation}
To see how four-covectors transform under a Lorentz transformation $\Lambda$, it will be helpful to define 
\begin{equation}\label{colambda}
	\Lambda\indices{_\mu^\nu}\myeq\eta_{\mu\rho}\eta^{\nu\sigma}\Lambda\indices{^\rho_\sigma}
\end{equation}
where $\eta^{\nu\sigma}=\eta_{\nu\sigma}$. If we also define the \textbf{Kronecker-delta}\index{Kronecker-delta} $\delta^\nu_\mu$ such that $\delta^\nu_\mu=1$ when $\mu=\nu$ and $\delta^\nu_\mu=0$ otherwise, then using the fact that $\eta_{\mu\rho}\eta^{\nu\rho}=\delta^\nu_\mu$ together with equation (\ref{lorentztrans}), we have 
\begin{equation}\label{lambdainverse}
\Lambda\indices{^\rho_\mu}\Lambda\indices{_\rho^\nu}=\delta^\nu_\mu.
\end{equation}
Since by definition, the inverse of $\Lambda^{-1}$ satisfies 
$(\Lambda^{-1})\indices{^\nu_\rho}\Lambda\indices{^\rho_\mu}=\delta^\nu_\mu,$
 we have $(\Lambda^{-1})\indices{^\nu_\rho}=\Lambda\indices{_\rho^\nu}.$  From (\ref{lorentzvector}), (\ref{covector}), and (\ref{colambda}), we therefore see that under a Lorentz transformation $\Lambda$, a four-covector field $\varphi_\mu(x)$ transforms as $\varphi_\mu(x)\rightarrow\varphi'_\mu(x')$
where
\begin{equation}\label{lorentzcovector}
\varphi'_\mu(x')=\Lambda\indices{_\mu^\nu}\varphi_\nu(\Lambda^{-1}x')
\end{equation}
 

Besides scalars, four-vectors, and four-covectors, we also need to consider physical quantities called rank-two tensors. The stress-energy tensor $T^{\mu\nu}$ introduced on page \pageref{stressenergy} is an example of a rank-two tensor. The defining property of a rank-two tensor field $\varphi^{\mu\nu}(x)$ is that under a Lorentz transformation $\Lambda$, it transforms as $\varphi^{\mu\nu}(x)\rightarrow{\varphi'}^{\mu\nu}(x')$ where
\begin{equation}\label{lorentztensor}
{\varphi'}^{\mu\nu}(x')=\Lambda\indices{^\mu_\rho}\Lambda\indices{^\nu_\sigma}\varphi^{\rho\sigma}(\Lambda^{-1}x').
\end{equation}
On page \pageref{massenergydensity}, we introduced the mass-energy density $T_S(x)$ on a spacelike hypersurface $S$. As explained in section \ref{massenergydensity}, the values of $T_S(x)$ for all $x\in S$ are the additional values that Kent uses to supplement standard quantum theory.  It was mentioned in passing that $T_S(x)$ does not depend on which frame of reference one is in. In other words, $T_S(x)$ is a scalar. I will now explain why this is so. 

We first need to consider the precise definition of $T_S(x)$. At each spacetime location on the spacelike hypersurface $S$ which an observer $O$ describes as having coordinates $x=(x^\mu)_{\mu=0}^3$, we define  $\eta^\mu(x)$ to be the future-directed  unit four-vector at $x$ that is orthogonal to $S$. In other words, $\eta^0(x)>0$, $\eta_\mu(x)\eta^\mu(x)=1$, and if $y\in S$ is very close to $x$, then 
\begin{equation}\label{etaorthog}
\frac{(x-y)_\mu\eta^\mu(x)}{\sqrt{(x-y)_\nu(x-y)^\nu}}\approx 0.
\end{equation}$T_S(x)$ is then given by the formula 
\begin{equation}\label{TSdef}
T_S(x)=T^{\mu\nu}(x)\eta_{\mu}(x)\eta_{\nu}(x).
\end{equation}
For example, if $S$ was the spacelike hypersurface consisting of all spacetime locations $x = (0,x^1,x^2,x^3)$, then $\big(\eta^{0}(x),\eta^{1}(x),\eta^{3}(x),\eta^{3}(x)\big) =(1,0,0,0),$ and hence $T_S(x)=T^{00}(x)$ which is the density of relativistic mass at $x$, i.e. the energy density at $x$ divided by $c^2$. Note that the condition that $y\in S$ is very close to $x$ in (\ref{etaorthog}) means that $T_S(x)$ only has a local dependence \label{localdependenceS} on $S$ in the vicinity of $x$. i.e. if $S'$ only differs from $S$ outside the vicinity of $x$, then  $T_{S'}(x)=T_S(x).$

To see why $T_S(x)$ is a scalar, suppose that $\Lambda$ is a Lorentz transformation such that $\Lambda\indices{^0_\mu}\eta^\mu>0$ for any future-directed  unit four-vector vector $\eta^\mu$. We refer to a $\Lambda$ with this property as an \textbf{orthochronous}\index{Lorentz transformation!orthochronous} Lorentz transformation. Also, suppose that $O$ and $O'$ are two observers such that spacetime locations that observer $O$ describes as having coordinates $x=(x^\mu)_{\mu=0}^3$ are described by $O'$ as having coordinates $x'=(\Lambda\indices{^\mu_\nu}x^\nu)_{\mu=0}^3$. Then since ${x'}_\mu{y'}^\mu= x_\mu y^\mu$, it follows that the future-directed unit four-vector orthogonal to $S$ at $x$ which $O$ describes as $\eta^\mu(x)$ will be described by $O'$ as  ${\eta'}^\mu(x')=\Lambda\indices{^\mu_\nu}\eta^\nu(x)$. Thus, for any spacetime location in $S$ that $O'$ describes as having coordinates $x'$ with corresponding  future-directed $S$-orthogonal unit four-vector ${\eta'}^\mu(x')$, $O'$ can construct a function $T'_S(x')$  with 
\begin{equation}\label{TSprimedef}
T'_S(x')=T'^{\mu\nu}(x')\eta'_{\mu}(x')\eta'_{\nu}(x').
\end{equation}
Then using  (\ref{lorentzcovector}) and (\ref{lorentztensor}) on the right-hand side of (\ref{TSprimedef}),  we have
\begin{equation}\label{invariantTS1}
\begin{split}
T'_S(x')&=\Lambda\indices{^\mu_\rho}\Lambda\indices{^\nu_\sigma}T^{\rho\sigma}(x)\Lambda\indices{_\mu^\alpha}\eta_{\alpha}(x)\Lambda\indices{_\nu^\beta}\eta_{\beta}(x)\\
&=\Lambda\indices{^\mu_\rho}\Lambda\indices{_\mu^\alpha} \Lambda\indices{^\nu_\sigma}\Lambda\indices{_\nu^\beta}T^{\rho\sigma}(x)\eta_{\alpha}(x)\eta_{\beta}(x)\\
&=\delta^\alpha_\rho\delta^\beta_\sigma T^{\rho\sigma}(x)\eta_{\alpha}(x)\eta_{\beta}(x)\\
&=T^{\alpha\beta}(x)\eta_{\alpha}(x)\eta_{\beta}(x)\\
&=T_S(x)
\end{split}
\end{equation}
where on the third line we have used (\ref{lambdainverse}), and on the last line we have used (\ref{TSdef}). To obtain (\ref{invariantTS1}), we assumed that $\Lambda$ is orthochronous because definition (\ref{TSdef}) assumes that $\eta^\mu(x)$ is future-directed. But if $\Lambda$ is non-orthochronous, we would need to take the negations of ${\eta'}^\mu(x')$ to get the future-directed $S$-orthogonal unit four-vector. But clearly this will not affect the equality in (\ref{invariantTS1}), so (\ref{invariantTS1}) holds for all Lorentz transformations, whether they are orthochronous or non-orthochronous.  We thus see that   $T_S(x)$ is a scalar.

Let us now consider the Hilbert space $H_{S_n}$  for a spacelike hypersurface $S_n$ as defined on page \pageref{HSidef}.\footnote{Also see page \pageref{HSdef} for the definition of $H_S$.} 
Given that $\hat{T}^{\mu\nu}(x)$ is the observable in the Tomonaga-Schwinger picture whose eigenstates with eigenvalues $\tau$ are the states of $S_n$ for which an observer $O$ observes the stress-energy tensor $T^{\mu\nu}(x)$ to take the value $\tau$ at $x$, it follows from (\ref{TSdef}) that 
\begin{equation}\label{TShat}
	\hat{T}_S(x)\myeq \hat{T}^{\mu\nu}(x)\eta_{\mu}(x)\eta_{\nu}(x)
	\end{equation}
will be the observable whose eigenstates with eigenvalues $\tau_S(x)$ are the states of $S_n$ for which an observer $O$ observes $T_S(x)$ to take the value $\tau_S(x)$ at $x$ when $x\in S_n\cap S$.\footnote{So long as $S_n$ and $S$ are tangential at $x$ as noted in footnote \ref{tangentialnote}.}
 
Now two observers $O$ and $O'$ will typically assign different physical states to $S_n$ based on their frame of reference. E.g. if $O$ and $O'$ are traveling at different speeds, they will attribute different energy levels and momenta to the spacetime locations of $S_n$. To understand the relationship between the states $O$ assigns to $S_n$ and the states $O'$ assigns, suppose $\ket*{\psi}$ and  $\ket*{\chi}$ are two states that an observer $O$ might judge $S_n$ to be in. As usual, we suppose the coordinates $x^\mu$ of observer $O$ transform to coordinates ${x'}^\mu=\Lambda\indices{^\mu_\nu}x^\nu$ of observer $O'$ for some Lorentz transformation $\Lambda.$ We also suppose that the states $\ket*{\psi}$ and $\ket*{\chi}$ that $O$ observes will transform to states $\ket*{\psi'}$  and $\ket*{\chi'}$ that $O'$ observes. We will denote the Hilbert space of the states on $S_n$ that $O'$ can observe as $H_{S_n}'$.\label{Hprimespace}\footnote{As we will discuss shortly, there is a map inner product preserving map $U(\Lambda)$ via which there is a one-to-one correspondence between states in $H_{S_n}$ and states in $H_{S_n}'$ so we can identify $H_{S_n}'$ with $H_{S_n}$ in which case $U(\Lambda)$ will be a unitary operator.}

Now if  $O$ judged $S_n$ to be in the superposition state $\ket{\psi}+\ket{\chi}$, then $O'$ would judge $S_n$ to be proportional to the superposition state $\ket{\psi'}+\ket{\chi'}$. Also recall that $\ket*{\psi'}$ and $\lambda\ket*{\psi'}$ represent the same physical state for any complex number $\lambda$, so there is sufficient flexibility as to which state we deem $\ket*{\psi}$ transforms to that we can deem the transformation $\ket{\psi}\rightarrow\ket*{\psi'}$ to be a linear transformation. But also note that if observer $O$ uses the Born rule to calculate the transition probability from state $\ket*{\psi}$ to state $\ket*{\chi}$, and  observer $O'$ uses the Born rule to calculate the transition probability from state $\ket*{\psi'}$ to state $\ket*{\chi'}$, then they should calculate the same probabilities. We must therefore have
$$|\ip*{\chi}{\psi}|^2=|\ip*{\chi'}{\psi'}|^2.$$
Using this fact together with the fact that $\ket*{\psi}$ and $\lambda\ket*{\psi}$ represent the same physical states, it can be shown that there is a unitary operator $U(\Lambda)$ which relates the states $\ket*{\psi}$ and $\ket*{\psi'}$ via the formulated
$$\ket*{\psi'}=U(\Lambda)\ket*{\psi}.\protect\footnotemark$$\footnotetext{For more details, see \cite{Wigner1939}. Since a unitary operator maps a Hilbert space to itself, we first need to identify $H_{S_n}$ and $H_{S_n}'$ in order for $U(\Lambda)$ to be unitary.}At this point, it is worth clarifying the different meanings of $T^{\mu\nu}(x)$, $T^{\prime\mu\nu}(x')$, $\tau^{\mu\nu}(x)$, $\tau^{\prime\mu\nu}(x')$,  $\hat{T}^{\mu\nu}(x)$ and $\hat{T}^{\prime\mu\nu}(x')$. 
\begin{itemize}
\item We use $T^{\mu\nu}(x)$ to refer to the description of the physical quantity that is being observed by $O$. Thus, $T^{\mu\nu}(x)$ is shorthand for the description ``the $\mu\nu$-component of the stress-energy tensor that $O$ observes at the spacetime location belonging to $S$ that $O$ describes as  $x$.'' 
\item Similarly,  $T^{\prime\mu\nu}(x')$ is shorthand for the description ``the $\mu\nu$-component of the stress-energy tensor that $O'$ observes at a spacetime location  belonging to $S$ that $O'$ describes as $x'$.'' 
\item $\tau^{\mu\nu}(x)$ stands for a particular (real) value of the physical quantity described by $T^{\mu\nu}(x)$ that $O$ observes, and 
\item $\tau^{\prime\mu\nu}(x')$ stands for a particular (real) value of the physical quantity described by $T^{\prime\mu\nu}(x')$ that $O'$ observes.
\item $\hat{T}^{\mu\nu}(x)$ for $x\in S_n$ is the Tomonaga-Schwinger observable acting on $H_{S_n}$ such that if observer $O$ deemed $S_n$ to be in an eigenstate $\ket*{\psi}$ of $\hat{T}^{\mu\nu}(x)$ with eigenvalue $\tau$ (a real number), then observer $O$ would observe the physical quantity described by  $T^{\mu\nu}(x)$ to have the value $\tau$.\footnote{Note that we consider a real number $\tau$ here rather than a real valued function $\tau^{\mu\nu}(x)$ of spacetime locations $x\in S$ and indices $\mu$ and $\nu$ since $\hat{T}^{\mu\nu}(x)$ will not in general commute for different values of $\mu$, $\nu$, so we won't be able to find a state which is a simultaneous eigenstate for all the different observables $\hat{T}^{\mu\nu}(x)$, though we may find a state which is very close to being an eigenstate of all the  $\hat{T}^{\mu\nu}(x)$ for different $\mu$ and $\nu$.} 
\item $\hat{T}^{\prime\mu\nu}(x')$ is the Tomonaga-Schwinger observable acting on $H_{S_n}'$ such that if observer $O'$ deemed $S_n$ to be in an eigenstate $\ket*{\psi'}$ of  $\hat{T}^{\prime\mu\nu}(x')$ with eigenvalue $\tau'$, then observer $O'$ would observe the physical quantity described by  $T^{\prime\mu\nu}(x')$ to have the value $\tau'$. 
\item $T_S(x)={T}^{\mu\nu}(x)\eta_{\mu}(x)\eta_{\nu}(x)$ is shorthand for the description ``the mass-energy density of the spacelike hypersurface $S$ observed by observer $O$ at a spacetime location that $O$ describes as $x$''. 
\item $T'_S(x')={T}^{\prime\mu\nu}(x')\eta'_{\mu}(x')\eta'_{\nu}(x')$ is shorthand for the description ``the mass-energy density of the spacelike hypersurface $S$ observed by observer $O'$ at a spacetime location that $O'$ describes as $x'$''. 
\item The function $\tau_S(x)$ stands for a particular range of values for each $x\in S$ of the physical quantity described by $T_S(x)$ observed by $O$. 
\item The function $\tau'_S(x')$ stands for a particular range of values for each $x'\in S$ of the physical quantity described by $T'_S(x')$ observed by $O'$. 
\item For each $x\in S$, $\hat{T}_S(x)=\hat{T}^{\mu\nu}(x)\eta_{\mu}(x)\eta_{\nu}(x)$ is the Tomonaga-Schwinger observable  such that if an observer $O$ deems $S$ to be in an eigenstate $\ket*{\psi}\in H_{S_n}$ of  $\hat{T}_S(x)$ with eigenvalue $\tau$ (a real number), then  $O$ would observe the physical quantity described by  $T_S(x)$ to have the value $\tau$. 
\item For each $x'\in S$, $\hat{T}'_S(x')=\hat{T}^{\prime\mu\nu}(x)\eta'_{\mu}(x')\eta'_{\nu}(x')$ is the Tomonaga-Schwinger observable  such that if an observer $O'$ deems $S$ to be in an eigenstate $\ket*{\psi'}\in H'_{S_n}$ of  $\hat{T}'_S(x')$ with eigenvalue $\tau'$ (a real number), then  $O'$ would observe the physical quantity described by  $T'_S(x')$ to have the value $\tau'$. 
\end{itemize}



Having clarified this terminology, we see that if $\ket*{\psi}\in H_{S_n}$ is a state for which $T^{\mu\nu}(x)\approx \tau^{\mu\nu}(x)$,\footnote{We say approximately ($\approx$) here since the operators $\hat{T}^{\mu\nu}$ will not in general commute, so we won't typically be able to find a state $\ket*{\psi}$ which is an eigenstate for all the observables $\hat{T}^{\mu\nu}$. It is the non-commutativity of observables that is responsible for Heisenberg's uncertainty principle.} and if $\ket*{\psi'}\in H_{S_n}'$ is a state for which $T^{\prime\mu\nu}(x')\approx \tau^{\mu\nu}(x')$, then
\begin{subequations}
\begin{align}
\hat{T}^{\mu\nu}(x)\ket{\psi}&\approx\tau^{\mu\nu}(x)\ket{\psi}, \text{ and }\label{stres1}\\ 
\hat{T}^{\prime\mu\nu}(x')\ket{\psi'}&\approx{\tau'}^{\mu\nu}(x')\ket{\psi'}.\label{stres1}
\end{align}
\end{subequations}
It then follows from (\ref{stres1}) that if $\ket{\psi'}=U(\Lambda)\ket{\psi}$, then
\begin{equation}\label{stress3}
    U(\Lambda)^{-1}\hat{T}^{\prime\mu\nu}(x')U(\Lambda)\ket{\psi}\approx{T'}^{\mu\nu}(x')\ket{\psi}.
\end{equation}
Therefore, in order for (\ref{lorentztensor}) to hold for ${T'}^{\mu\nu}(x')$ in the classical limit (where we treat the stress-energy observables as though they commute with each other and replace the approximations by equalities), by plugging an operator form of  (\ref{lorentztensor}) into (\ref{stress3}), we see that we must have
\begin{equation}\label{TUrelation}
U(\Lambda)^{-1}\hat{T}^{\prime\mu\nu}(x')U(\Lambda)=\Lambda\indices{^\mu_\rho}\Lambda\indices{^\nu_\sigma}\hat{T}^{\rho\sigma}(\Lambda^{-1}x').
\end{equation}



Now to say that Kent's model is Lorentz invariant, is to say that (\ref{kentconsistency0}) defines a rank-two tensor, for then this quantity and the quantities on which it depends will transform in the way that physical quantities should transform under a Lorentz transformation $\Lambda$ when the spacetime coordinates of two observers $O$ and $O'$ are related by the formula ${x'}^\mu=\Lambda\indices{^\mu_\nu}x^\nu$.\footnote{Note that having a privileged spacelike hypersurface $S$ in which a notional measurement of $T_S$ is made does not of itself break Lorentz invariance. Just because we are privileging a spacelike hypersurface $S$, we are not making any assumptions about simultaneity being defined by $S$. Because spacelike separation is a Lorentz invariant proper, both $O$ and $O'$ will deem the spacetime locations on $S$ to be spacelike separated. The Lorentz transformation itself has absolutely no effect on what $S$ is. It is just that $O$ and $O'$ will use different coordinates to describe a particular spacetime location on $S$. It maybe that in the coordinate system of $O$, some of the spacetime locations of $S$ are simultaneous (i.e. have the same $x^0$ value), but there is no requirement of simultaneity, and there is no claim that a reference frame in which the spacetime locations of $S$ are simultaneous is particularly special. In Kent's theory, it is sufficient for there to be just one hypersurface on which  $T_S$ has a determinate value. But if another hypersurface were to be chosen instead, it would make no difference to empirical adequacy since (\ref{kentconsistency}) will hold regardless of what spacelike hypersurface $S$ is chosen.} Thus, in order to show that Kent's model is Lorentz invariant, we need to show that if $\{\ket{\xi_j}:j\}$ is an orthonormal basis of the Hilbert space of states\footnote{Thus, $H_{S_n,\tau_S}$ is the subspace of states $\ket{\xi}\in H_{S_n}$ for which  $\hat{T}_S(x)\ket{\xi}=\tau_S(x)\ket{\xi}$  for all $x\in S_n\cap S$ as mentioned on page \pageref{HStau}.} $H_{S_n,\tau_S}$ for which $O$ observes $T_S(x)$ to be $\tau_S(x)$ for all $x\in S_n(y)\cap S$, and if $\{\ket{\xi_j'}:j\}$ is an orthonormal basis of the Hilbert space of states\footnote{Thus,  $H'_{S_n,\tau'_S}$ is the subspace of states $\ket{\xi'}\in H'_{S_n}$ for which  $\hat{T}'_S(x')\ket{\xi'}=\tau'_S(x')\ket{\xi'}$  for all $x'\in S_n\cap S$. } $H'_{S_n,\tau_S'}$ for which $O'$ observes $T'_S(x')$ to be $\tau'_S(x')$ for all $x'\in S_n(y')\cap S$, then
\begin{equation}\label{kentlorentz}
\lim_{n\rightarrow\infty}\frac{\ev{\pi_n'\hat{T}^{\prime\mu\nu}(y')}{\Psi_n'}}{\ev{\pi_n'}{\Psi_n'}}=\Lambda\indices{^\mu_\rho}\Lambda\indices{^\nu_\sigma} \lim_{n\rightarrow\infty}\frac{\ev{\pi_n\hat{T}^{\rho\sigma}(y)}{\Psi_n}}{\ev{\pi_n}{\Psi_n}}
\end{equation}
where $\pi_n=\sum_j\dyad{\xi_j}$, $\pi_n'=\sum_j\dyad{\xi_j'}$, and $\ket{\Psi_n'}=U(\Lambda)\ket{\Psi_n}$. 

To see why (\ref{kentlorentz}) holds, we first recall that $\pi_n'$ will be independent of which orthonormal basis we choose for $H_{S_n,\tau_S'}$.\footnote{We showed this was the case for $\pi_n$ in footnote \ref{priproof} on page \pageref{priproof}.} Therefore, if we can show that $\{\ket{\xi_j'}\myeq U(\Lambda)\ket{\xi_j}:j\}$ is an orthonormal basis of $H_{S_n,\tau_S'}$, it will follow that $\pi_n'=U(\Lambda)\pi_nU(\Lambda)^{-1}$. 

That the elements of $\{U(\Lambda)\ket{\xi_j}:j\}$ are orthonormal follows from the unitarity of $U(\Lambda)$ together with the orthonormality of  $\{\ket{\xi_j}:j\}$. 
It remains for us to show that each $U(\Lambda)\ket*{\xi_j}\in H'_{S_n,\tau_S'},$ and that any $\ket*{\xi'}\in H'_{S_n,\tau_S'}$ can be expressed as a linear combination of the $U(\Lambda)\ket*{\xi_j}$.

Well, first note that by (\ref{TUrelation}) and a calculation similar to (\ref{invariantTS1})
\begin{equation}
\begin{split}\label{invariantTShat}
U(\Lambda)^{-1}\hat{T}'_S(x')U(\Lambda)&=U(\Lambda)^{-1}\hat{T}^{\prime\mu\nu}(x')\eta'_{\mu}(x')\eta'_{\nu}(x')U(\Lambda)\\
&=\Lambda\indices{^\mu_\rho}\Lambda\indices{^\nu_\sigma}\hat{T}^{\rho\sigma}(x)\Lambda\indices{_\mu^\alpha}\eta_{\alpha}(x)\Lambda\indices{_\nu^\beta}\eta_{\beta}(x)\\
&=\Lambda\indices{^\mu_\rho}\Lambda\indices{_\mu^\alpha} \Lambda\indices{^\nu_\sigma}\Lambda\indices{_\nu^\beta}\hat{T}^{\rho\sigma}(x)\eta_{\alpha}(x)\eta_{\beta}(x)\\
&=\delta^\alpha_\rho\delta^\beta_\sigma \hat{T}^{\rho\sigma}(x)\eta_{\alpha}(x)\eta_{\beta}(x)\\
&=\hat{T}^{\alpha\beta}(x)\eta_{\alpha}(x)\eta_{\beta}(x)\\
&=\hat{T}_S(x)
\end{split}
\end{equation}
From (\ref{invariantTShat}), we see that  $U(\Lambda)\hat{T}_S(x)=\hat{T}'_S(x')U(\Lambda)$, so
$$
\hat{T}_S'(x')U(\Lambda)\ket{\xi_j}=U(\Lambda)\hat{T}_S(x)\ket{\xi_j}=\tau_S(x)U(\Lambda)\ket{\xi_j}=\tau_S'(x')U(\Lambda)\ket{\xi_j}
$$
for all $x'\in S_n(y')\cap S$, where we have used the fact $\tau_S'(x')=\tau_S(x)$ since $T_S(x)$ is a scalar. Therefore, $U(\Lambda)\ket{\xi_j}\in H'_{S_n,\tau_S'}$. 

Now suppose that $\ket{\xi'}$ is a state for which $O'$ observes $T'_S(x')$ to be $\tau'_S(x')$ for all $x'\in S_n(y')\cap S$, i.e.  $\hat{T}_S'(x')\ket{\xi'}=\tau_S'(x')\ket{\xi'}$. From (\ref{invariantTShat}) we see that  $\hat{T}_S(x)U(\Lambda)^{-1}=U(\Lambda)^{-1}\hat{T}'_S(x')$, so
\begin{equation}\label{TSUxi}
\begin{split}
\hat{T}_S(x)U(\Lambda)^{-1}\ket{\xi'}&= U(\Lambda)^{-1} \hat{T}_S'(x')\ket{\xi'}\\
&=\tau_S'(x')U(\Lambda)^{-1}\ket{\xi'}\\
&=\tau_S(x)U(\Lambda)^{-1}\ket{\xi'}
\end{split}
\end{equation}
where on the last line we have used the fact that $T_S(x)$ is a scalar. Therefore, $U(\Lambda)^{-1}\ket{\xi'}$ can be expressed as a linear combination of the basis elements $\{\ket{\xi_j}:j\}$ of $H_{S_n,\tau_S}$, and hence  $\ket{\xi'}$  can be expressed as a linear combination of $\{U(\Lambda)\ket{\xi_j}:j\}$. 




Thus, we see that $\{\ket{\xi_j'}\myeq U(\Lambda)\ket{\xi_j}:j\}$ is a spanning orthonormal subset of $H'_{S_n,\tau_S'}$, so it must therefore be an orthonormal basis of $H'_{S_n,\tau_S'}$. From this it follows that $\pi_n'=U(\Lambda)\pi_nU(\Lambda)^{-1}$. Therefore, 
\begin{equation}\label{kentlorentz2}
\begin{split}
\frac{\ev{\pi_n'\hat{T}^{\mu\nu}(y')}{\Psi_n'}}{\ev{\pi_n'}{\Psi_n'}}&=\frac{\ev{U(\Lambda)^{-1}U(\Lambda)\pi_nU(\Lambda)^{-1}\hat{T}^{\mu\nu}(y')U(\Lambda)}{\Psi_n}}{\ev{U(\Lambda)^{-1}U(\Lambda)\pi_n U(\Lambda)^{-1}U(\Lambda)}{\Psi_n}}\\
&=\frac{\ev{\pi_nU(\Lambda)^{-1}\hat{T}^{\mu\nu}(y')U(\Lambda)}{\Psi_n}}{\ev{\pi_n}{\Psi_n}}\\
&=\frac{\ev{\pi_n\Lambda\indices{^\mu_\rho}\Lambda{^\nu_\sigma}\hat{T}^{\rho\sigma}(y)}{\Psi_n}}{\ev{\pi_n }{\Psi_n}}
\end{split}
\end{equation}
where on the last line we have used (\ref{TUrelation}). Thus, equation (\ref{kentlorentz}) holds, and hence Kent's model is Lorentz invariant.

Note that in this proof of Lorentz invariance, we don't need to take the limit of $S_n$ as $n\rightarrow\infty$. That is, we could remove the $\lim_{n\rightarrow\infty}$ from equation (\ref{kentconsistency0}) and consider a particular $S_n$, and the corresponding $\ev*{T^{\mu\nu}(y)}_{\tau_S}$ would still be a rank-two tensor. Butterfield tells us that Kent's theory is  Lorentz invariant because his algorithm respects the light cone structure of $y$.\footnote{See \cite[30]{Butterfield}.} However, this statement could be slightly misleading because we don't need to consider the subset $S^1(y)\subset S$ of locations outside the light cone of $y$ in order to obtain a Lorentz invariant model. Doing the calculation on any Tomonaga-Schwinger spacelike hypersurface is sufficient to guarantee Lorentz invariance since any such spacelike hypersurface (e.g. $S_n$) is not altered at all by a Lorentz transformation -- only its coordinate description changes under a Lorentz transformation, and so the additional information of the scalar $\tau_S(x)$ on $S_n\cap S$ is Lorentz invariant. The only reason we need to consider the limit $\lim_{n\rightarrow \infty}S_n$ and hence $S^1(y)=\lim_{n\rightarrow \infty}S_n\cap S$ is that it is only in the limit that we use all the available information in $\tau_S(x)$ to calculate $\ev*{T^{\mu\nu}(y)}_{\tau_S}$. 


\section{Kent's Theory\label{Kentdecoherencesection} and Decoherence Theory\textsuperscript{*}}
In section \ref{probOutcomes} we saw that decoherence theory by itself does not offer a solution to the problem of outcomes. In this section, we consider how the additional information in Kent's theory is sufficient to address this problem. We will explain this by again considering  Kent's toy model discussed in section \ref{toysection}.

We thus suppose that a system is in a superposition $\psi_0^\text{sys} = c_1\psi_1^\text{sys}+c_2\psi_2^\text{sys}$ of two local states $\psi_1^\text{sys}$ and $\psi_2^\text{sys}$ where $\abs{c_1}^2+\abs{c_2}^2=1$, and that there is a photon coming in from the left that interacts with the system.\footnote{As in footnote \ref{wavefunctionfootnote} on page \pageref{wavefunctionfootnote}, we write $\psi_i^\text{sys}$ for the wave function that corresponds to the state $\ket*{\psi_i^\text{sys}(t)}$ with $\psi_i^\text{sys}(z, t)=\ip{z}{\psi_i^\text{sys}(t)}$.} We also suppose that  $y_1$ is a spacetime location with spatial location $z_1$ between the two spacelike hypersurfaces $S_0$ and $S$, and we consider a spacelike hypersurface $S_n=S_n(y_1)$  in a sequence of spacelike hypersurfaces that each contain $y_1$ as described on page \pageref{siydef}. 

In order to obtain a sufficiently simple description of the state $\ket{\Psi_n}\in H_{S_n}$ of $S_n$ for which we can use the formula (\ref{kentconsistency0}) to calculate Kent's beable, we will  
use a coarse-grained model so that $S_n$ is treated as a mesh of tiny cells\footnote{For a more detailed discussion of coarse-graining, see pp. \pageref{meshref} ff.} labeled by a sequence $(y_k)_{k=1}^\infty$. Thus, for each cell $y_k$ there will be a Hilbert space $H_k$ describing the state of that cell. We can think of each of these $y_k$ as systems that can become entangled with one another, but we will assume that $y_1$ is entangled with only a finite number $M$ of the other $y_k$ which we label as $y_{k_1}, \ldots, y_{k_M}$. What this means is that the most general expression for $\ket{\Psi_n}$ will be of the form
\begin{equation}\label{Sistate}
\ket{\Psi_n}=\Big(\sum_j\sum_{n\in\mathbb{N}^M} c_{j,n}\ket{\xi_{1,j}}\prod_{l=1}^{M}\ket{\xi_{k_{l},n_l}}\Big)\ket*{\Xi}.
\end{equation}
In this expression, $\{\ket{\xi_{1,j}}:j\}$ is an orthonormal basis of $H_1$, $\mathbb{N}^M$ means the set of all lists $(n_1,\ldots,n_M)$ with each $n_l\in\mathbb{N}$ where $\mathbb{N}$ is the set of positive integers greater than 0. The set of states $\{\ket{\xi_{k_{l},m}}:m\in\mathbb{N}\}$ form an orthonormal basis of $H_{k_{l}}$ for each $k_l$, and the $k_{l}$ are all distinct from each other and from $1$. Also, $M$ is chosen to be as small as possible so that any common factors of $\ket{\Psi_n}$ belong to $\ket*{\Xi}$ which is a sum of states of the form $\prod_l\ket{\xi_{\kappa_l}}$ where the states $\ket{\xi_{\kappa_l}}\in H_{\kappa_l}$ range over all the cells of $S_n$ not included in the set $\{k_{l}:l=1,\ldots,M\}.$ We also assume that each summand $c_{j,n}\ket{\xi_{1,j}}\prod_{l=1}^{M}\ket{\xi_{k_{l},n_l}}\ket*{\Xi}$ of $\ket*{\Psi_n}$ contains a state in each $H_k$ for every cell $k$ of $S_n$. In other words, if $k\neq 1$ and does not belong to the set $\{k_{l}:l=1,\ldots,M\}$, then $k$ belongs to the set $\{\kappa_l:\text{ there exists }\ket*{\xi_{\kappa_l}}\in H_{\kappa_l}\text{ appearing in }\ket*{\Xi}.\}$. Also, we will give $H_{S_n}$ an inner product so that if 
$$ \ket{\Psi_n'}=\Big(\sum_j\sum_{n\in\mathbb{N}^M} c'_{j,n}\ket{\xi_{1,j}}\prod_{l=1}^{M}\ket{\xi_{k_{l},n_l}}\Big)\ket*{\Xi'},$$ then
$$\ip{\Psi_n'}{\Psi_n}=\Big(\sum_j\sum_{n\in\mathbb{N}^M} \overline{c'_{j,n}}c_{j,n} \Big) \ip{\Xi'}{\Xi}$$
where $\ip{\Xi'}{\Xi}$ is defined in the obvious way. With this inner product, we will assume that $\ket{\Psi_n}$ is appropriately normalized so that $\ip{\Psi_n}{\Psi_n}=1$. If we also assume that  $\ip{\Xi}{\Xi}=1$, it will follow that $\sum_j\sum_{n\in\mathbb{N}^M}\abs{c_{j,n}}^2=1.$

Now in order to see how Kent's model addresses the problem of outcomes, we will need to consider several scenarios from his toy model. In each scenario, we will use the decomposition (\ref{Sistate}) of $\ket{\Psi_n}$ to calculate the reduced density matrix that encapsulates all the information needed to calculate expectation values at different spacetime locations. 

First, consider Figure \ref{kentdeco1} which depicts the spacelike hypersurface $S_n(y^a_1)$ for a spacetime location $y^a_1$ that occurs before the photon has interacted with the system.

\begin{figure}[ht!]
\captionsetup{justification=justified}
\centering
\tikzmath{
\a=5.3;  
\psione=0;
\psitwo=1.5;
\h=1;
\labelx=(\psione+\psitwo)/2;
\labely=-1.5;
\phstartx=-1.7;
\phstarty=\h;
\tbeg=\phstarty;
\ca=\phstartx-\tbeg;
\ttwo=\psitwo-\ca;
\cb=\ttwo+\ca;
\xend=\ttwo-\a+\cb;
\tone=\psione-\ca;
\cc=\tone+\ca;
\xendz=\tone-\a+\cc;
\tthree=\cc+\tone-\psitwo;
\circsize=0.08;
\md = (\a+\h)/2;
\tlen=0.75;
\textscale = 0.7;
\picscale = 0.89;
\nudge=0.1;
\tnudge=(\ttwo-\tone)/2+0.8;
\ttesta=2*\tone-\ttwo-\tnudge;
\ttestb=2*\tone-\ttwo+\tnudge;
\ttestc=\ttwo-\tnudge;
\ttestd=\ttwo+\tnudge;
\sonea=\a+\psione-\ttesta;
\sadd=0.5;
\lrange = -(\psione-\a+\ttesta)+\sadd;
\rrange =\lrange; 
\timex=\rrange-1.5;
\e = 0.4;
\ttestx=2.4;
\at=\a-\ttestx;
\ct=\ttestx;
\lam = 0.87;
\e = 0.2;
\hae=(2*pow(\at,3)*\lam*(2+\lam)+\e*\e*(2*\e-sqrt(4*\e*\e+\at*\at*\lam*\lam))-8*\at*\e*(-2*\e+sqrt(4*\e*\e+\at*\at*\lam*\lam))-2*\at*\at*(2+\lam)*(-2*\e+sqrt(4*\e*\e+\at*\at*\lam*\lam)))/(4*\at*\lam*(2*\at+2*\e-sqrt(4*\e*\e+\at*\at*\lam*\lam)))-(\e*\e/4+\at*\at*(-1+\lam))/(\at*\lam);
\mmu=(\tone-\tbeg)/(\psione-\phstartx);
\nnu=(\psione*\tbeg-\phstartx*\tone)/(\psione-\phstartx);
} 
\tikzstyle{scorestars}=[star, star points=5, star point ratio=2.25, draw, inner sep=1pt]%
\tikzstyle{scoresquare}=[draw, rectangle, minimum size=1mm,inner sep=0pt,outer sep=0pt]%
\begin{tikzpicture}[scale=\picscale,
declare function={
	testxonep(\ps,\t)=\a+\ps-\t;
	testxonem(\ps,\t)=\ps-\a+\t; 
	xa(\m,\n)=(-\ct*\m+\e*\m+\m*\n-sqrt(\ct*\ct*\lam*\lam+\e*\e*\m*\m+2*\e*\lam*\lam*\n+\lam*\lam*\n*\n-2*\ct*\lam*\lam*(\e+\n)))/(\lam*\lam-\m*\m);
	xb(\m,\n)=(-\ct*\m+\e*\m+\m*\n+sqrt(\ct*\ct*\lam*\lam+\e*\e*\m*\m+2*\e*\lam*\lam*\n+\lam*\lam*\n*\n-2*\ct*\lam*\lam*(\e+\n)))/(\lam*\lam-\m*\m);
	bl(\x)=\ct+\at-\e/2-1/2*(sqrt(\lam*\lam*pow(\x+\hae+\at,2)+\e*\e)-\e+\lam*(\x+\hae+\at));
	br(\x)=\ct+\at-\e/2-1/2*(sqrt(\lam*\lam*pow(\x-\hae-\at,2)+\e*\e)-\e-\lam*(\x-\hae-\at));
	bc(\x)=\ct+sqrt(\lam*\lam*\x*\x+\e*\e)-\e;
},
 ] 
\definecolor{tempcolor}{RGB}{250,190,0}
\definecolor{darkgreen}{RGB}{40,190,40}

\draw[->,blue, thick] [domain=-\at/2:-\lrange, samples=150]   plot (\x, {bl(\x)})  ;
\draw[blue, thick] [domain=-\at/2:\at/2, samples=150] plot (\x, {bc(\x)})   ;
\draw[->,blue, thick] [domain=\at/2:\rrange, samples=150]   plot (\x, {br(\x)})   ;
 \node[scale=\textscale]  at (2.7,4.1) {$S_n(y^a_1)$}; 

\draw[<->] (-\lrange, \h) node[left, scale=\textscale] {$S_0$} -- (\rrange, \h) node[right, scale=\textscale] {$S_0$};
\draw[<->] (-\lrange, \a) node[left, scale=\textscale] {$S$} -- (\rrange, \a) node[right, scale=\textscale] {$S$};
              
\draw[->, shorten <= 5pt,  shorten >= 1pt] (\psione,\h) node[below, scale=\textscale]{$\psi_1^{\text{sys}}$} node[above left, scale=\textscale]{$z_1$}-- (\psione,\a) ;
\draw[->,  shorten <= 5pt,  shorten >= 1pt] (\psitwo,\h) node[below, scale=\textscale]{$\psi_2^{\text{sys}}$} node[above right, scale=\textscale]{$z_2$}-- (\psitwo,\a);

\draw[dashed, tempcolor,  thick](\phstartx,\tbeg) node[below left=-2,scale=\textscale]{}--(\psione,\tone) node[above, pos=0.3, rotate=45,scale=0.7,black] {} node[below, pos=0.3, rotate=45,scale=0.7,black] {};
\draw[dashed, tempcolor](\psione,\tone) node[below left=-2,scale=\textscale]{}--(\psitwo,\ttwo );
\draw[dashed, tempcolor](\psitwo,\ttwo)--(\xend,\a); 
\draw[dashed, tempcolor,  thick](\psione,\tone)--(\xendz,\a);



%\draw[dashed, darkgreen, ultra thick](\psione,\tone)--(\psitwo,\tthree);
%\draw [black,fill] (\psitwo,\tthree) circle [radius=\circsize] node [black,below=4,right,scale=\textscale] {$2t_1-t_2$}; 


%\draw [black,fill] (\psione,\tone) circle [radius=\circsize] node [black,left=4,scale=\textscale] {$t_1$}; 
%\draw [black,fill](\psitwo,\ttwo)circle [radius=\circsize] node [black,above right,scale=\textscale, align=left] {$t_2$}; 

%\draw [decorate, decoration = {calligraphic brace}] (\psitwo+\nudge,\ttwo) --  (\psitwo+\nudge,\tone+\nudge/4) node[midway,right, scale=\textscale]{$t_2-t_1$}; 
%\draw [decorate, decoration = {calligraphic brace}] (\psitwo+\nudge,\tone-\nudge/4) --  (\psitwo+\nudge,2*\tone-\ttwo) node[midway,right, scale=\textscale]{$t_2-t_1$}; 

\draw[->] (\timex,\md-\tlen/2) --  (\timex,\md+\tlen/2) node[midway,right, scale=\textscale]{time}; 
 
\draw[dotted](\psione,\ttestx)--({testxonep(\psione,\ttestx)},\a);
\draw[dotted](\psione,\ttestx)--({testxonem(\psione,\ttestx)},\a);
%\draw [black,fill](\psione,\ttestx) circle [radius=\circsize] node [black,below=6,left,scale=\textscale] {$y^a_1$}; 
\draw (\psione,\ttestx) node[ scoresquare, fill=gray]  {} node [black,below=6,right,scale=\textscale] {$y^a_1$};
\draw (\psitwo, {bc(\psitwo)}) node[ scoresquare, fill=gray]  {} node [black,below=6,right,scale=\textscale] {$y^a_2$};
\draw ({xa(\mmu,\nnu)}, {xa(\mmu,\nnu)*\mmu+\nnu}) node[ scoresquare, fill=white]  {} node [black,left=7,below=-4,scale=\textscale] {$y^a_3$};

\draw[magenta,->,ultra thick] ({testxonem(\psione,\ttestx)},\a)--(-\lrange,\a);
\draw[magenta,->,ultra thick] ({testxonep(\psione,\ttestx)},\a)--(\rrange,\a);
%\draw [black,fill] (\xendz,\a) circle [radius=\circsize] node [black,above,scale=\textscale] {$\gamma_1$}; 
\end{tikzpicture}% pic 1

\vspace*{2px}
\caption{Depiction of a superposition of two local states at $z_1$ and $z_2$ before the photon has interacted with them. The gray squares indicate cells in $S^1(y^a_1)$ whose states are among the summands in (\ref{Sistate}) rather than in $\Xi$. The white square indicates a cell in $S_n(y^a_1)$ whose state is a factor in $\Xi$.}
\label{kentdeco1}
\end{figure}

The gray squares correspond to the summands that appear in (\ref{Sistate}). If the system were in the $\psi_1^\text{sys}$-state, then the state describing $S_n(y^a_1)$ would have a factor $\ket{\psi_1^\text{sys}}\in H_1$ indicating that there is a 
non-zero mass at the $y^a_1$-cell, and there would also be a factor $\ket{0_2}\in H_2$ which we use to indicate that there is zero mass/energy at $y^a_2$. 
There is also an incoming photon at the $y^a_3$-cell, and so we use $\ket{\gamma_3}$ to indicate that there is a photon there.
 Thus, if  the system  were in the $\psi_1^\text{sys}$-state, we would write the state of $S_n(y^a_1)$ 
 as $\ket{\Psi_n}=\ket{\psi_1^\text{sys}}\ket{0_2}\ket{\gamma_3}\ket*{\Xi'}$, where $\ket*{\Xi'}$ describes the states of all the other cells of $S_n(y^a_1)$. In this very simple scenario, $\ket*{\Xi'}=\prod_{k\neq 1,2,3}\ket{0_k}$ indicating that there is zero mass/energy at all the other $y_k$.

 On the other hand, if the system were in the state $\psi_2^\text{sys}$, then the state describing $S_n(y^a_1)$ would have a factor $\ket{\psi_2^\text{sys}}\in H_2$ 
 indicating that there is a non-zero mass at the $y^a_2$-cell, and there would also be a factor $\ket{0_1}\in H_1$ which we use to indicate that there is zero mass at $y^a_1$,
  and again the $y^a_3$-cell would be in the $\ket{\gamma_3}$-state, and every other cell would be described by  $\ket*{\Xi'}$  just as if the system had been in the $\psi_1^\text{sys}$-state. Therefore, when the system is in the state $\psi_2^\text{sys}$, we would write the state of $S_n(y^a_1)$ as $\ket{\Psi_n}=\ket{0_1}\ket{\psi_2^\text{sys}}\ket{\gamma_3}\ket*{\Xi'}$. 
 
 Now since the system is actually in a supposition $\psi_0^\text{sys} = c_1\psi_1^\text{sys}+c_2\psi_2^\text{sys}$, the state of $S_n(y^a_1)$ will be 
 \begin{equation*}
 \ket{\Psi_n}=\big(c_1\ket{\psi_1^\text{sys}}\ket{0_2}+c_2\ket{0_1}\ket{\psi_2^\text{sys}}\big)\ket{\gamma_3}\ket*{\Xi'}=\big(c_1\ket{\psi_1^\text{sys}}\ket{0_2}+c_2\ket{0_1}\ket{\psi_2^\text{sys}}\big)\ket*{\Xi}
 \end{equation*}
where we have absorbed the $\ket{\gamma_3}$-state into $\ket*{\Xi}$ (i.e. $\ket*{\Xi}= \ket{\gamma_3}\ket*{\Xi'}$).

Now as it stands, the state $\ket{\Psi_n}$ describing $S_n(y^a_1)$ has a definite mass-energy density $\tau_S(x)$ for $x\in S_n(y^a_1)\cap S$, namely $0$. Thus, if $\pi_n$ is the operator featuring in (\ref{kentconsistency0}) that corresponds to this definite mass-energy density, then $\pi_n\ket{\Psi_n}=\ket{\Psi_n}$. Therefore, equation (\ref{kentconsistency0}) for Kent's beables tells us that
\begin{equation}\label{kentbeablenoinfo}
\ev*{T^{\mu\nu}(y^a_1)}_{\tau_S}=\ev*{\hat{T}^{\mu\nu}(y^a_1)}{\Psi_n},
\end{equation}
where we have also used the fact that $\ip*{\Psi_n}{\Psi_n}=1.$

Now as we saw in section \ref{decotheory}, if we are interested only in the expectation values of observables for a system $\mathcal{S}$ contained within a universe $\mathcal{U}=\mathcal{S}+\mathcal{E}$, then the information needed to do this can be encapsulated in the reduced density matrix for $\mathcal{S}$. Thus, if the universe is described by a state 
$\ket{\Psi}=\sum_j c_j \ket{\psi_j}_\mathcal{S}\ket{E_j}_\mathcal{E}$ with corresponding density matrix $\hat{\rho}=\dyad{\Psi}\in M(H_\mathcal{U})$, then the reduced density matrix $\hat{\rho}_\mathcal{S}\in M(H_\mathcal{S})$ is the Hermitian operator acting on the state space $H_\mathcal{S}$ with the property that 
\begin{equation}\tag{\ref{reducedev} revisited}
\ev*{\hat{O}_\mathcal{U}}_\rho=\Tr_\mathcal{S}(\hat{\rho}_\mathcal{S}\hat{O}_\mathcal{S})
\end{equation}
where $\hat{O}_\mathcal{S}$ is an observable on $H_\mathcal{S}$,  and $\hat{O}_\mathcal{U}$ is the corresponding observable on $H_\mathcal{U}$. Furthermore, we also have
\begin{equation}\label{reduced2}
\hat{\rho}_\mathcal{S}=\sum_j \abs{c_j}^2\dyad{\psi_j}+\sum_{j\neq k} c_j\overline{c_k}\ip{E_k}{E_j}\dyad{\psi_j}{\psi_k}.\protect\footnotemark
\end{equation}
\footnotetext{cf. (\ref{reduced})}We can thus apply this to the situation at hand by taking $S_n$ to be our universe $\mathcal{U}$ and $y^a_1$ to be the system $\mathcal{S}$, and $S_n\setminus \{y^a_1\}$ to be the environment $\mathcal{E}$. If we assume that $\ip{0_2}{\psi_2^\text{sys}}= 0$, then by (\ref{reduced2}), the corresponding reduced density matrix $\hat{\rho}_{y^a_1}$ takes the form of an improper mixture
\begin{equation}\label{kentred}
\hat{\rho}_{y^a_1}= \abs{c_1}^2\dyad{\psi_1^\text{sys}}+\abs{c_2}^2\dyad{0_1}.
\end{equation}
Therefore, by (\ref{kentbeablenoinfo}) and (\ref{kentred}), Kent's beable at $y^a_1$ will take the form 
\begin{equation}\label{kentbe}
\begin{split}
\ev*{T^{\mu\nu}(y^a_1)}_{\tau_S}&= \ev*{\hat{T}^{\mu\nu}(y^a_1)}{\Psi_n} \\
&=\Tr_{y^a_1}(\hat{\rho}_{y^a_1}\hat{T}^{\mu\nu}(y^a_1))\\
&=\abs{c_1}^2\ev*{\hat{T}^{\mu\nu}(y^a_1)}{\psi_1^\text{sys}}+\abs{c_2}^2\ev*{\hat{T}^{\mu\nu}(y^a_1)}{0_1}.
\end{split}
\end{equation}
But since $\hat{\rho}_{y^a_1}$ is an improper mixture, we cannot give (\ref{kentbe}) an ignorance interpretation -- the universe is still in the superposition state
$$\ket{\Psi_n}=c_1 \ket*{\psi_1^\text{sys}}\ket*{E_1}+c_2 \ket*{0_1}\ket*{E_2}$$ where $\ket{E_1}=\ket{0_2}\ket*{\Xi}$ and $\ket{E_2}=\ket{\psi_2^\text{sys}}\ket*{\Xi}$. 

In order to solve the problem of outcomes, we need to provide a satisfactory explanation (i.e. an explanation that is consistent with special relativity and the predictions of standard quantum theory)  of how the superposition state $\ket{\Psi_n}$ effectively goes to either the state $\ket*{\psi_1^\text{sys}}\ket*{E_1}$ or to the state $\ket*{0_1}\ket*{E_2}$.\footnote{cf. the initial discussion of the problem of outcomes on page \pageref{proboutcomes}. I have used the word `effectively' to qualify this sentence since it is not necessary to prove that there actually is such a transition from the state  $\ket{\Psi_n}$ to either the state $\ket*{\psi_1^\text{sys}}\ket*{E_1}$ or to the state $\ket*{0_1}\ket*{E_2}$. Rather, it is sufficient to show that if we consider any observable $\hat{O}_{\mathcal{S}}$ acting on $\mathcal{S}$, then the expectation value takes the form $\ev*{\hat{O}_{\mathcal{S}}}{\psi_1^\text{sys}}$ or $\ev*{\hat{O}_{\mathcal{S}}}{0_1}$ once there is an outcome, for then the system $\mathcal{S}$ has all the properties consistent with it being in the state $\ket*{\psi_1^\text{sys}}$ or the state $\ket*{0_1}$ respectively.} In terms of density operators, this means we need to show how the improper state (\ref{kentred}), transitions to a pure state of the form $\dyad{\psi_1^\text{sys}}$ or $\dyad{0_1}$.  

To this end, let us consider Kent's beables at the spacetime location $y^b_1$ depicted in figure \ref{kentdecoh2}. 
\begin{figure}[ht!]
\captionsetup{justification=justified}
\centering
\tikzmath{
\a=5.3;  
\psione=0;
\psitwo=1.5;
\h=1;
\labelx=(\psione+\psitwo)/2;
\labely=-1.5;
\phstartx=-1.7;
\phstarty=\h;
\tbeg=\phstarty;
\ca=\phstartx-\tbeg;
\ttwo=\psitwo-\ca;
\cb=\ttwo+\ca;
\xend=\ttwo-\a+\cb;
\tone=\psione-\ca;
\cc=\tone+\ca;
\xendz=\tone-\a+\cc;
\tthree=\cc+\tone-\psitwo;
\circsize=0.08;
\md = (\a+\h)/2;
\tlen=0.75;
\textscale = 0.7;
\picscale = 0.89;
\nudge=0.1;
\tnudge=(\ttwo-\tone)/2+0.8;
\ttesta=2*\tone-\ttwo-\tnudge;
\ttestb=2*\tone-\ttwo+\tnudge;
\ttestc=\ttwo-\tnudge;
\ttestd=\ttwo+\tnudge;
\sonea=\a+\psione-\ttesta;
\sadd=0.5;
\lrange = -(\psione-\a+\ttesta)+\sadd;
\rrange =\lrange; 
\timex=\rrange-1.5;
\e = 0.4;
\ttestx=3.0;
\at=\a-\ttestx;
\ct=\ttestx;
\lam = 0.87;
\e = 0.2;
\hae=(2*pow(\at,3)*\lam*(2+\lam)+\e*\e*(2*\e-sqrt(4*\e*\e+\at*\at*\lam*\lam))-8*\at*\e*(-2*\e+sqrt(4*\e*\e+\at*\at*\lam*\lam))-2*\at*\at*(2+\lam)*(-2*\e+sqrt(4*\e*\e+\at*\at*\lam*\lam)))/(4*\at*\lam*(2*\at+2*\e-sqrt(4*\e*\e+\at*\at*\lam*\lam)))-(\e*\e/4+\at*\at*(-1+\lam))/(\at*\lam);
\mmu=(\tone-\tbeg)/(\psione-\phstartx);
\nnu=(\psione*\tbeg-\phstartx*\tone)/(\psione-\phstartx);
\muf=(\a-\tone)/(\xendz-\psione);
\nuf=(\xendz*\tone-\psione*\a)/(\xendz-\psione);
} 
\tikzstyle{scorestars}=[star, star points=5, star point ratio=2.25, draw, inner sep=1pt]%
\tikzstyle{scoresquare}=[draw, rectangle, minimum size=1mm,inner sep=0pt,outer sep=0pt]%
\begin{tikzpicture}[scale=\picscale,
declare function={
	testxonep(\ps,\t)=\a+\ps-\t;
	testxonem(\ps,\t)=\ps-\a+\t; 
	xa(\m,\n)=(-\ct*\m+\e*\m+\m*\n-sqrt(\ct*\ct*\lam*\lam+\e*\e*\m*\m+2*\e*\lam*\lam*\n+\lam*\lam*\n*\n-2*\ct*\lam*\lam*(\e+\n)))/(\lam*\lam-\m*\m);
	xb(\m,\n)=(-\ct*\m+\e*\m+\m*\n+sqrt(\ct*\ct*\lam*\lam+\e*\e*\m*\m+2*\e*\lam*\lam*\n+\lam*\lam*\n*\n-2*\ct*\lam*\lam*(\e+\n)))/(\lam*\lam-\m*\m);
	bl(\x)=\ct+\at-\e/2-1/2*(sqrt(\lam*\lam*pow(\x+\hae+\at,2)+\e*\e)-\e+\lam*(\x+\hae+\at));
	br(\x)=\ct+\at-\e/2-1/2*(sqrt(\lam*\lam*pow(\x-\hae-\at,2)+\e*\e)-\e-\lam*(\x-\hae-\at));
	bc(\x)=\ct+sqrt(\lam*\lam*\x*\x+\e*\e)-\e;
},
 ] 
\definecolor{tempcolor}{RGB}{250,190,0}
\definecolor{darkgreen}{RGB}{40,190,40}

\draw[->,blue, thick] [domain=-\at/2:-\lrange, samples=150]   plot (\x, {bl(\x)})  ;
\draw[blue, thick] [domain=-\at/2:\at/2, samples=150] plot (\x, {bc(\x)})  node[right=20, above=10,black,scale=\textscale]{}  ;
\draw[->,blue, thick] [domain=\at/2:\rrange, samples=150]   plot (\x, {br(\x)})   ;

 \node[scale=\textscale]  at (2.7,4.6) {$S_n(y^b_1)$}; 
\draw[<->] (-\lrange, \h) node[left, scale=\textscale] {$S_0$} -- (\rrange, \h) node[right, scale=\textscale] {$S_0$};
\draw[<->] (-\lrange, \a) node[left, scale=\textscale] {$S$} -- (\rrange, \a) node[right, scale=\textscale] {$S$};
              
\draw[->, shorten <= 5pt,  shorten >= 1pt] (\psione,\h) node[below, scale=\textscale]{$\psi_1^{\text{sys}}$} node[above left, scale=\textscale]{$z_1$}-- (\psione,\a) ;
\draw[->,  shorten <= 5pt,  shorten >= 1pt] (\psitwo,\h) node[below, scale=\textscale]{$\psi_2^{\text{sys}}$} node[above right, scale=\textscale]{$z_2$}-- (\psitwo,\a);

\draw[dashed, tempcolor,  thick](\phstartx,\tbeg) node[below left=-2,scale=\textscale]{}--(\psione,\tone) node[above, pos=0.3, rotate=45,scale=0.7,black] {} node[below, pos=0.3, rotate=45,scale=0.7,black] {};
\draw[dashed, tempcolor,  thick](\psione,\tone) node[below left=-2,scale=\textscale]{}--(\psitwo,\ttwo );
\draw[dashed, tempcolor,  thick](\psitwo,\ttwo)--(\xend,\a); 
\draw[dashed, tempcolor, thick](\psione,\tone)--(\xendz,\a);





\draw[->] (\timex,\md-\tlen/2) --  (\timex,\md+\tlen/2) node[midway,right, scale=\textscale]{time}; 
 
\draw[dotted](\psione,\ttestx)--({testxonep(\psione,\ttestx)},\a);
\draw[dotted](\psione,\ttestx)--({testxonem(\psione,\ttestx)},\a);
%\draw [black,fill](\psione,\ttestx) circle [radius=\circsize] node [black,below=6,left,scale=\textscale] {$y^b_1$}; 
\draw (\psione,\ttestx) node[ scoresquare, fill=gray]  {} node [black,below=6,right,scale=\textscale] {$y^b_1$};
\draw (\psitwo, {bc(\psitwo)}) node[ scoresquare, fill=gray]  {} node [black,below=6,right,scale=\textscale] {$y^b_2$};
\draw ({xa(\mmu,\nnu)}, {xa(\mmu,\nnu)*\mmu+\nnu}) node[ scoresquare, fill=gray]  {} node [black,below=3,scale=\textscale] {$y^b_4$};
\draw ({xb(\muf,\nuf)}, {xb(\muf,\nuf)*\muf+\nuf}) node[ scoresquare, fill=gray]  {} node [black,below=3,scale=\textscale] {$y^b_3$};

\draw[magenta,->,ultra thick] ({testxonem(\psione,\ttestx)},\a)--(-\lrange,\a);
\draw[magenta,->,ultra thick] ({testxonep(\psione,\ttestx)},\a)--(\rrange,\a);
%\draw [black,fill] (\xendz,\a) circle [radius=\circsize] node [black,above,scale=\textscale] {$\gamma_1$}; 
\end{tikzpicture}% pic 1

\vspace*{2px}
\caption{Depiction of a superposition of two local states at $z_1$ and $z_2$ with $S_n(y^b_1)$ being after the photon has interacted without the photon intersecting $S_n(y^b_1)\cap S$. The gray squares indicate cells in $S^1(y^b_1)$ whose states are among the summands in (\ref{Sistate}).}
\label{kentdecoh2}
\end{figure}The state of $S_n(y^b_1)$ will then be
 \begin{equation*}
 \ket{\Psi_n}=\big(c_1\ket{\psi_1^\text{sys}}\ket{0_2}\ket{\gamma_3}\ket{0_4}+c_2\ket{0_1}\ket{\psi_2^\text{sys}}\ket{0_3}\ket{\gamma_4}\big)\ket*{\Xi}
 \end{equation*}
 where the notation is analogous to that in the previous example. Since no photon detections are registered on $S_n(y^b_1)\cap S$, we again have $\pi_n\ket{\Psi_n}=\ket{\Psi_n}$ so that the reduced density matrix $\hat{\rho}_{y_1^b}$ will again be given by  (\ref{kentred}) with $y^a_1$ replaced by $y^b_1$. However, in this case, Kent's beables $\ev*{T^{\mu\nu}(y^b_1)}_{\tau_S}$ will not be given by (\ref{kentbe}) because in the limit as $n\rightarrow\infty$, the photon \emph{will} be registered on $S_n(y^b_1)\cap S$. 
 
 To deal with the case when a photon is registered on $S_n(y^b_1)\cap S$, we consider a third example as depicted in figure \ref{kentdecoh3}.


\begin{figure}[ht!]
\captionsetup{justification=justified}
\centering
\tikzmath{
\a=5.3;  
\psione=0;
\psitwo=1.5;
\h=1;
\labelx=(\psione+\psitwo)/2;
\labely=-1.5;
\phstartx=-1.7;
\phstarty=\h;
\tbeg=\phstarty;
\ca=\phstartx-\tbeg;
\ttwo=\psitwo-\ca;
\cb=\ttwo+\ca;
\xend=\ttwo-\a+\cb;
\tone=\psione-\ca;
\cc=\tone+\ca;
\xendz=\tone-\a+\cc;
\tthree=\cc+\tone-\psitwo;
\circsize=0.08;
\md = (\a+\h)/2;
\tlen=0.75;
\textscale = 0.7;
\picscale = 0.89;
\nudge=0.1;
\tnudge=(\ttwo-\tone)/2+0.8;
\ttesta=2*\tone-\ttwo-\tnudge;
\ttestb=2*\tone-\ttwo+\tnudge;
\ttestc=\ttwo-\tnudge;
\ttestd=\ttwo+\tnudge;
\sonea=\a+\psione-\ttesta;
\sadd=0.5;
\lrange = -(\psione-\a+\ttesta)+\sadd;
\rrange =\lrange; 
\timex=\rrange-1.5;
\e = 0.4;
\ttestx=4;
\at=\a-\ttestx;
\ct=\ttestx;
\lam = 0.87;
\e = 0.2;
\hae=(2*pow(\at,3)*\lam*(2+\lam)+\e*\e*(2*\e-sqrt(4*\e*\e+\at*\at*\lam*\lam))-8*\at*\e*(-2*\e+sqrt(4*\e*\e+\at*\at*\lam*\lam))-2*\at*\at*(2+\lam)*(-2*\e+sqrt(4*\e*\e+\at*\at*\lam*\lam)))/(4*\at*\lam*(2*\at+2*\e-sqrt(4*\e*\e+\at*\at*\lam*\lam)))-(\e*\e/4+\at*\at*(-1+\lam))/(\at*\lam);
\mmu=(\tone-\tbeg)/(\psione-\phstartx);
\nnu=(\psione*\tbeg-\phstartx*\tone)/(\psione-\phstartx);
\muf=(\a-\ttwo)/(\xend-\psitwo);
\nuf=(\xend*\ttwo-\psitwo*\a)/(\xend-\psitwo);
} 
\tikzstyle{scorestars}=[star, star points=5, star point ratio=2.25, draw, inner sep=1pt]%
\tikzstyle{scoresquare}=[draw, rectangle, minimum size=1mm,inner sep=0pt,outer sep=0pt]%
\begin{tikzpicture}[scale=\picscale,
declare function={
	testxonep(\ps,\t)=\a+\ps-\t;
	testxonem(\ps,\t)=\ps-\a+\t; 
	xa(\m,\n)=(-\ct*\m+\e*\m+\m*\n-sqrt(\ct*\ct*\lam*\lam+\e*\e*\m*\m+2*\e*\lam*\lam*\n+\lam*\lam*\n*\n-2*\ct*\lam*\lam*(\e+\n)))/(\lam*\lam-\m*\m);
	xb(\m,\n)=(-\ct*\m+\e*\m+\m*\n+sqrt(\ct*\ct*\lam*\lam+\e*\e*\m*\m+2*\e*\lam*\lam*\n+\lam*\lam*\n*\n-2*\ct*\lam*\lam*(\e+\n)))/(\lam*\lam-\m*\m);
	bl(\x)=\ct+\at-\e/2-1/2*(sqrt(\lam*\lam*pow(\x+\hae+\at,2)+\e*\e)-\e+\lam*(\x+\hae+\at));
	br(\x)=\ct+\at-\e/2-1/2*(sqrt(\lam*\lam*pow(\x-\hae-\at,2)+\e*\e)-\e-\lam*(\x-\hae-\at));
	bc(\x)=\ct+sqrt(\lam*\lam*\x*\x+\e*\e)-\e;
},
 ] 
\definecolor{tempcolor}{RGB}{250,190,0}
\definecolor{darkgreen}{RGB}{40,190,40}

\draw[->,blue, thick] [domain=-\at/2:-\lrange, samples=150]   plot (\x, {bl(\x)})  ;
\draw[blue, thick] [domain=-\at/2:\at/2, samples=150] plot (\x, {bc(\x)})  node[right=20, above=10,black,scale=\textscale]{}  ;
\draw[->,blue, thick] [domain=\at/2:\rrange, samples=150]   plot (\x, {br(\x)})   ;

 \node[scale=\textscale]  at (1,4.1) {$S_n(y^c_1)$}; 
\draw[<->] (-\lrange, \h) node[left, scale=\textscale] {$S_0$} -- (\rrange, \h) node[right, scale=\textscale] {$S_0$};
\draw[<->] (-\lrange, \a) node[left, scale=\textscale] {$S$} -- (\rrange, \a) node[right, scale=\textscale] {$S$};
              
\draw[->, shorten <= 5pt,  shorten >= 1pt] (\psione,\h) node[below, scale=\textscale]{$\psi_1^{\text{sys}}$} node[above left, scale=\textscale]{$z_1$}-- (\psione,\a) ;
\draw[->,  shorten <= 5pt,  shorten >= 1pt] (\psitwo,\h) node[below, scale=\textscale]{$\psi_2^{\text{sys}}$} node[above right, scale=\textscale]{$z_2$}-- (\psitwo,\a);

\draw[dashed, tempcolor,  thick](\phstartx,\tbeg) node[below left=-2,scale=\textscale]{}--(\psione,\tone) node[above, pos=0.3, rotate=45,scale=0.7,black] {} node[below, pos=0.3, rotate=45,scale=0.7,black] {};
\draw[dashed, tempcolor,  thick](\psione,\tone) node[below left=-2,scale=\textscale]{}--(\psitwo,\ttwo );
\draw[dashed, tempcolor,  thick](\psitwo,\ttwo)--(\xend,\a); 
\draw[dashed, tempcolor,  thick](\psione,\tone)--(\xendz,\a);

\draw[magenta,->,ultra thick] ({testxonem(\psione,\ttestx)},\a)--(-\lrange,\a);
\draw[magenta,->,ultra thick] ({testxonep(\psione,\ttestx)},\a)--(\rrange,\a);



\draw[->] (\timex,\md-\tlen/2) --  (\timex,\md+\tlen/2) node[midway,right, scale=\textscale]{time}; 
 
\draw[dotted](\psione,\ttestx)--({testxonep(\psione,\ttestx)},\a);
\draw[dotted](\psione,\ttestx)--({testxonem(\psione,\ttestx)},\a);
%\draw [black,fill](\psione,\ttestx) circle [radius=\circsize] node [black,below=6,left,scale=\textscale] {$y^c_1$}; 
\draw (\psione,\ttestx) node[ scoresquare, fill=gray]  {} node [black,below=6,right,scale=\textscale] {$y^c_1$};
\draw (\psitwo, {bc(\psitwo)}) node[ scoresquare, fill=gray]  {} node [black,below=6,right,scale=\textscale] {$y^c_2$};
\draw ({xb(\muf,\nuf)}, {xb(\muf,\nuf)*\muf+\nuf}) node[ scoresquare, fill=gray]  {} node [black,right=7, below=-4,scale=\textscale] {$y^c_4$};
\draw (\xendz,\a) node[ scoresquare, fill=gray]  {} node [black,below=3,scale=\textscale] {$y^c_3$};


%\draw [black,fill] (\xendz,\a) circle [radius=\circsize] node [black,above,scale=\textscale] {$\gamma_1$}; 
\end{tikzpicture}% pic 1

\vspace*{2px}
\caption{Depiction of a superposition of two local states at $z_1$ and $z_2$ with $y^c_1$ sufficiently late that the photon intersects $S_n(y^c_1)\cap S$. The gray squares indicate cells in $S^1(y^c_1)$ whose states are among the summands in (\ref{Sistate})}
\label{kentdecoh3}
\end{figure}

In this case, the state of $S_n(y^c_1)$ will be
 \begin{equation*}
 \ket{\Psi_n}=\big(c_1\ket{\psi_1^\text{sys}}\ket{0_2}\ket{\gamma_3}\ket{0_4}+c_2\ket{0_1}\ket{\psi_2^\text{sys}}\ket{0_3}\ket{\gamma_4}\big)\ket*{\Xi}
 \end{equation*}
 but now we have to consider the fact that the photon intersects $S_n(y^c_1)\cap S$. There are two possible (notional) measurement outcomes that can occur on $S_n(y^c_1)\cap S$: either $T_S=\tau_{S,1}$ where $\tau_{S,1}(y^c_3)\neq 0$, or $T_S=\tau_{S,2}$ where $\tau_{S,2}(y^c_3)=0.$ 
 
 The case  $T_S=\tau_{S,1}$ indicates that there is a photon detection at $y^c_3$ so that the local state at the $y^c_3$-cell is $\ket{\gamma_3}$. Therefore, if we write $\pi_{n,1}$ for the operator $\pi_n$, we have 
 $$\pi_{n,1}\ket{\Psi_n}=c_1\ket{\psi_1^\text{sys}}\ket{0_2}\ket{\gamma_3}\ket{0_4}\ket*{\Xi}.$$
 Therefore, 
 $\ev*{\pi_{n,1}\hat{T}^{\mu\nu}(y^c_1)}{\Psi_n}=\abs{c_1}^2\ev*{\hat{T}^{\mu\nu}(y^c_1)}{\psi_1^\text{sys}}$ and  $\ev*{\pi_{n,1}}{\Psi_n}=\abs{c_1}^2$. Hence, by (\ref{kentconsistency0}), Kent's beables at $y^c_1$ will be 
 $$\ev*{T^{\mu\nu}(y^c_1)}_{\tau_{S,1}}=\ev*{\hat{T}^{\mu\nu}(y^c_1)}{\psi_1^\text{sys}}.$$ 
 From this, it follows that the reduced density matrix at $y^c_1$ will take the form of a pure state:
 \begin{equation}\label{purerho}
\hat{\rho}_{y^c_1}= \dyad{\psi_1^\text{sys}}.
\end{equation} 
 On the other hand, for the case when  $T_S=\tau_{S,2}$, this indicates that there is no photon detection at $y^c_3$, so that the local state at the $y^c_3$-cell will be $\ket{0_3}$. So if we now  write $\pi_{n,2}$ for the operator $\pi_n$, we have 
 $$\pi_{n,2}\ket{\Psi_n}=c_2\ket{0_1}\ket{\psi_2^\text{sys}}\ket{0_3}\ket{\gamma_4}\ket*{\Xi}.$$
 Therefore, 
 $\ev*{\pi_{n,2}\hat{T}^{\mu\nu}(y^c_1)}{\Psi_n}=\abs{c_2}^2\ev*{\hat{T}^{\mu\nu}(y^c_1)}{0_1}$ and  $\ev*{\pi_{n,2}}{\Psi_n}=\abs{c_2}^2$,  
  and so by (\ref{kentconsistency0}), Kent's beables at $y^c_1$ will be 
 $$\ev*{T^{\mu\nu}(y^c_1)}_{\tau_{S,2}}=\ev*{\hat{T}^{\mu\nu}(y^c_1)}{0_1}.$$
 In this case, the reduced density matrix at $y^c_1$  will be
  \begin{equation}
\hat{\rho}_{y^c_1}= \dyad{0_1},
\end{equation} 
which is again a pure state.

In these examples we have therefore seen how the additional information concerning photon detection on $S_n(y_1)\cap S$ is able to determine whether the reduced density matrix at $y_1$ is a pure state or an improper mixture. Hence, Kent's theory offers an answer to d'Espagnat's problem of outcomes. As mentioned in section \ref{probOutcomes}, d'Espagnat noticed that with decoherence theory alone, we are not entitled to give an ignorance interpretation to the reduced density matrix for a system that is an improper mixture, and thus we are not able to conclude that an outcome has occurred. However, if the reduced density matrix of a system goes from being an improper mixture to a pure state of the form $\dyad{\psi}$ as it does when Kent's additional information is taken into account, then we can say that an outcome has occurred, namely the outcome of the system being in the state $\ket{\psi}.$  




\section{Butterfield's Analysis of Outcome Independence  in Kent's theory\label{butterfieldtoy}}
Let us now consider Kent's theory in the light of Shimony's notion of Outcome Independence (OI)  as defined in section \ref{OISec}. 

Butterfield\footnote{See \cite[30-32]{Butterfield}} tries to answer the question of whether OI holds in Kent's theory by considering an example that builds on Kent's toy model. Butterfield's example is designed to capture the salient features of a Bell experiment where two spatially separated observers always observe opposite outcomes of some measurement. Following Kent, Butterfield thus considers a universe in one spatial dimensional. In this universe, there are two entangled systems, a left-system and a right-system as depicted in figure \ref{ButterfieldOI}. 

\begin{figure}[ht!]
	\captionsetup{justification=justified}
	\centering
	\tikzmath{
	\a=5.3;  
	\psione=-1;
	\psitwo=-0.5;
	\psioneq=2;
	\psitwoq=2.5;
	\psioner=0;
	\psitwor=1;
	\e = 0.1;
	\h=-0.8;
	\phstartx=-3.9;
	\phstarty=-.8;
	\tbeg=\phstarty;
	\ca=\phstartx-\tbeg;
	\ttwo=\psitwo-\ca;
	\cb=\ttwo+\ca;
	\xend=\ttwo-\a+\cb;
	\tone=\psione-\ca;
	\cc=\tone+\ca;
	\xendz=\tone-\a+\cc;
	\tthree=\cc+\tone-\psitwo;
	\phstartxq=\psitwoq+2.9;
	\phstartyq=-.8;
	\tbegq=\phstartyq;
	\ttwoq=\tbegq-(\psitwoq-\phstartxq);
	\xendq=-\ttwoq+\a+\psitwoq;
	\toneq=\tbegq-(\psioneq-\phstartxq);
	\xendzq=-\toneq+\a+\psioneq;
	\circsize=0.05;
	\md = (\a+\h)/2;
	\tlen=0.75;
	\textscale = 0.8;
	\picscale = 0.95;
	\nudge=0.1;
	\tnudge=(\ttwo-\tone)/2;
	\ttesta=2*\tone-\ttwo-\tnudge;
	\ttestb=2*\tone-\ttwo+\tnudge;
	\ttestc=\ttwo-\tnudge;
	\ttestd=\ttwo+\tnudge;
	\sonea=\a+\psione-\ttesta;
	\sadd=0.5;
	\lrange = -(\psioner-\a+\ttesta)+\sadd;
	\rrange =\a+\psitwor-\ttesta+\sadd+0.5; 
	\timex=\rrange-0.7;
	} 
	\begin{tikzpicture}[scale=1.2,
	declare function={
		testxonep(\ps,\t)=\a+\ps-\t;
		testxonem(\ps,\t)=\ps-\a+\t; 
	},
	 ] 
	
	 \definecolor{tempcolor}{RGB}{250,190,0}
	 \definecolor{darkgreen}{RGB}{40,190,40}
	 \draw[<->] (-\lrange, \h) node[left, scale=\textscale] {$S_0$} -- (\rrange, \h) node[right, scale=\textscale] {$S_0$};
	 \draw[<->] (-\lrange, \a) node[left, scale=\textscale] {$S$} -- (\rrange, \a) node[right, scale=\textscale] {$S$};
	 
				   
	 \draw[->, shorten <= 5pt,  shorten >= 1pt] (\psione,\h) node[below, scale=\textscale]{$\psi_1^{\text{sys}}$} node[above left, scale=\textscale]{$Z=z_1$}-- (\psione,\a);
	 \draw[->,  shorten <= 5pt,  shorten >= 1pt] (\psitwo,\h) node[below, scale=\textscale]{$\psi_2^{\text{sys}}$} node[above right, scale=\textscale]{$Z=z_2$}-- (\psitwo,\a);
	 
	 \draw[->, shorten <= 5pt,  shorten >= 1pt] (\psioneq,\h) node[below, scale=\textscale]{$\psi_3^{\text{sys}}$} node[above left, scale=\textscale]{$Z=z_3$}-- (\psioneq,\a);
	 \draw[->,  shorten <= 5pt,  shorten >= 1pt] (\psitwoq,\h) node[below, scale=\textscale]{$\psi_4^{\text{sys}}$} node[above right, scale=\textscale]{$Z=z_4$}-- (\psitwoq,\a);
	 
	 %\draw[dashed, tempcolor, ultra thick](\phstartx,\tbeg) node[below left=-2,scale=\textscale]{}--(\psitwo,\ttwo );
	 \draw[dashed, tempcolor, ultra thick](\phstartx,\tbeg) node[below left=-2,scale=\textscale]{}--(\psione,\tone );
	 \draw[dashed, gray, ultra thick](\psitwo,\ttwo)--(\xend,\a);
	 \draw[dashed, gray, ultra thick](\psione,\tone)--(\psitwo,\ttwo) ;
	 \draw[dashed, tempcolor, ultra thick](\psione,\tone)--(\xendz,\a) ;
	 
	 \draw [red,fill] (\xendz,\a) circle [radius=\circsize] node [black,above,scale=\textscale] {$\gamma_1$}; 
	 \draw [black,fill] (\xend,\a) circle [radius=\circsize] node [black,above,scale=\textscale] {$\gamma_2$}; 
	 
	 \draw[dashed, tempcolor, ultra thick](\phstartxq,\tbegq) node[below left=-2,scale=\textscale]{}--(\psitwoq,\ttwoq );
	 \draw[dashed, tempcolor, ultra thick](\psitwoq,\ttwoq)--(\xendq,\a)  ;
	 \draw[dashed, gray, ultra thick](\psioneq,\toneq)--(\psitwoq,\ttwoq) ;
	 \draw[dashed, gray, ultra thick](\psioneq,\toneq)--(\xendzq,\a) ;
	 
	 \draw [black,fill] (\xendzq,\a) circle [radius=\circsize] node [black,above,scale=\textscale] {$\gamma_3$}; 
	 \draw [red,fill] (\xendq,\a) circle [radius=\circsize] node [black,above,scale=\textscale] {$\gamma_4$}; 
	 %\draw[dashed, darkgreen, ultra thick](\psione,\tone)--(\psitwo,\tthree);
	 %\draw [black,fill] (\psitwo,\tthree) circle [radius=\circsize] node [black,below=4,right,scale=\textscale] {$t=2t_1-t_2$}; 
	 
	 
	 \draw [red,fill] (\psione,\tone) circle [radius=\circsize]; 
	 \draw [black,fill](\psitwo,\ttwo)circle [radius=\circsize]; 
	 
	 \draw [black,fill] (\psioneq,\toneq) circle [radius=\circsize]; 
	 \draw [red,fill](\psitwoq,\ttwoq)circle [radius=\circsize]; 
	 
	 %\draw [decorate, decoration = {calligraphic brace}] (\psitwo+\nudge,\ttwo) --  (\psitwo+\nudge,\tone+\nudge/4) node[midway,right, scale=\textscale]{$t_2-t_1$}; 
	 %\draw [decorate, decoration = {calligraphic brace}] (\psitwo+\nudge,\tone-\nudge/4) --  (\psitwo+\nudge,2*\tone-\ttwo) node[midway,right, scale=\textscale]{$t_2-t_1$}; 

	\draw[->] (\timex,\md-\tlen/2) --  (\timex,\md+\tlen/2) node[midway,right, scale=\textscale]{time}; 
	 
	%\draw[dotted](\psione,\ttesta)--({testxonep(\psione,\ttesta)},\a);
	%\draw[dotted](\psione,\ttesta)--({testxonem(\psione,\ttesta)},\a);
	%\draw [black,fill](\psione,\ttesta) circle [radius=\circsize] node [black,below=5,right,scale=\textscale] {$y_a$}; 
	
	%\draw[magenta,->,ultra thick] ({testxonem(\psione,\ttesta)},\a)--(-\lrange,\a);
	%\draw[magenta,->,ultra thick] ({testxonep(\psione,\ttesta)},\a)--(\rrange,\a);
	
	\end{tikzpicture}% pic 1
	
	\vspace*{2px}
	\caption{Butterfield's thought experiment for analyzing OI}
	\label{ButterfieldOI}
	\end{figure}

Two locations $z_1$ and $z_2$ with $z_2>z_1$ belong to a left-system, and there are two possible outcomes for a measurement on the left-system: either all the mass/energy of the left-system is localized at $z_1$ or all the mass/energy of the left-system  is localized at $z_2$. These two possibilities are analogous to a spin up or a spin down measurement outcome in a Stern-Gerlach statement. Likewise, two locations $z_3$ and $z_4$ with $z_3<z_4$ and $z_3\gg z_2$ belong to a right-system, and again, there are two possible measurement outcomes: either all the mass/energy of the right-system is localized at $z_3$ or all the mass/energy of the right-system  is localized at $z_4$. 

The initial joint state of the two systems is 
$a \ket*{\psi_1}\ket*{\psi_4} +b \ket*{\psi_2}\ket*{\psi_3}.$
This means that the left-system will be found to be localized at $z_1$ with probability $\abs{a}^2$, and at $z_2$ with probability $\abs{b}^2$, and if the left-system is localized at $z_1$, the  right system must be localized at $z_4$, whereas if the left-system is localized at $z_2$, then the right system must be localized at $z_3$.  

Now Butterfield supposes that there are two photons, one coming in from the left that interacts with the left system, and one coming in from the right that interacts with the right system. As in Kent's toy model, there is a late time spacelike hypersurface $S$, on which the photons are ``measured''. Since the joint state of the two systems  is in superposition, there will be two possible measurement outcomes for the two photons that arrive at $S$. Either the left-photon is measured at $\gamma_1$ and the right-photon is measured at $\gamma_4$, or the left-photon is measured at $\gamma_2$ and the right photon is measured at $\gamma_3$. Thus, if we suppose that the (notional) measurement for $T_S(x)$ yields an energy distribution $\tau_S(x)$ that is nonzero at $\gamma_1$ and $\gamma_4$, but is zero at $\gamma_2$ and $\gamma_3$, then we can say that the outcome of the measurement on the two systems is that the left system is localized at $z_1$ and the right system is localized at $z_4$. Moreover, the probability of this outcome is $1$ given that the (notional) measurement of $T_S(x)$ on $S$ is $\tau_S(x)$. In other words, this model is deterministic. But as we saw on page \pageref{OIdet}, if a model is deterministic, then OI must hold. This is the conclusion that Butterfield draws. 

Now if Kent's theory is to be consistent with special relativity, OI being satisfied might initially seem concerning. Indeed, we saw in section \ref{OISec} that OI implies the negation of PI, and the negation of PI is not consistent with special relativity.\footnote{At this point, one might make the following remark: the argument that a violation of PI constitutes a violation of relativity is based on the idea that if one knew the value of the hidden data, one could transmit messages at superluminal speed. But when the hidden data is grounded in data about the future hypersurface $S$, then the fact that if one knew this data, one could transmit messages superluminally should not be a cause for concern since all sorts of things become possible if you can know future contingents.
\vspace{1em}
\\
To this remark, there are two responses that one could make. Firstly, it would be somewhat misleading in the context of Kent's interpretation to say that a knowledge of data about $S$ implies a knowledge of future contingents since when calculating Kent's $T^{\mu\nu}(y)$-beables $\ev*{T^{\mu\nu}(y)}_{\tau_S}$, the only knowledge about the data of $S$ that is needed is for regions of $S$ outside the light cone of $y$, and whether this data is about something in the future or in the past is going to depend on what frame of reference one is in. Only when the data is within the light cone of $y$ will we be able to say categorically that knowledge of this data constitutes knowledge of future contingents. But Kent's beables are not dependent on such data.
\vspace{1em}
\\
Secondly, as mentioned on page \pageref{lambdaknowledge}, the main concern with a violation of PI is not simply the possibility of superluminal signally, but rather the possibility of the propatation of superluminal effects, of which superluminal signallying would be a very clear demonstration. But whether or not there is such a demonstration, a violation of PI seems to be saying that effects can be propagated superluminally, and this is unacceptable to adherents of relativity theory.} However, there is one salient feature of a Bell experiment that is not captured in Butterfield's scenario, namely, in a Bell experiment, one can perform different measurements.  PI and its negation only make sense when there are parameters that can be changed. Furthermore, in the proof that OI implies the negation of PI,\footnote{The proof  that determinism implies the negation of PI (on pages \pageref{bellinequality2} to \pageref{PIdeterminism}), also assumes that the choice of parameter is not determined by the hidden variable $\lambda$.} it is assumed that the choice of parameter is not determined by the hidden variable $\lambda$. If the choice of parameters was determined by $\lambda$, then for $\hat{a}\neq\hat{b}$, at least one of the probabilities $P_{\lambda,\bm{\hat{a}},\bm{\hat{c}}}(\uvbp{a},\uvbp{c}),$ $P_{\lambda,\bm{\hat{c}},\bm{\hat{b}}}(\uvbp{c},\uvbp{b})$ or $P_{\lambda,\bm{\hat{a}},\bm{\hat{b}}}(\uvbp{a},\uvbp{b})$ would not be well-defined.\footnote{If $\lambda$ \label{lambdadetermineprob} did determine the choice of measurements, either $P(\lambda,\bm{\hat{a}},\bm{\hat{c}})=0$, $P(\lambda,\bm{\hat{c}},\bm{\hat{b}})=0$, or $P(\lambda,\bm{\hat{a}},\bm{\hat{b}})=0$. So for example, if we thought of $P_{\lambda,\bm{\hat{a}},\bm{\hat{b}}}(X,Y)$ as a conditional probability $P(X,Y|\lambda,\bm{\hat{a}},\bm{\hat{b}})$, and the probability $P(\lambda,\bm{\hat{a}},\bm{\hat{b}})=0$, then according to the definition of conditional probability,  $P(X,Y|\lambda,\bm{\hat{a}},\bm{\hat{b}})=\frac{0}{0}.$} Even though Butterfield is only considering OI in his thought experiment, a proper analysis of OI shouldn't be undertaken without considering an experiment with parameters (e.g. knob settings that correspond to measurement axes of a Stern-Gerlach experiment). This is because the determination of whether OI holds will depend on what one counts as being the hidden variable data of a system, and we need the hidden variable of a system to be such that the notion of PI is well-defined. Otherwise, one's verdict on OI will be irrelevant to Shimony's analysis of why Bell's inequality fails to hold. 

In the next section I will discuss Leegwater's criteria for what one should count as being the hidden variable data of a system, and in the following section \ref{KentconsistentQT}, I will consider a toy model that takes parameter settings into account.


\section{Hidden variables and the Colbeck-Renner theorem\label{colbeckrennerthm}}
In this section we will consider hidden variables in the light of the Colbeck-Renner theorem. Roughly speaking, the Colbeck-Renner theorem says there are no hidden variables theories that are of interest to quantum physicists -- either the hidden variables will be redundant or the hidden variable theory will be incompatible with standard quantum physics. It might therefore seem that the Colbeck-Renner theorem presents a serious challenge to Kent's theory. However, the challenge really hinges on what criteria the data of a theory must satisfy for it to be classified as hidden variable data. A careful analysis of the kind of data Kent's theory relies on reveals that the Colbeck-Renner theoerm is not as serious a challenge to Kent's theory as it first might seem. 

First we need to consider the criteria a set of data should satisfy if it is to be classified as hidden variable data of a physical system $\mathcal{S}$. The criteria we discuss below can be found either explicitly or implicitly in Leegwater's proof of the Colbeck-Renner theorem.\footnote{See \cite{LeegwaterGijs2016Aitf}} The first criterion we will discuss is the following:
\begin{enumerate}
	\item all the information of $\lambda$ is about $\mathcal{S}$ so that a change in $\lambda$ corresponds to a change in the system $\mathcal{S}$.\label{hidden1}
\end{enumerate} 
Notice that Butterfield does not accept this criterion. Butterfield assumes that the hidden variables in Kent's theory consist in the outcome $\tau_S(x)$ of $T_S(x)$ over the whole of $S$. However, this assumption is going to cause difficulties in the context of Shimony's analysis. This is because in Kent's theory, the information in $\tau_S(x)$ over the whole of $S$ clearly would determine which parameters are chosen in a Bell experiment, for this information would determine where a silver atom coming out of a Stern-Gerlach apparatus would be detected on a detection screen (as depicted in figure \ref{rotate}), and from the position of this detection, one could determine the orientation of the magnetic field used in the Stern-Gerlach experiment. So if we stipulated that $\lambda=\tau_S$ is the hidden variable data of every system in Kent's theory, then Kent's theory wouldn't satisfy the preconditions necessary for defining OI and PI. This would make Kent's theory radically different from the pilot wave interpretation where one can define OI and PI because the hidden variables in the pilot wave interpretation, being the positions and momenta of the particles, are independent of the measurement choices. An unfortunate consequence of not being able to define OI and PI is that we wouldn't be able to evaluate Kent's theory in the light of Shimony's analysis of why Bell's inequality fails to hold. 

But it is not obvious that we should stipulate that $\lambda=\tau_S$ is the hidden variable data of every system in Kent's theory. Just because we give $\tau_S$ a single label $\lambda$, it doesn't follow that $\tau_S$ is a single piece of information. There is typically going to be a huge amount of information in $\tau_S$, and so for a given system $\mathcal{S}$, we should carefully discern  what collection of information in $\tau_S$ should be stipulated as being the hidden variable data $\lambda$ of $\mathcal{S}$, hence criterion \ref{hidden1}. Criterion \ref{hidden1} shouldn't be that difficult to satisfy, for if $\lambda$ contained information that could change without this corresponding to any change in $\mathcal{S}$, then we should be able to discard this irrelevant information when considering $\mathcal{S}$ and redefine what $\lambda$ should be for the system. 

In the pilot wave interpretation, the positions and momenta of the particles that constitute a system would fulfil criterion \ref{hidden1}. On the other hand, all the information in $\tau_S$ of Kent's theory would not fulfil this criterion unless, of course, $\mathcal{S}$ was the whole universe. So in order for Kent's theory to satisfy criterion \ref{hidden1}, we just need to discard the information of $\tau_S$ that is irrelevant to the system $\mathcal{S}$ that is being considered in order to obtain the appropriate hidden variable data $\lambda$. 

Note, however, that we don't insist that a difference in $\mathcal{S}$ entails a difference in $\lambda$. This is because a hidden-variables theory is envisaged as augmenting standard quantum theory. So in the case when $\mathcal{S}$ is not entangled with any other system, there will be a quantum state describing $\mathcal{S}$, and this quantum state can be other than it is (indicating that $\mathcal{S}$ can be in a different physical state)  whilst the hidden variable remains the same. We thus impose a second criterion for a hidden-variables theory:
\begin{enumerate}
	\setcounter{enumi}{1}
	\item \label{hidden3} If $\lambda$ is the hidden variable of a system $\mathcal{S}$ and if $\ket{\phi}$ is the quantum state of $\mathcal{S}$ or of some composite system $\mathcal{U}$ that contains $\mathcal{S}$ as a subsystem, then it is possible for there to be a different quantum state $\ket{\phi'}$ of $\mathcal{S}$ (or $\mathcal{U}$) while the hidden variable $\lambda$ remains unchanged, and it is possible for there to be a different hidden variable $\lambda$ while $\ket{\phi}$ remains unchanged.
\end{enumerate} 
This criterion is satisfied in the pilot wave interpretation, since the quantum state is the pilot wave itself. The pilot wave could be other than it is without any of the positions and momenta of the particles changing, but changing the pilot wave would result in a physical change of the system since the pilot wave governs how  the positions and the momenta of the particles subsequently evolve over time. We will discuss the failure of criterion \ref{hidden3} for Kent's theory at the end of this section.

Another criterion implicit in Leegwater's proof for a set of data $\lambda$ to constitute the hidden variable data of a system $\mathcal{S}$ is the following: 
\begin{enumerate}
	\setcounter{enumi}{2}
\item \label{hidden2} it should be possible to change the measurement parameters when measuring $\mathcal{S}$ without this determining what $\lambda$ should be. 
\end{enumerate} 
It is worth noting that  we used criterion \ref{hidden2} when showing that OI implies the negation of PI. If this criterion doesn't hold, we cannot even begin to consider whether PI holds in a given theory. This is because the criterion for PI depends on the probability $P_{\lambda,\bm{\hat{a}},\bm{\hat{b}}}(\uvbpm{a},\uvbpm{b})$ being well-defined, but if the choice of $\bm{\hat{a}}$ or $\bm{\hat{b}}$ determines what $\lambda$ should be, then one wouldn't be able to define $P_{\lambda',\bm{\hat{a}},\bm{\hat{b}}}(\uvbpm{a},\uvbpm{b})$ for $\lambda'\neq\lambda$.\footnote{Cf. footnote \ref{lambdadetermineprob} on page \pageref{lambdadetermineprob}.} But even without any consideration of PI, a rejection of criterion \ref{hidden2} would still seem undesirable, for it would be rather strange if changing the choice of measurement parameters necessarily changed the hidden variable $\lambda$ of the system $\mathcal{S}$, and hence by criterion \ref{hidden1} the system $\mathcal{S}$ itself.\footnote{Of course, in the quantum world, strangeness is not necessarily an argument against something being true.} Moreover, if free will is real and the free choice of the measurement parameter was made before it was determined which system was going to be measured, then it wouldn't even be clear which $\lambda$ of which system we were talking about.\footnote{If the reality of free will is denied, then there wouldn't necessarily be this problem of associating the choice of measurement with the $\lambda$ of the system, because the physical state of the universe could determine which choice of measurement is going to be made as well as which system is going to be measured.}  

In the pilot wave interpretation, the positions and momenta of the particles that constitute a system would fulfil criterion \ref{hidden2}. In the case of Kent's interpretation, we would have to choose carefully the subset of $\tau_S$ for the $\lambda$ of the system being measured if criterion \ref{hidden2} is to hold. But it seems that this should be possible, for one can imagine just changing the part of $\tau_S$ that corresponded to where the measurement parameter dial/knob was without this changing Kent's stress-momentum tensor for the system being measured immediately before it interacts with the measurement device.   

Closely related to criterion \ref{hidden2} is the following criterion: 
\begin{enumerate}
	\setcounter{enumi}{3}
	\item \label{hidden5} There is a range of possible values $\lambda$ for a system $\mathcal{S}$, and for each possible value, we can assign a probability $p_\lambda$ that $\lambda$ obtains, and we can do so in such a way that $p_\lambda$ is independent of any choice of measurement that is to be made on $\mathcal{S}$.
\end{enumerate} 
Butterfield refers to criterion \ref{hidden5} as the `no-conspiracy' assumption, and it is one of the criteria assumed in the Colbeck-Renner theorem. However, Butterfield adds that `no-conspiracy' is a rather unfair label for this criterion since there wouldn't necessarily be anything conspiratorial if this assumption was violated.\footnote{See \cite[34]{Butterfield}.} But in saying this, Butterfield is envisaging $\lambda$ to be the whole of $\tau_S$, and this is in violation of criterion \ref{hidden1}. Since we can expect the whole of $\tau_S$ (together with the universal state $\ket*{\Psi_0}$) to determine Kent's stress-momentum tensor for the measurement parameter dial/knob, then we wouldn't expect criterion \ref{hidden5} to hold. But on the other hand, if we adopt criterion \ref{hidden1} and assume that only information relevant to $\mathcal{S}$ is included in the $\lambda$ for $\mathcal{S}$, then criterion \ref{hidden5} is more plausible. It ties in with common sense intuitions that scientists have free will and can make choices about which measurements they make, and that these choices are statistically independent of the states of the physical systems they are measuring. However, not everyone shares this intuition. If criterion \ref{hidden5} doesn't hold, then what a physical system does will depend on what property of this system one is about to measure. This kind of dependence is referred to as \textbf{superdeterminism}\index{superdeterminism}. Bell coined the term superdeterminism in a 1983 BBC interview, where he said:  
\begin{adjustwidth}{1cm}{}
	\begin{displayquote}
		There is a way to escape the inference of superluminal speeds and spooky action at a distance. But it involves absolute determinism in the universe, the complete absence of free will. Suppose the world is superdeterministic, with not just inanimate nature running on behind-the-scenes clockwork, but with our behavior, including our belief that we are free to choose to do one experiment rather than another, absolutely predetermined, including the ``decision'' by the experimenter to carry out one set of measurements rather than another, the difficulty disappears.
	\end{displayquote}
\end{adjustwidth}
However, Sabine Hossenfelder disputes Bell's argument that the only way to escape the inference of superluminal speeds and spooky action at a distance is to violate free will. Rather, all that is needed to escape this inference is a violation of the statistical independence of the choice of measurement parameters and the state of the system being measured, and this violation is what Hossenfelder takes to be superdeterminism.\footnote{ See \cite{superdeterminism}.   }


\begin{comment}

more reasonable. For example, in the case where the choice is made before it is determined which  system is to be measured, and the system  if wouldn't be clear $\lambda$ for which system would be affected
For if this probability $p_\lambda$ did depend on the choice that was to be made on the system, then we could  envisage a system $\mathcal{S}$ consisting of two entangled particles which Alice and Bob measure separately. If Bob's choice of measurement affected the probability distribution of $p_\lambda$, then it would seem that the effect of Bob's measurement could propagate to Alice faster than the speed of light.\footnote{Recall from the discussion on page \pageref{lambdaknowledge}, that in considering any possible violation of relativity,   it is irrelevant whether Alice knows the hidden variable $\lambda$ and hence whether Alice could work out which measurement Bob had made, because Alice's state of knowledge shouldn't have any effect on the speed at which Bob's effect is propagated. But if she did know $\lambda$, after enough measurements, she would be able to work out the distribution $p_\lambda$, and so if this distribution depended on Bob's choice, she would be able to say something about the choice he made.} Adherents of relativity theory would therefore not want to reject criterion \ref{hidden5}.


We should also state explicitly a fifth criterion for hidden variables as a condition for the possibility :
\begin{enumerate}
	\setcounter{enumi}{4}
	\item \label{hidden5} Suppose  $\mathcal{A}$ is any system that is entangled with $\mathcal{S}$, and that the quantum state of the composite system $\mathcal{S}+\mathcal{A}$  is $\ket{\phi}_{\mathcal{S}+\mathcal{A}}$. Then for any measurement $O_\mathcal{S}$ on $\mathcal{S}$ and $O_\mathcal{A}$ on $\mathcal{A}$, there is a probability for the joint measurement of $O_\mathcal{S}$ and $O_\mathcal{A}$ on $\mathcal{S}+\mathcal{A}$ that is a function of $\lambda$  despite $\lambda$ only referring to the system $\mathcal{S}$.	
\end{enumerate}
\end{comment}

In addition to these four criteria for the hidden variable data $\lambda$ of a system $\mathcal{S}$, it is also desirable for a hidden-variables theory to satisfy PI and empirical adequacy. We defined PI for a two-outcome measurement on page \pageref{PIdef}, but it is easy to generalize the definition of PI for measurements with more than two outcomes. In this more generalized setting, we suppose that $\mathcal{A}$ is any system that is entangled with the system $\mathcal{S}$, and that the quantum state of the composite system $\mathcal{S}+\mathcal{A}$  is $\ket{\phi}_{\mathcal{S}+\mathcal{A}}$. We also suppose that $O_{\mathcal{S}}$ and $O_{\mathcal{A}}$ represent measurement procedures on $\mathcal{S}$ and $\mathcal{A}$ respectively, and that $o_{\mathcal{S}}$ and $o_{\mathcal{S}}$ represent particular measurement outcomes respectively. For a hidden variable $\lambda$ for the system $\mathcal{S}$,\footnote{Although Leegwater, in his proof of the Colbeck-Renner theorem assumes that $\lambda$ is a hidden variable for the system $\mathcal{S}$ only, it looks like the proof would still go through if $\lambda$ was a hidden variable for the composite system $\mathcal{S}+\mathcal{A}$.} there will be a probability $P_\lambda^{\ket{\phi}_{\mathcal{S}+\mathcal{A}}}(O_\mathcal{S}=o_\mathcal{S}\, \& \, O_\mathcal{A}=o_\mathcal{A})$ (understandable in a frequentist sense) that the measurement outcomes of $O_{\mathcal{S}}$ and $O_{\mathcal{A}}$ will be $o_{\mathcal{S}}$  and $o_{\mathcal{A}}$ respectively. Given a second measurement procedure $O_{\mathcal{A}}'$ on $\mathcal{A}$, PI states that
\begin{equation}\tag{PI}
	\sum_{\substack{o_\mathcal{A}\text{ an }\\ \text{outcome }\\ 
	 \text{of }O_{\mathcal{A}}}}P_\lambda^{\ket{\phi}_{\mathcal{S}+\mathcal{A}}}(O_\mathcal{S}=o_\mathcal{S}\, \& \,O_\mathcal{A}=o_\mathcal{A}) = \sum_{\substack{o_\mathcal{A}'\text{ an}\\ \text{outcome }\\ 
	 \text{of }O_{\mathcal{A}}'}}P_\lambda^{\ket{\phi}_{\mathcal{S}+\mathcal{A}}}(O_\mathcal{S}=o_\mathcal{S}\, \& \,O'_\mathcal{A}=o'_\mathcal{A}). 
\end{equation}
If PI holds, then we can define the probability
\begin{equation}
	P^{\ket{\phi}_{\mathcal{S}+\mathcal{A}}}_{\lambda}(O_\mathcal{S}=o_\mathcal{S})=\sum_{\substack{o_\mathcal{A}\text{ an }\\ \text{outcome }\\ 
	\text{of }O_{\mathcal{A}}}}P_\lambda^{\ket{\phi}_{\mathcal{S}+\mathcal{A}}}(O_\mathcal{S}=o_\mathcal{S}\, \& \,O_\mathcal{A}=o_\mathcal{A})
\end{equation}
that is independent of the measurement procedure $O_\mathcal{A}$ on $\mathcal{A}$.\footnote{Cf. (\ref{PIone}).}


As for the definition of \textbf{empirical adequacy}\index{empirical adequacy!formal definition} (EA),  this states that
\begin{equation}\tag{EA}\label{adeq}
	\sum_{\lambda\in\Lambda}p_\lambda P_\lambda^{\ket{\phi}_{\mathcal{S}+\mathcal{A}}}(O_\mathcal{S}=o_\mathcal{S}\, \& \,O_\mathcal{A}=o_\mathcal{A})=P^{\ket{\phi}_{\mathcal{S}+\mathcal{A}}}(O_\mathcal{S}=o_\mathcal{S}\, \& \,O_\mathcal{A}=o_\mathcal{A})
\end{equation}
where $\Lambda$ is the set of all hidden variables so that $\sum_{\lambda\in\Lambda} p_\lambda = 1$, and where 
$$P^{\ket{\phi}_{\mathcal{S}+\mathcal{A}}}(O_\mathcal{S}=o_\mathcal{S}\, \& \,O_\mathcal{A}=o_\mathcal{A})$$
 is the standard probability calculated using the Born Rule with the eigenstates of the observables $\hat{O}_\mathcal{S}$ and $\hat{O}_\mathcal{A}$ and the quantum state $\ket{\phi}_{\mathcal{S}+\mathcal{A}}$. EA is essentially the same as equation (\ref{bohmconsistency}). It also has some similarities with (\ref{kentconsistency}), though the main difference is the range of the summation -- the index of the summands of (\ref{kentconsistency}) does not parametrize hidden variables that satisfy criteria \ref{hidden1} to \ref{hidden5} above.

Now, as I've been alluding to, criteria \ref{hidden1} to \ref{hidden5} together with the conditions of PI and EA are very restrictive. Leegwater proves a version of the Colbeck-Renner theorem\footnote{See \cite{LeegwaterGijs2016Aitf}.} which takes the following form: if one defines hidden variables according to criteria \ref{hidden1} to \ref{hidden5}, then in any hidden-variables theory for which PI and EA hold, the hidden variables are redundant. In other words, 
\begin{equation}\label{colbeckrenner}
P_\lambda^{\ket{\phi}_{\mathcal{S}+\mathcal{A}}}(O_\mathcal{S}=o_\mathcal{S}\, \& \,O_\mathcal{A}=o_\mathcal{A})=P^{\ket{\phi}_{\mathcal{S}+\mathcal{A}}}(O_\mathcal{S}=o_\mathcal{S}\, \& \,O_\mathcal{A}=o_\mathcal{A})
\end{equation}
for any measurement $O_\mathcal{S}$ on $\mathcal{S}$ and $O_\mathcal{A}$ on $\mathcal{A}$.\footnote{Strictly speaking, we should say that equation (\ref{colbeckrenner}) holds for almost all $\lambda$, but we need not concern ourselves here with the details of measure theory that would be needed to make sense of this qualification.} 

Thus, the Colbeck-Renner theorem means that we cannot hope to make Kent's theory into a hidden-variables theory that satisfies criterion \ref{hidden1} to \ref{hidden5} as well as  PI and EA, for the information in Kent's theory is clearly non-redundant.

But nevertheless, it still seems that we should be able to make some kind of sense of PI and EA in Kent's theory and that we should be able to evaluate Kent's theory on the basis of whether these notions of PI and EA are true in this context. To achieve this aim, one strategy would be to relax or drop one or more of the 
four criteria for a hidden variable. Since we still want to be able to make sense of PI and EA, we won't want to relax criteria \ref{hidden2} or \ref{hidden5}. That leaves the possibility of relaxing or droping criteria \ref{hidden1} or \ref{hidden3}. 

Now clearly, we wouldn't be able to drop criterion \ref{hidden1} entirely, for otherwise $\lambda$ would contain information that would determine the choice of measurement made on $\mathcal{S}$. But it doesn't seem problematic if we relax criterion \ref{hidden1} so that there can be information that can change without this corresponding to a change in the system $\mathcal{S}$ so long as this information doesn't determine the measurement choice that is to be made. 

As for criterion \ref{hidden3}, there doesn't seem to be any problem with dropping it entirely. On doing this, then instead of thinking of $\tau_S$ as an augmentation of standard quantum theory, we can think of $\tau_S$ as a rather elaborate way of stipulating the initial quantum states of experiments as well as the quantum states of measurement outcomes. In the next section, we will describe in some more detail how to extract the quantum state of a system from the universal quantum state $\ket*{\Psi_0}$ and $\tau_S$, but roughly speaking, if we consider an experimental setup including some measurement apparatus $\mathcal{A}$ and an object to be measured $\mathcal{S}$, then the information in  $\tau_S$ outside the light cone of the spacetime location of $\mathcal{S}+\mathcal{A}$ before they have interacted will determine the initial quantum states of $\mathcal{S}$ and $\mathcal{A}$ before they interact, and likewise, the information in  $\tau_S$ outside the light cone of the spacetime location of $\mathcal{S}+\mathcal{A}$ after they have interacted will determine the quantum outcome states of $\mathcal{S}$ and $\mathcal{A}$ after they have interacted. This will mean that when the information in $\tau_S$ that is about $\mathcal{S}$ changes, the quantum state of $\mathcal{S}$ extracted from $\tau_S$ and   $\ket*{\Psi_0}$ will also change, and hence criterion \ref{hidden3} will fail to hold. But the information of $\tau_S$ will be non-redundant, for without this information, we would only have the evolution of universal quantum state $\ket{\Psi_0}$ which would continually branch into many worlds. In the many worlds that resulted, the energy density on the spacelike hypersurface $S$ would not be in a definite state, but rather would be in a superposition of definite states. But with the information of $\tau_S$ one of these many states in this superposition is selected as actual. If we could then appropriately partition the information in $\tau_S(x)$ on the basis of whether it determined the quantum state of $\mathcal{S}$, or the quantum state of the apparatus $\mathcal{A}$, or the quantum state of the rest of the universe, we could then consider whether Kent's theory gave the same predictions as standard quantum theory. If it did, then PI and EA would hold in Kent's theory, since these both hold in standard quantum theory. And since Kent's theory is formulated in the Lorentz invariant setting of Schwinger and Tomonaga, this would mean that Kent's theory is a solution to the measurement problem! In other words, we would have a one-world interpretation of quantum physics which gave the same probabilities for experimental outcomes that standard quantum physics predicts, and under this interpretation, the physical world would possess the necessary symmetries that guarantee whatever frame of reference one was in, the speed of light would be constant.  

\section{Kent's Theory and standard quantum theory\textsuperscript{*}\label{KentconsistentQT}}
In this section, I will describe in more detail how to extract the quantum state of a system at a particular time from the universal quantum state $\ket*{\Psi_0}$ and the mass-energy density $\tau_S$, and I will show that Kent's theory does indeed give the same predictions as standard quantum theory in the case of an experimental apparatus $\mathcal{A}$ measuring the properties of a particle $\mathcal{S}$. Again, we will consider a toy model similar to Kent's toy model described in section \ref{toysection} where photons are treated as point particles.

So let $\tau_S$ be the notional mass-energy density measurement on $S$. In order to avoid undue complexity, we will assume that there is no simultaneous $\hat{T}_S$-eigenstate degeneracy so that if $\ket*{\Psi}$ and $\ket*{\Psi'}$ are normalized\footnote{In this section we will assume that all states are normalized.} simultaneous $\hat{T}_S$-eigenstates with simultaneous eigenvalues $\tau_S$ and $\tau_S'$ respectively, then
$$(\forall x\in S) \,(\tau_S(x)=\tau_S'(x))\implies \ket*{\Psi}=\ket*{\Psi'}.$$
This means that corresponding to $\tau_S$, there will be a unique simultaneous $\hat{T}_S$-eigenstate $\ket*{\Psi}$, and according to the Born Rule, the notional mass-energy density measurement $\tau_S$ will have been selected with a probability 
$$P(T_S = \tau_S)=|\mel{\Psi}{U_{SS_0}}{\Psi_0}|^2=|\ip{\Psi}{\Psi_S}|^2$$
where $\ket*{\Psi_0}$ is the state of the initial spacelike hypersurface $S_0$, where $U_{SS_0}$ is the unitary operator defined by equation (\ref{SchwingerUnitaryOP}), and where $\ket*{\Psi_S}=U_{SS_0}\ket*{\Psi_0}$.

Now suppose this notional measurement $\tau_S$ indicates that there is some apparatus $\mathcal{A}$ that exists in the vicinity of a spatial location $z_0$ at time $t_i$ as depicted in figure \ref{pisolution}. 
\begin{figure}[ht!]
	\captionsetup{justification=justified}
	\centering
	\tikzmath{
	\a=5.3;  
	\qa=5.3;  
	\psione=0;
	\qpsione=0;
	\psitwo=1.5;
	\h=-1;
	\labelx=(\psione+\psitwo)/2;
	\labely=-1.5;
	\phstartx=-1.1;
	\qphstartx=-3.8;
	\wphstartx=-0.8;
	\phstarty=\h;
	\tbeg=\phstarty;
	\ca=\phstartx-\tbeg;
	\ttwo=\psitwo-\ca;
	\cb=\ttwo+\ca;
	\xend=\ttwo-\a+\cb;
	\tone=\psione-\ca;
	\cc=\tone+\ca;
	\xendz=\tone-\a+\cc;
	\qca=\qphstartx-\tbeg;
	\qtone=\qpsione-\qca;
	\qqcc=\qtone+\qca;
	\qxendz=\qtone-\qa+\qqcc;
	\wa=5.3;  
	\wpsione=0;
	\wttestx=3.7;
	\wca=\wphstartx-\tbeg;
	\wtone=\wpsione-\wca;
	\wwcc=\wtone+\wca;
	\wxendz=\wtone-\wa+\wwcc;
	\wat=\wa-\wttestx;
	\wct=\wttestx;
	\wlam = 0.87;
		\we=0.1;
	\tthree=\cc+\tone-\psitwo;
	\circsize=0.08;
	\md = (\a+\h)/2;
	\tlen=0.75;
	\textscale = 0.7;
	\picscale = 0.78;
	\nudge=0.1;
	\tnudge=(\ttwo-\tone)/2+0.8;
	\ttesta=2*\tone-\ttwo-\tnudge;
	\sonea=\a+\psione-\ttesta;
	\sadd=0.5;
	\lrange = -(\psione-\a+\ttesta)+\sadd;
	\rrange =\lrange; 
	\timex=\rrange-1.5;
	\ttestx=2.4;
	\at=\a-\ttestx;
	\ct=\ttestx;
	\qttestx=1.2;
	\qat=\qa-\qttestx;
	\qct=\qttestx;
	\qlam = 0.87;
	\lam = 0.87;
	\e = 0.1;
	\qe=0.1;
	\hae=(2*pow(\at,3)*\lam*(2+\lam)+\e*\e*(2*\e-sqrt(4*\e*\e+\at*\at*\lam*\lam))-8*\at*\e*(-2*\e+sqrt(4*\e*\e+\at*\at*\lam*\lam))-2*\at*\at*(2+\lam)*(-2*\e+sqrt(4*\e*\e+\at*\at*\lam*\lam)))/(4*\at*\lam*(2*\at+2*\e-sqrt(4*\e*\e+\at*\at*\lam*\lam)))-(\e*\e/4+\at*\at*(-1+\lam))/(\at*\lam);
	\qhae=(2*pow(\qat,3)*\qlam*(2+\qlam)+\qe*\qe*(2*\qe-sqrt(4*\qe*\qe+\qat*\qat*\qlam*\qlam))-8*\qat*\qe*(-2*\qe+sqrt(4*\qe*\qe+\qat*\qat*\qlam*\qlam))-2*\qat*\qat*(2+\qlam)*(-2*\qe+sqrt(4*\qe*\qe+\qat*\qat*\qlam*\qlam)))/(4*\qat*\qlam*(2*\qat+2*\qe-sqrt(4*\qe*\qe+\qat*\qat*\qlam*\qlam)))-(\qe*\qe/4+\qat*\qat*(-1+\qlam))/(\qat*\qlam);
		\whae=(2*pow(\wat,3)*\wlam*(2+\wlam)+\we*\we*(2*\we-sqrt(4*\we*\we+\wat*\wat*\wlam*\wlam))-8*\wat*\we*(-2*\we+sqrt(4*\we*\we+\wat*\wat*\wlam*\wlam))-2*\wat*\wat*(2+\wlam)*(-2*\we+sqrt(4*\we*\we+\wat*\wat*\wlam*\wlam)))/(4*\wat*\wlam*(2*\wat+2*\we-sqrt(4*\we*\we+\wat*\wat*\wlam*\wlam)))-(\we*\we/4+\wat*\wat*(-1+\wlam))/(\wat*\wlam);
	} 
	\tikzstyle{scorestars}=[star, star points=5, star point ratio=2.25, draw, inner sep=1pt]%
	\tikzstyle{scoresquare}=[draw, rectangle, minimum size=1mm,inner sep=0pt,outer sep=0pt]%
	\begin{tikzpicture}[scale=\picscale,
	declare function={
		testxonep(\ps,\t)=\a+\ps-\t;
		testxonem(\ps,\t)=\ps-\a+\t; 
		bl(\x)=\ct+\at-\e/2-1/2*(sqrt(\lam*\lam*pow(\x+\hae+\at,2)+\e*\e)-\e+\lam*(\x+\hae+\at));
		br(\x)=\ct+\at-\e/2-1/2*(sqrt(\lam*\lam*pow(\x-\hae-\at,2)+\e*\e)-\e-\lam*(\x-\hae-\at));
		bc(\x)=\ct+sqrt(\lam*\lam*\x*\x+\e*\e)-\e;
		qbl(\qx)=\qct+\qat-\qe/2-1/2*(sqrt(\qlam*\qlam*pow(\qx+\qhae+\qat,2)+\qe*\qe)-\qe+\qlam*(\qx+\qhae+\qat));
		qbr(\qx)=\qct+\qat-\qe/2-1/2*(sqrt(\qlam*\qlam*pow(\qx-\qhae-\qat,2)+\qe*\qe)-\qe-\qlam*(\qx-\qhae-\qat));
		qbc(\qx)=\qct+sqrt(\qlam*\qlam*\qx*\qx+\qe*\qe)-\qe;
		wbl(\wx)=\wct+\wat-\we/2-1/2*(sqrt(\wlam*\wlam*pow(\wx+\whae+\wat,2)+\we*\we)-\we+\wlam*(\wx+\whae+\wat));
		wbr(\wx)=\wct+\wat-\we/2-1/2*(sqrt(\wlam*\wlam*pow(\wx-\whae-\wat,2)+\we*\we)-\we-\wlam*(\wx-\whae-\wat));
		wbc(\wx)=\wct+sqrt(\wlam*\wlam*\wx*\wx+\we*\we)-\we;
	},
	 ] 
	\definecolor{tempcolor}{RGB}{250,190,0}
	\definecolor{darkgreen}{RGB}{40,190,40}
	
	\draw[->,blue, thick] [domain=-\at/2:-\lrange, samples=150]   plot (\x, {bl(\x)})  ;
	\draw[blue, thick] [domain=-\at/2:\at/2, samples=150] plot (\x, {bc(\x)})   ;
	\draw[->,blue, thick] [domain=\at/2:\rrange, samples=150]   plot (\x, {br(\x)})   ;
	
	 
	 \draw[->,gray, thick] [domain=-\at/2:-\lrange, samples=150]   plot (\x, {qbl(\x)})  ;
	\draw[gray, thick] [domain=-\at/2:\at/2, samples=150] plot (\x, {qbc(\x)})   ;
	\draw[->,gray, thick] [domain=\at/2:\rrange, samples=150]   plot (\x, {qbr(\x)})   ;
	
	\draw[->,black, thick] [domain=-\at/2:-\lrange, samples=150]   plot (\x, {wbl(\x)})  ;
	 \draw[black, thick] [domain=-\at/2:\at/2, samples=150] plot (\x, {wbc(\x)})   ;
	 \draw[->,black, thick] [domain=\at/2:\rrange, samples=150]   plot (\x, {wbr(\x)})   ;

	  
	  
	
	
	 \node[scale=\textscale]  at (2.5,4.1) {$S_{n,f}$}; 
	  \node[scale=\textscale]  at (3.9,4.1) {$S_{n,i}$}; 
	  	  \node[scale=\textscale]  at (1.1,4.1) {$S_{n,m}$}; 
	
	\draw[<->] (-\lrange, \h) node[left, scale=\textscale] {$S_0$} -- (\rrange, \h) node[right, scale=\textscale] {$S_0$};
	\draw[<->] (-\lrange, \a) node[left, scale=\textscale] {$S$} -- (\rrange, \a) node[right, scale=\textscale] {$S$};
				  
	\draw[->, shorten <= 5pt,  shorten >= 1pt] (\psione,\h)  node[above right, scale=\textscale]{$z_0$}-- (\psione,\a) ;
	
	
	\draw[dashed, tempcolor,  ultra thick](\phstartx,\tbeg) node[below left=-2,scale=\textscale]{}--(\psione,\tone) node[above, pos=0.3, rotate=45,scale=0.7,black] {} node[below, pos=0.3, rotate=45,scale=0.7,black] {};
	\draw[dashed, tempcolor,  ultra thick](\psione,\tone)--(\xendz,\a);
	
	
	\draw[dashed, tempcolor, ultra thick](\qphstartx,\tbeg) node[below left=-2,scale=\textscale]{}--(\psione,\qtone) node[above, pos=0.3, rotate=45,scale=0.7,black] {} node[below, pos=0.3, rotate=45,scale=0.7,black] {};
	\draw[dashed, tempcolor, ultra thick](\psione,\qtone)--(\qxendz,\a);

	\draw[dashed, orange](\wphstartx,\tbeg) node[below left=-2,scale=\textscale]{}--(\psione,\wtone) node[above, pos=0.3, rotate=45,scale=0.7,black] {} node[below, pos=0.3, rotate=45,scale=0.7,black] {};
	\draw[dashed, orange](\psione,\wtone)--(\wxendz,\a);
	
	\draw[->] (\timex,\md-\tlen/2) --  (\timex,\md+\tlen/2) node[midway,right, scale=\textscale]{time}; 
	 
	\draw[dotted](\psione,\ttestx)--({testxonep(\psione,\ttestx)},\a);
	\draw[dotted](\psione,\ttestx)--({testxonem(\psione,\ttestx)},\a);
	\draw[dotted](\psione,\qttestx)--({testxonep(\psione,\qttestx)},\a);
	\draw[dotted](\psione,\qttestx)--({testxonem(\psione,\qttestx)},\a);
	
	\draw (\psione,\ttestx) node[ scoresquare, fill=gray]  {} node [black,below=6,right,scale=\textscale] {$t_f$};
	\draw (\psione,\qttestx) node[ scoresquare, fill=gray]  {} node [black,below=6,right,scale=\textscale] {$t_i$};
	\draw (\psione,\wttestx) node[ scoresquare, fill=gray]  {} node [black,below=6,right,scale=\textscale] {$t_m$};
	
%	\draw[magenta,->,ultra thick] ({testxonem(\psione,\qttestx)},\a)--(-\lrange,\a);
%	\draw[magenta,ultra thick] ({testxonem(\psione,\ttestx)},\a)-- ({testxonem(\psione,\qttestx)},\a);
%	\draw[magenta,ultra thick] ({testxonep(\psione,\ttestx)},\a)-- ({testxonep(\psione,\qttestx)},\a);
%	\draw[magenta,->,ultra thick] ({testxonep(\psione,\qttestx)},\a)--(\rrange,\a);
	
	\draw [black,fill](\xendz,\a) circle [radius=\circsize] node [black,above=9,right=-4,scale=\textscale] {$\gamma_i^{(\mathcal{A})}$}; 
	\draw [black,fill](\wxendz,\a) circle [radius=\circsize] node [black,above=9,left=-7,scale=\textscale] {$\gamma_i^{(\mathcal{S})}$}; 
	\draw [black,fill](\qxendz,\a) circle [radius=\circsize] node [black,above,scale=\textscale] {$\gamma_f^{\prime}$}; 
		%\draw [black,fill] (\xendz,\a) circle [radius=\circsize] node [black,above,scale=\textscale] {$\gamma_1$}; 
	\end{tikzpicture}% pic 1
	
	\vspace*{2px}
	\caption{Depicts an experiment where the state of some photons $\gamma_i^{(\mathcal{S})}$ and $\gamma_i^{(\mathcal{A})}$ on the spacelike hypersurface $S$ determines the initial conditions of an experimental setup of a particle $\mathcal{S}$ and apparatus $\mathcal{A}$ in the vicinity of the spacetime location $( t_i, z_0)$.  The state of the photons $\gamma_f^{\prime}$ on the spacelike hypersurface $S$ determines the final state of the apparatus $\mathcal{A}$ after the particle $ \mathcal{S}$ has finished interacting with it from time $t_f$ onwards so that the apparatus at time $t_m$ displays a definite measurement outcome. It is assumed that no incoming photons have become entangled with the experiment after the $\gamma_i^{(\mathcal{S})}$ and $\gamma_i^{(\mathcal{A})}$ photons and before the $\gamma_f^{\prime}$ photons have become entangled with the experiment.  }
	\label{pisolution}
	\end{figure}
This means that prior to $t_i$, the apparatus will have interacted with many photons so that the photon detections on $S$ outside the light cone of $y_i=(t_i, z_0)$ will indicate via Kent's stress-energy beables that there is some apparatus in the vicinity of $z_0$ that we can identify as $\mathcal{A}$. We further assume that Kent's stress-energy beables determine that $\mathcal{A}$ is in a state $\ket{a}$ which encapsulates among other things the measurement parameters of the apparatus.  We also suppose that the information in $\tau_S$ indicates that there is a particle $\mathcal{S}$ at time $t_i$ in a state
$\ket{s}$ that is heading towards the apparatus so that it will interact with it. This means that all the 
possible\footnote{i.e. possible given $\ket{\Psi_0}$ and the Born rule selection criterion.} 
simultaneous $\hat{T}_S$-eigenstates on $S$ whose simultaneous $\hat{T}_S$-eigenvalues agree with $\tau_S$ for all $x\in S^1(y_i)$\footnote{Recall from page \pageref{S2} that $S^1(y_i)$ is the subset of $S$ that is outside the light cone of $y_i$.} 
 are such that their simultaneous $\hat{T}_S$-eigenvalues within the light cone of $y_i$ indicate that at some time after $t_i$, the particle $\mathcal{S}$ would have interacted
with the apparatus $\mathcal{A}$. 

At this point, it will be helpful to define a \textbf{simultaneous $\hat{T}_S$-eigenstate of a subregion}\index{simultaneous $\hat{T}_S$-eigenstate of a subregion} $U$ of $S$ to be a state $\ket{\Psi_U}\in H_U$  which is an eigenstate of $\hat{T}_S(u)$ for every $u\in U$, where $H_U$ is the Hilbert space of states describing $U$. We will assume that we can write any state of $H_S$ as a superposition of states of the form $\ket*{\Psi_U}\ket*{\Psi_{S\setminus U}}$, where $\ket{\Psi_U}\in H_U $ is  a simultaneous $\hat{T}_S$-eigenstate of the subregion $U$ of $S$, and $\ket*{\Psi_{S\setminus U}}\in H_{S\setminus U}$ is a simultaneous
$\hat{T}_S$-eigenstate of the subregion $S\setminus U$ of $S$.\footnote{We effectively made this assumption in equation (\ref{Sistate}).} We will accordingly let  
$\ket*{\gamma^{(S^1(y_i))}_i}$ denote the simultaneous $\hat{T}_S$-eigenstate of the subregion $S^1(y_i)$ of $S$ with simultaneous $\hat{T}_S$-eigenvalue $\tau_S(x)$ respectively for all $x\in S^1(y_i)$. Then any  simultaneous $\hat{T}_S$-eigenstate over the whole of $S$  whose simultaneous $\hat{T}_S$-eigenvalue agrees with 
$\tau_S$ on the subregion $S^1(y_i)$ will be expressible as
$\ket*{\gamma^{(S^1(y_i))}_i}\ket*{\Psi_{S\setminus S^1(y_i)}}$, 
and any such simultaneous $\hat{T}_S$-eigenstate will determine the apparatus $\mathcal{A}$ and the particle $\mathcal{S}$ to exist in states $\ket{a}$ and $\ket{s}$ respectively given the state $\ket*{\Psi_0}$ of the initial hypersurface $S_0$. In figure \ref{pisolution}, rather than depicting $\ket*{\gamma^{(S^1(y_i))}_i}$, we depict the two components $\ket*{\gamma^{(\mathcal{S})}_i}$ and $\ket*{\gamma^{(\mathcal{A})}_i}$ of $\ket*{\gamma^{(S^1(y_i))}_i}$ which are simultaneous $\hat{T}_S$-eigenstates for subregions $S_{\mathcal{S}}$ and $S_{\mathcal{A}}$ of $S^1(y_i)$ where the states of $\mathcal{S}$ and $\mathcal{A}$ are determined respectively, so that 
\begin{equation}\label{gammadecomp}
\ket*{\gamma^{(S^1(y_i))}_i}=\ket*{\gamma^{(\mathcal{S})}_i}\ket*{\gamma^{(\mathcal{A})}_i}\ket*{\Xi^{(S^1(y_i))}_i}
\end{equation}
where $\ket*{\Xi^{(S^1(y_i))}_i}$ is a simultaneous $\hat{T}_S$-eigenstate over the remainder of $S^1(y_i)$, i.e. for the subregion $S^1(y_i)\setminus(S_{\mathcal{S}}\cup S_{\mathcal{A}})$. Note that it is not necessary that the state $\ket*{\gamma^{(\mathcal{S})}_i}$ is caused by photons that have interacted directly with $\mathcal{S}$. Rather, it is sufficient that the photons have been reflected from some system $\mathcal{B}$, say, that has interacted with $\mathcal{S}$ for which $\ket*{s}$ is a pointer state, and that enough photons from $\mathcal{B}$ have intersected $S$ so as to distinguish its different pointer states. 

We also assume that there are no further interactions of $\mathcal{S}$ with photons that are registered on $S$ until the particle has finished interacting with the apparatus $\mathcal{A}$.  In making this assumption, we suppose that there is a time $t_f>t_i$ such that if the notional measurement on $S$ had resulted in the outcome $\tau_S^{(j)}$ rather than $\tau_S$ where $\tau_S^{(j)}(x)=\tau_S(x)$ for all $x\in S^1(y_i)$, then for all $x \in S^1(y_f,y_i)=S^1(y_f)\setminus S^1(y_i)$,\footnote{i.e $S^1(y_f,y_i)$ is the subset of $S$ that is within the light cone of $y_i=(t_i, z_0)$ but outside the light cone of $y_f=(t_f, z_0)$.} we would be able to say of the mass-energy density $\tau_S^{(j)}(x)$ at $x$ that it wasn't caused by a photon that had been reflected from $\mathcal{S}$ or from something that had become entangled with $\mathcal{S}$.\footnote{This assumption of our toy model assumes that photons can be treated as point-particles so that they have precise trajectories and that different photons will almost certainly be detected at different locations on $S$. In physical reality, we can't treat photons as point-particles, and so there will be some ambiguity about where the photons detected on $S$ came from.}

We will assume that given that the notional measurement restricted to $S^1(y_i)$ is $\tau_S$, there is sufficiently little interaction of the composite system $\mathcal{S}+\mathcal{A}$ with its environment so that we can assume it evolves unitarily in accordance with the Schr\"{o}dinger equation. Therefore, given that the apparatus $\mathcal{A}$ is in a state $\ket{a}$ that encapsulates its parameter settings, and the particle $\mathcal{S}$ is on course to interact with $\mathcal{A}$, we can express the state $\ket{s}$ of $\mathcal{S}$ as a superposition $\ket{s}=\sum_j c_j \ket{s_j}$ where $\{\ket{s_j}:j\}$ is the set of pointer states corresponding to a particular parameter setting of the apparatus $\mathcal{A}$ that are encapsulated in the state $\ket{a}$. As described on page \pageref{pointer}, this means there are future states $\ket{a_j}$ of the apparatus $\mathcal{A}$ such that $\ip{a_j}{a_{j'}}=0$ for $j\neq j'$,\footnote{Strictly speaking, $\ip{a_j}{a_{j'}}\approx 0$ for $j\neq j'$, but we will assume $\ip{a_j}{a_{j'}}=0$ in this toy model in order to avoid undue complexity.} and such that the composite system $\mathcal{S}+\mathcal{A}$ will evolve according to the Schr\"{o}dinger equation as
$$\ket{s_j}\ket{a}\rightarrow \ket{s_j}\ket{a_j} $$
for each pointer state $\ket{s_j}$, and hence
\begin{equation}\label{saevolution}
\ket{s}\ket{a}\rightarrow \sum_j c_j \ket{s_j}\ket{a_j}.
\end{equation}

We will also assume that given that the notional measurement restricted to $S^1(y_i)$ is $\tau_S$, there is a time interval between $t_f$ and $t_m > t_f$ during which photons will reflect off the apparatus $\mathcal{A}$ and ultimately be detected at spacetime locations on the hypersurface $S$ that correspond to one of the definite measurement states $\ket{a_f}$ of the apparatus indicating that $\mathcal{S}$ is in the state $\ket{s_f}$. But whatever the  notional measurement on $S$ is, so long as it results in an outcome $\tau_S^{(j)}$ with $\tau_S^{(j)}(x)=\tau_S(x)$ for all $x\in S^1(y_i)$, then we're assuming that for all $x \in S^1(y_m,y_f),$\footnote{where $y_m=(t_m, z_0)$.} we would be able to say of the mass-energy density $\tau_S^{(j)}(x)$ at $x$ that it was caused by a photon that had been reflected from the apparatus $\mathcal{A}$ being in some state $\ket{a_j}$ rather than one of the other states.\footnote{This is again an assumption of our toy model, so it may not be true in more realistic models where there are many more object off which photons could reflect.} We will let $S_{\mathcal{A}}'$ denote the subregion of $S^1(y_m,y_f)$ where photons coming from the apparatus arrive and hence determine which state the apparatus  is in, and we will let $\ket*{\gamma'_j}$ denote the simultaneous $\hat{T}_S$-eigenstate of the subregion $S_{\mathcal{A}}'$ of $S$ that corresponds to the apparatus $\mathcal{A}$ being in state $\ket{a_j}$.  We will also label the states on the subregion $S\setminus (S^1(y_i)\cup S_{\mathcal{A}}')$ as $\ket{\Xi_j}$ so that we can express the state $\ket*{\Psi_S}=U_{SS_0}\ket*{\Psi_0}$ as a superposition
\begin{equation}\label{PsiSdecomp}
\ket*{\Psi_S}=b\ket*{\gamma_i^{(S^1(y_i))}}\sum_j c_j \ket*{\gamma_j'}\ket*{\Xi_j} +\sum_{k\neq 0} b_k\ket*{\gamma_k^{(S^1(y_i))}}\ket*{\Xi_k'}
\end{equation}
where the $\ket*{\gamma_k^{(S^1(y_i))}}$ for $k\neq i$ are simultaneous $\hat{T}_S$-eigenstates of the subregion $S^1(y_i)$ whose simultaneous $\hat{T}_S$-eigenvalues restricted to $S^1(y_i)$ are distinct from $\tau_S$, where $\ket*{\Xi_k'}$ are states of the subregion $S\setminus S^1(y_i)$, and where $b$  is a complex numbers whose modulus squared gives the probability that the notional measurement on $S^1(y_i)$ will be $\tau_S$, and likewise, the modulus squared of the $b_k$ give the probabilities of the other possible notional measurements on $S^1(y_i).$ 

Now we aim to show that within Kent's theory, we can calculate the probability the particle emerges from the measuring apparatus $\mathcal{A}$ in state $\ket{s_{f}}$ given that it enters $\mathcal{A}$ in state $\ket{s}$, and that this probability is the same as if one ignored $S$ and just applied the Born Rule to $\ket{s}$ and $\ket{s_f}$. 

In order to show this, let us choose a sequence of spacelike hypersurfaces $S_{n,i}$ which go through the spacetime location $y_i=(t_i, z_0)$ such that $\lim_{n\rightarrow\infty} S_{n,i}\cap S=S^1(y_i).$\footnote{We understand this limit first by giving $S^1(y_i)$ and $S_{n,i}$  topologies that makes them locally homeomorphic to Euclidean space. Then by saying there is this limit of hypersurfaces, we mean that every point $u\in S^1(y_i)$ has a neighborhood $U\subset S^1(y_i)$ for which there is an integer $N$ such that $U\subset S_{n,i}$ for all $n\geq N$.} Let us assume that $n$ is sufficiently large so that the photons described by $\ket*{\gamma_i^{(\mathcal{S})}}$ and $\ket*{\gamma_i^{(\mathcal{A})}}$ belong to $S_{n,i}$. The spacelike hypersurface $S_{n,i}$ and the photons being reflected from the vicinity of $z_0$ just before time $t_i$ are  depicted in figure \ref{pisolution}.

With equation (\ref{PsiSdecomp}) in mind, we can express the quantum state $\ket{\Psi_{n,i}}=U_{S_{n,i},S_0}\ket{\Psi_0}$  of the spacelike hypersurface $S_{n,i}$ as a superposition 
\begin{equation}\label{Psinidecomp}
\ket{\Psi_{n,i}}=b\ket*{\gamma_i^{(\mathcal{S})}}\ket*{\gamma_i^{(\mathcal{A})}}\ket{s}\ket{a}\ket{\xi_{n,i}}+\cdots.
\end{equation} 
The $\ket*{\gamma_i^{(\mathcal{S})}}\ket*{\gamma_i^{(\mathcal{A})}}$ component of the first summand of (\ref{Psinidecomp}) is extracted from the $\ket*{\gamma_i^{(S^1(y_i))}}$ component of (\ref{PsiSdecomp}) which we can do because we're assuming $S_{n,i}$ overlaps with $S$ in the subregion $S^1(y_i)$ corresponding to the states $\ket*{\gamma_i^{(\mathcal{S})}}$ and $\ket*{\gamma_i^{(\mathcal{A})}}$. Corresponding to the region in the vicinity of $y_i$ on $S_{n,i}$, we have the components $\ket{s}\ket{a}$ because we're assuming that the measurement of $\tau_S$ on $S^1(y_i)$ guarantees that $\mathcal{S}$ and $\mathcal{A}$ are in the states $\ket{s}$ and $\ket{a}$ respectively. The component $\ket{\xi_{n,i}}$ corresponds to the state of all the other regions of $S_{n,i}$ not determined by $\ket*{\gamma_i^{(\mathcal{S})}}$, $\ket*{\gamma_i^{(\mathcal{A})}}$, $\ket{s}$ or $\ket{a}$, and the ellipses correspond to the summation over $k$ term of (\ref{PsiSdecomp}) suitably modified so that the summands are states on $S_{n,i}$ rather than $S$.

If we now define the projection $\pi_{n,i}$ corresponding to the measurement outcome  $\tau_S(x)$ on $S_{n,i}\cap S$ as in equation (\ref{tauprojection}), then
\begin{equation}\label{piphi}
	\pi_{n,i}\ket{\Psi_{n,i}}\approx b\ket*{\gamma_i^{(\mathcal{S})}}\ket*{\gamma_i^{(\mathcal{A})}}\ket{s}\ket{a}\ket{\xi_{n,i}},
\end{equation}
and the larger $n$ is, the closer (\ref{piphi}) will come to being an equality. The key thing to note about (\ref{piphi}) is that the systems $\mathcal{S}$ and $\mathcal{A}$ are not entangled with each other or with the environment. We can therefore think of the measurement outcome of $\tau_S(x)$ on $S_{n,i}\cap S$ for sufficiently large $n$ as specifying the initial states $\ket{s}$ and $\ket{a}$ of   $\mathcal{S}$ and $\mathcal{A}$ before they interact. If $n$ was too small, $S_{n,i}\cap S$ might not contain the subregion for which $\ket{\gamma_i^{\mathcal{A}}}$ is a state, in which case we could expect the $\mathcal{A}$-component of $\pi_{n,i}\ket{\Psi_{n,i}}$ to be entangled with the environment with different environment states being correlated with different parameter settings of $\mathcal{A}$. Likewise, we could expect the $\mathcal{S}$-component of $\pi_{n,i}\ket{\Psi_{n,i}}$ to be entangled with  the environment with different environment states being correlated with different states of $\mathcal{S}$ if $n$ was too small. In some situations, the rate at which $\mathcal{S}$ interacts with its immediate environment may be greater than the rate at which photons from the immediate environment of $\mathcal{S}$ are registered on $S$, in which case, it would not be possible to disentangle $\mathcal{S}$ from its environment in $\pi_{n,i}\ket{\Psi_{n,i}}$. But in controlled experimental settings in which the system $\mathcal{S}$ is prepared to be in a definite state, it should be possible to disentangle $\mathcal{S}$ from its environment in $\pi_{n,i}\ket{\Psi_{n,i}}$. So in this situation, to extract the state of a system $\mathcal{S}$ in the vicinity of $z_0$ at time $t_i$ from $\ket{\Psi_0}$ and $\tau_S$, we need to take a hypersurface $S_{n,i}$ for sufficiently large $n$ that goes through $y_i=(t_i, z_0)$. The state of $\mathcal{S}$ in the vicinity of $y_i$ will then be the disentangled normalized $\mathcal{S}$-component of $\pi_{n,i}\ket{\Psi_{n,i}}=\pi_{n,i}U_{S_{n,i},S_0}\ket{\Psi_0}$. So in the case of (\ref{Psinidecomp}), the disentangled normalized $\mathcal{S}$-component of $\pi_{n,i}\ket{\Psi_{n,i}}$ will be $\ket{s}$.

\begin{comment}
  For convenience, we will omit the reference to $n$ and write $S_i$ for $S_{n,i}$, $\ket{\Psi_i}$ for $\ket{\Psi_{n,i}}$, and $\pi_i$ for $\pi_{n,i}$. We will also write $\ket{\Phi_i}$ for the normalized state of $\pi_i\ket{\Psi_i}$ so that 
 \begin{equation}\label{phii}
	\ket{\Phi_i}\approx \ket{s}\ket{a}\ket*{\gamma_i^{(\mathcal{S})}}\ket*{\gamma_i^{(\mathcal{A})}}.
\end{equation}

Now we're assuming that the measurement outcome $\tau_S$ on the whole of $S$ will determine the apparatus $\mathcal{A}$ to be in the state $\ket{a_f}$ by time $t_m$, and hence the particle $\mathcal{S}$ to be in the state $\ket{s_f}$, and $\tau_S$ will determine this outcome with probability $1$. However, if the the mass-energy density was only determined to be $\tau_S$ on $S^1(y_i)$, then the probability the apparatus and the particle would be found to be in the states $\ket{a_f}$ and $\ket{s_f}$ respectively at time $t_m$ would typically be less than $1$.
 
 To calculate this probability, we first consider the evolution of $\ket{\Phi_i}$ to $ U_{S_f,S_i}\ket{\Phi_{i}}$. It's possible that there may be photons ``measured'' on $S$ between the spacelike hypersurfaces $S_i$ and $S_f$ as indicated in figure \ref{pisolution} (i.e. on $(S\cap S_f)\setminus(S\cap S_i)$), but we are assuming that they do not get entangled with the different pointer states of the apparatus. In other words, $\ket{\Phi_i}$ will evolve to a state of the form 
\begin{equation}\label{USfievolve1}
	U_{S_f,S_i}\ket{\Phi_{i}}\approx \sum_j c_j\ket{s_j}\ket{a_j}\ket*{\gamma_i^{(\mathcal{S})}}\ket*{\gamma_i^{(\mathcal{A})}}\sum_kg_k\ket{\gamma'_k},
\end{equation}
where $\ket{\gamma_k'}$ correspond to the possible measurements of $T_S(x)$  on $(S\cap S_f)\setminus(S\cap S_i)$, and $\sum_k\abs{g_k}^2=1$.

But from time $t_f$ to $t_m$, we assume that the apparatus does get entangled with photons which are measured on $S\cap S_m$. Thus, if $\{\ket{\gamma_j^{\prime\prime}}:j\}$ are the normalized states representing the possible measurements outcomes of these photons such that $\ip{\gamma_j^{\prime\prime}}{\gamma_k^{\prime\prime}}\approx 0$ for $j\neq k$, then 
$$U_{S_m,S_f} U_{S_f,S_i}\ket{\Phi_{i}}\approx \sum_j c_j\ket{s_j}\ket{a_j}\ket*{\gamma_i^{(\mathcal{S})}}\ket*{\gamma_i^{(\mathcal{A})}}\sum_kg_k\ket{\gamma'_k}\ket{\gamma_j^{\prime\prime}}.$$
Since we are assuming that at time $t_m$ a measurement of photons on $S\cap S_m$ is able to determine that the apparatus is in state $\ket{a_f}$, this can only happen if $U_{S_m,S_f} U_{S_f,S_i}\ket{\Phi_{i}}$ is found to be in one of the states $\ket{\Phi_{k,f}}$ for some $k$ where
$$\ket{\Phi_{k,j}}=\ket{s_j}\ket{a_j}\ket*{\gamma_i^{(\mathcal{S})}}\ket*{\gamma_i^{(\mathcal{A})}}\ket{\gamma'_k}\ket{\gamma_j^{\prime\prime}}.$$
By the Born Rule, the probability $\ket{\Phi_i}$ will be found to be in state $\ket{\Phi_{k,j}}$ will be
$$\abs{\ip{\Phi_{k,j}}{\Phi_i}}=\abs{c_j}^2\abs{g_k}^2.$$
Therefore,
$$P(f|\ket{\Phi_i})=\sum_k \abs{\ip{\Phi_{k,f}}{\Phi_i}}=\abs{c_f}^2=\abs{\ip{s_f}{s}}^2.$$
Hence, the probability that a complete measurement of $T_S(x)$ on $S$ will give a measurement outcome of the particle being in state $\ket{s_f}$ given the partial measurement of $T_S(x)$ on $S_i\cap S$ determines the particle to be initially in the state $\ket{s}$ will be the same as the standard Born Rule probability $\abs{\ip{s_f}{s}}^2$ of $\ket{s}$ being found to be in state $\ket{s_f}$.

\end{comment}

Now given that the system $\mathcal{S}$ is in state $\ket{s}$ and that $\ket{s_f}$ was one of the possible measurement outcome states for $\mathcal{S}$, according to standard quantum mechanics, the Born rule would predict that the measurement outcome state $\ket{s_f}$ occurs with a probability of $|\ip{s}{s_f}|^2$. We will now show that we can obtain this probability in Kent's theory as well. To do this, we recall that in standard quantum theory, if  we define the operator $[\psi]=\dyad{\psi}$ for some state $\ket{\psi}$ of a system, then when the system is in some initial state $\ket{\chi}$, the Born Rule implies that $\ev{[\psi]}{\chi}=P(\psi|\chi)$, where $P(\psi|\chi)$ is the probability that the system will be found to be in state $\ket{\psi}$ given that it was initially in state $\ket{\chi}$. But by (\ref{evev}),  $\ev{[\psi]}{\chi}$ is just the expectation $\ev*{[\psi]}_\chi$ of $[\psi]$ when $[\psi]$ is treated as an observable. 

Now in equation (\ref{kentconsistency0}), we saw how to calculate the expectation value $\ev*{T^{\mu\nu}(y)}_{\tau_S}$ of the observable $\hat{T}^{\mu\nu}(y)$ given the notional measurement $\tau_S$ on $S$ outside the light cone of $y$. This suggests that the expectation value of any observable $\hat{O}$ defined at spacetime location $y_i=(t_i,z_0)$ given the notional measurement $\tau_S$ on $S$ outside the light cone of $y_i$ is going to be
\begin{equation}\label{kentevo}
\ev*{\hat{O}}_{\tau_S}=\lim_{n\rightarrow\infty}\frac{\ev*{\pi_{n,i}\hat{O}}{\Psi_{n,i}}}{\ev*{\pi_{n,i}}{\Psi_{n,i}}}.
\end{equation}
By (\ref{piphi}), $\lim_{n\rightarrow\infty}\ev*{\pi_{n,i}}{\Psi_{n,i}}=\abs{b}^2$, and so taking $\hat{O}$ to be $[s_f]$ at spacetime location $y_i$ we have 
$$ \ev*{[s_f]}_{\tau_S}=\frac{\abs{b}^2\abs{\ip{s_f}{s}}^2}{\abs{b}^2}=\abs{\ip{s_f}{s}}^2.$$
Thus, Kent's conditional expectation $\ev*{[s_f]}_{\tau_S}$ at spacetime location $y_i$ gives us the same probability $\abs{\ip{s_f}{s}}^2$ for a particle transitioning from state $\ket{s}$ to state $\ket{s_f}$ as in standard quantum theory.

We can also use Kent's conditional expectation to show that at time $t_m$, $\ket{s_f}$ occurs with probability $1$ given the notional measurement $\tau_S$ on $S$ outside the light cone of $y_m=(t_m,z_0)$ has $\ket{\gamma_f'}$ as a component . To see this, first note that since we are assuming that between times $t_i$ and $t_f$, $\ket{s}\ket{a}$ evolves according to (\ref{saevolution}), we can apply $U_{S_{n,f},S_{n,i}}$ to (\ref{Psinidecomp}) (where $S_{n,f}$ is one of the spacelike hypersurfaces that goes through $y_f$ as depicted in figure \ref{pisolution}) to get
\begin{equation}\label{Psinfdecomp}
	\ket{\Psi_{n,f}}=b\ket*{\gamma_i^{(\mathcal{S})}}\ket*{\gamma_i^{(\mathcal{A})}}\sum_j c_j \ket{s_j}\ket{a_j}\ket{\xi_{n,f}}+\cdots.
	\end{equation} 
In (\ref{Psinfdecomp}), the component $\ket{\xi_{n,f}}$ corresponds to the state of all the other regions of $S_{n,f}$ not determined by $\ket*{\gamma_i^{(\mathcal{S})}}$, $\ket*{\gamma_i^{(\mathcal{A})}}$, or the state of $\mathcal{S}$ and $\mathcal{A}$ in the vicinity of $y_f=(t_f, z_0)$, and the ellipses correspond to the ellipses of (\ref{Psinidecomp}) to which $U_{S_{n,f},S_{n,i}}$ has been applied. 

Since we need to calculate Kent's conditional expectation of $[s_f]$ at spacetime location $y_m$, we need to apply  $U_{S_{n,m},S_{n,f}}$ to (\ref{Psinfdecomp}), where $S_{n,m}$ is one of the spacelike hypersurfaces that goes through $y_m$ as depicted in figure \ref{pisolution}. To do this, we continue to assume that no photons interact with $\mathcal{S}$ between times $t_f$ and $t_m$. However, we do assume that photons will interact with the apparatus, and for large enough $n$, the $S_{n,m}$ hypersurfaces will contain the subregion $S_{\mathcal{A}}'$ of $S^1(y_m)$ where the photons coming from the apparatus arrive, and so for each $j$, the $\ket{\gamma_j'}$-state that corresponds to the $\ket{a_j}$-state of the apparatus $\mathcal{A}$ and which forms a component of one of the summands of $\ket{\Psi_S}$ as shown in equation (\ref{PsiSdecomp}) will also appear $\ket{\Psi_{n,m}}$. It therefore follows that 
\begin{equation}\label{Psinfdecomp}
	\ket{\Psi_{n,f}}=b\ket*{\gamma_i^{(\mathcal{S})}}\ket*{\gamma_i^{(\mathcal{A})}}\sum_j c_j \ket{s_j}\ket{a_j}\ket{\gamma_j'}\ket{\xi_{n,m}}+\cdots.
\end{equation} 
where the component $\ket{\xi_{n,m}}$ corresponds to the state of all the regions of $S_{n,m}$ not determined by $\ket*{\gamma_i^{(\mathcal{S})}}$, $\ket*{\gamma_i^{(\mathcal{A})}}$,  $S_{\mathcal{A}}'$, or the state of $\mathcal{S}$ and $\mathcal{A}$ in the vicinity of $y_m=(t_m, z_0)$, and the ellipses correspond to the ellipses of (\ref{Psinfdecomp}) to which $U_{S_{n,m},S_{n,f}}$ has been applied. Since we are assuming that the notional measurement restricted to $S^1(y_m)$ will correspond to the apparatus being in the definite measurement state $\ket{a_f}$, then defining the projection corresponding to the measurement outcome $\tau_S$ on $S_{n,m}\cap S$ as in equation (\ref{tauprojection}), we will have
\begin{equation}\label{piphim}
\pi_{n,m}\ket{\Psi_{n,m}}\approx b c_f \ket*{\gamma_i^{(\mathcal{S})}}\ket*{\gamma_i^{(\mathcal{A})}}\ket{s_f}\ket{a_f}\ket{\gamma_f'}\ket{\xi_{n,m}}
\end{equation}
and the larger $n$ is, the closer (\ref{piphim}) will come to being an equality. 

We can now use (\ref{kentconsistency}) to calculate Kent's conditional expectation of $\ev*{[s_f]}_{\tau_S}$ at spacetime location $y_m$. By (\ref{piphim}), we have  $\lim_{n\rightarrow\infty}\ev*{\pi_{n,m}}{\Psi_{n,m}}=\abs{b}^2 \abs{c_f}^2 $, and $\lim_{n\rightarrow\infty}\ev*{[s_f] \pi_{n,m}}{\Psi_{n,m}}=\abs{b}^2 \abs{c_f}^2 $, and so by (\ref{kentevo}), at spacetime location $y_m$ we have
$$ \ev*{[s_f]}_{\tau_S}=1,$$
and so according to Kent's theory, $\mathcal{S}$ will be in state $\ket{s_f}$ by time $t_m$.

Also note that we can typically expect the $\ket*{\gamma_i^{(\mathcal{S})}}$-state to be independent of the $\ket*{\gamma_i^{(\mathcal{A})}}$-state. Therefore, since $\ket*{\gamma_i^{(\mathcal{A})}}$ will determine the measurement choice, and since $\ket*{\gamma_i^{(\mathcal{S})}}$ determines the initial state of the particle, we can expect the state of the particle to be independent of the measurement choice in Kent's theory. Thus, we can fulfil one of the necessary criteria (i.e. criterion \ref{hidden2}) for PI to be a well-defined notion.

We can also choose a set of $\lambda$ so that criterion \ref{hidden5} holds. To do this, we consider equation (\ref{gammadecomp}) which presupposes there is a subregion $S_{\mathcal{S}}$ of $S^1(y_i)$ which determines the state $\mathcal{S}$ and another non-overlapping subregion $S_{\mathcal{A}}$ that determines the state $\mathcal{A}$. In general, we wouldn't be able to make this association between subregions of $S^1(y_i)$ and states of  $\mathcal{S}$  and $\mathcal{A}$ -- after all, $\mathcal{A}$ might not even exist. But we should be able to make this association if an appropriate choice for the state of the remainder of $S^1(y_i)$ is made. In (\ref{gammadecomp}), $\ket*{\Xi_i^{(S^1(y_i))}}$ is able to serve this role. We can then suppose that $\ket*{\gamma_i^{(\mathcal{S})}}$ is from a basis $\Lambda_{\mathcal{S}}=\{\ket*{\gamma_{i,1}^{(\mathcal{S})}},\ket*{\gamma_{i,2}^{(\mathcal{S})}},\ldots\}$ of states that describe all the states of the subregion $S_{\mathcal{S}}$ of $S^1(y_i)$ corresponding to $\mathcal{S}$ that together with $\ket*{\Xi_i^{(S^1(y_i))}}$ and $\ket*{\Psi_S}$ determine $\mathcal{S}$ to be in the state $\ket{s}$. We could then take the $\lambda$ of the system $\mathcal{S}$ in criterion \ref{hidden5} to be one of the basis states in $\Lambda_{\mathcal{S}}$. Given that the interpretation of the states in $\Lambda_{\mathcal{S}}$ presupposes $\ket*{\Xi_i^{(S^1(y_i))}}$, we would take the probability $p_\lambda$ for $\lambda = \ket*{\gamma_i^{(\mathcal{S})}}$ to be the probability that the notional measurement on $S$ given $\ket*{\Xi_i^{(S^1(y_i))}}$ and $\ket*{\Psi_S}$ agreed with the energy-density values specified by $ \ket*{\gamma_i^{(\mathcal{S})}}$ on the subregion $S_{\mathcal{S}}$ of $S^1(y_1)$ that $ \ket*{\gamma_i^{(\mathcal{S})}}$ describes. If we let $\{\ket*{Z_1}, \ket*{Z_2},\ldots  \}$ be a basis of simultaneous $\hat{T}_S$-eigenstates for the subregion $(S\setminus S^1(y_1))\cup S_{\mathcal{A}}$ so that states of the form $\ket*{\gamma_{i,l}^{(\mathcal{S})}}\ket*{\Xi_i^{(S^1(y_i))}}\ket*{Z_k}$ will be simultaneous $\hat{T}_S$-eigenstates for the whole of $S$, then the formula for the probability $p_\lambda$ will be 
\begin{equation}\label{plambda}
p_{\lambda}=\frac{\sum_k |\ip*{\Psi_S}{\gamma_i^{(\mathcal{S})}}\ket*{\Xi_i^{(S^1(y_i))}}\ket*{Z_k}|^2}{\sum_{k,l} |\ip*{\Psi_S}{\gamma_{i,l}^{(\mathcal{S})}}\ket*{\Xi_i^{(S^1(y_i))}}\ket*{Z_k}|^2}.
\end{equation}
We can then show that a version of EA analogous to (\ref{adeq}) on page \pageref{adeq} holds. To express EA in this context, we let
$O_{\mathcal{S}}$ be the observable that returns $j$ if the system $\mathcal{S}$ is measured to be in the state $\ket*{s_j}$, and for $\lambda = \ket*{\gamma_i^{(\mathcal{S})}}$, we let $P_\lambda^{\ket{s}}(O_{\mathcal{S}}=j)$ denote the probability that $O_{\mathcal{S}}=j$ given that the hypersurface is in state $\ket*{\Psi_S}$ before the notional energy-density measurement on $S$, and that this measurement result is only determined up to the state $\ket*{\gamma_i^{(\mathcal{S})}}\ket*{\Xi_i^{(S^1(y_i))}}$ on the subregion $S^1(y_1)\setminus S_{\mathcal{A}}$ which nevertheless ensures the system $\mathcal{S}$ is in the  state $\ket{s}$ before it interacts with the apparatus $\mathcal{A}$. Then to calculate $P_\lambda^{\ket{s}}(O_{\mathcal{S}}=j)$, we will need to sum over the probabilities that the notional energy density measurement has a $\ket*{\gamma_j'}$ component\footnote{To avoid undue complexity, we assume there is only one $\ket*{\gamma_j'}$-state for each $\ket*{a_j}$-state of the apparatus $\mathcal{A}$.} in its simultaneous $\hat{T}_S$-eigenstate for each state in the basis of states  $\{\ket*{Z_1'},\ket*{Z_2'},\ldots\}$ corresponding to the subregion $S\setminus(S^{1}(y_i)\cup S_{\mathcal{A}}')$. Accordingly, if we slightly redefine our notation by absorbing $\ket*{\gamma_i^{(\mathcal{A})}}$ into the $\ket*{\gamma_l'}$, we will find that   
$$P_\lambda^{\ket{s}}(O_{\mathcal{S}}=j)=\frac{\sum_k|\ip*{\Psi_S}{\gamma_i^{(\mathcal{S})}}\ket*{\Xi_i^{(S^1(y_i))}}\ket*{\gamma_j'}\ket*{Z_k'}|^2}{\sum_{k,l}|\ip*{\Psi_S}{\gamma_i^{(\mathcal{S})}}\ket*{\Xi_i^{(S^1(y_i))}}\ket*{\gamma_l'}\ket*{Z_k'}|^2}.$$ 
Also note that with this slight redefinition of $\ket*{\gamma_l'}$,  equation (\ref{PsiSdecomp}) becomes
$$\ket*{\Psi_S}=b\ket*{\gamma_i^{(\mathcal{S})}}\ket*{\Xi_i^{(S^1(y_i)}}\sum_lc_l\ket{\gamma_l'}\ket{\Xi_l}+\cdots.$$
We will therefore be able to express
$\ket*{\Xi_l}$ in terms of the basis $\{\ket*{Z_1'}, \ket*{Z_2'},\ldots  \}$ so that 
$$\ket{\Xi_l}= \sum_k d_{lk}\ket*{Z_k'}$$
with $\sum_{k}|d_{lk}|^2=1$ since we are assuming all states are normalized. Therefore
$$P_\lambda^{\ket{s}}(O_{\mathcal{S}}=j)=\frac{|b|^2|c_j|^2\sum_k |d_{jk}|^2}{|b|^2\sum_{k,l} |c_l|^2 |d_{lk}|^2}= |c_j|^2.$$
Therefore $$P_\lambda^{\ket{s}}(O_{\mathcal{S}}=j)=|\ip*{s}{s_j}|^2=P^{\ket{s}}(O_{\mathcal{S}}=j).$$ Moreover, since $\sum_\lambda p_\lambda =1$ we have 
$$\sum_\lambda p_\lambda P_\lambda^{\ket{s}}(O_{\mathcal{S}}=j)= P^{\ket{s}}(O_{\mathcal{S}}=j)$$
which is analogous to the EA formula on page \pageref{adeq}.


\section{Kent's Theory and Parameter Independence\label{kentpi}}
  In the previous section, we saw how we can generalize Kent's beable $\ev*{\hat{T}^{\mu\nu}(y)}_{\tau_S}$ to calculate conditional expectations $\ev*{\hat{O}}_{\tau_S}$ for any observable $\hat{O}$ defined at a particular spacetime location $(t_i, z_0)$, and that in the case of the observable $[s_f]=\dyad{s_f}$, this expectation yields the same probability as standard quantum mechanics for the outcome $\ket*{s_f}$ given the initial state $\ket{s}$ of the system.  We also saw that  EA holds in Kent's theory, and to see this, it was necessary to calculate the probability $P_\lambda^{\ket{s}}(O_{\mathcal{S}}=j)$ appropriately conditioned on the energy-density measurement determined on a subregion of $S$. 
  
  Now the expectation  $\ev*{[s_f]}_{\tau_S}$ and the probability $P_\lambda^{\ket{s}}(O_{\mathcal{S}}=j)$ depend on just one observable for just one spacetime location. However, in order to consider whether PI holds, we need to consider two observables corresponding to two different spacetime locations. In order to do this, we need to make a further adaption to Kent's theory. In this section, we will describe this adaption and show that with it, Kent's theory allows us to calculate probabilities for Bell-type experiments, and that these probabilities are the same as in standard quantum theory. Since PI holds in standard quantum theory,  a consequence of Kent's theory agreeing with standard quantum theory is that PI will also hold in Kent's theory.


So let's consider figure \ref{bellsolution} which depicts a one-dimensional view of a Bell-type experiment.
\begin{figure}[ht!]
	\captionsetup{justification=justified}
	\centering
	\tikzmath{
	\a=5.3;  
	\qa=5.3;  
	\ja=5.3;  
	\psione=-1;
	\jpsione=1;
	\qpsione=-1;
	\psitwo=1.5;
	\h=-1;
	\labelx=(\psione+\psitwo)/2;
	\labely=-1.5;
	\phstartx=-2.1;
	\offset=-\psione;
	\joffset=-\jpsione;
	\qphstartx=-3.8;
	\jphstartx=-3.8;
	\wphstartx=-1.8;
	\phstarty=\h;
	\tbeg=\phstarty;
	\ca=\phstartx-\tbeg;
	\ttwo=\psitwo-\ca;
	\cb=\ttwo+\ca;
	\xend=\ttwo-\a+\cb;
	\tone=\psione-\ca;
	\cc=\tone+\ca;
	\xendz=\tone-\a+\cc;
	\qca=\qphstartx-\tbeg;
	\qtone=\qpsione-\qca;
	\qqcc=\qtone+\qca;
	\qxendz=\qtone-\qa+\qqcc;
	\jca=\jphstartx-\tbeg;
	\jtone=\jpsione-\jca;
	\jqcc=\jtone+\jca;
	\jxendz=\jtone-\ja+\jqcc;
	\wa=5.3;  
	\wpsione=-1;
	\wttestx=3.7;
	\wca=\wphstartx-\tbeg;
	\wtone=\wpsione-\wca;
	\wwcc=\wtone+\wca;
	\wxendz=\wtone-\wa+\wwcc;
	\wat=\wa-\wttestx;
	\wct=\wttestx;
	\wlam = 0.87;
		\we=0.1;
	\tthree=\cc+\tone-\psitwo;
	\circsize=0.08;
	\md = (\a+\h)/2;
	\tlen=0.75;
	\textscale = 0.7;
	\picscale = 0.78;
	\nudge=0.1;
	\tnudge=(\ttwo-\tone)/2+0.8;
	\ttesta=2*\tone-\ttwo-\tnudge;
	\sonea=\a+\psione-\ttesta;
	\sadd=0.5;
	\lrange = 8.7;
	\rrange =\lrange; 
	\timex=\rrange-1.5;
	\ttestx=2.4;
	\at=\a-\ttestx;
	\ct=\ttestx;
	\qttestx=1.2;
	\qat=\qa-\qttestx;
	\qct=\qttestx;
	\qlam = 0.87;
	\jttestx=1.2;
	\jat=\ja-\jttestx;
	\jct=\jttestx;
	\jlam = 0.87;
	\lam = 0.87;
	\e = 0.1;
	\qe=0.1;
	\je=0.1;
	\hae=(2*pow(\at,3)*\lam*(2+\lam)+\e*\e*(2*\e-sqrt(4*\e*\e+\at*\at*\lam*\lam))-8*\at*\e*(-2*\e+sqrt(4*\e*\e+\at*\at*\lam*\lam))-2*\at*\at*(2+\lam)*(-2*\e+sqrt(4*\e*\e+\at*\at*\lam*\lam)))/(4*\at*\lam*(2*\at+2*\e-sqrt(4*\e*\e+\at*\at*\lam*\lam)))-(\e*\e/4+\at*\at*(-1+\lam))/(\at*\lam);
	\qhae=(2*pow(\qat,3)*\qlam*(2+\qlam)+\qe*\qe*(2*\qe-sqrt(4*\qe*\qe+\qat*\qat*\qlam*\qlam))-8*\qat*\qe*(-2*\qe+sqrt(4*\qe*\qe+\qat*\qat*\qlam*\qlam))-2*\qat*\qat*(2+\qlam)*(-2*\qe+sqrt(4*\qe*\qe+\qat*\qat*\qlam*\qlam)))/(4*\qat*\qlam*(2*\qat+2*\qe-sqrt(4*\qe*\qe+\qat*\qat*\qlam*\qlam)))-(\qe*\qe/4+\qat*\qat*(-1+\qlam))/(\qat*\qlam);
		\whae=(2*pow(\wat,3)*\wlam*(2+\wlam)+\we*\we*(2*\we-sqrt(4*\we*\we+\wat*\wat*\wlam*\wlam))-8*\wat*\we*(-2*\we+sqrt(4*\we*\we+\wat*\wat*\wlam*\wlam))-2*\wat*\wat*(2+\wlam)*(-2*\we+sqrt(4*\we*\we+\wat*\wat*\wlam*\wlam)))/(4*\wat*\wlam*(2*\wat+2*\we-sqrt(4*\we*\we+\wat*\wat*\wlam*\wlam)))-(\we*\we/4+\wat*\wat*(-1+\wlam))/(\wat*\wlam);
			\jhae=(2*pow(\jat,3)*\jlam*(2+\jlam)+\je*\je*(2*\je-sqrt(4*\je*\je+\jat*\jat*\jlam*\jlam))-8*\jat*\je*(-2*\je+sqrt(4*\je*\je+\jat*\jat*\jlam*\jlam))-2*\jat*\jat*(2+\jlam)*(-2*\je+sqrt(4*\je*\je+\jat*\jat*\jlam*\jlam)))/(4*\jat*\jlam*(2*\jat+2*\je-sqrt(4*\je*\je+\jat*\jat*\jlam*\jlam)))-(\je*\je/4+\jat*\jat*(-1+\jlam))/(\jat*\jlam);
	} 
	\tikzstyle{scorestars}=[star, star points=5, star point ratio=2.25, draw, inner sep=1pt]%
	\tikzstyle{scoresquare}=[draw, rectangle, minimum size=1mm,inner sep=0pt,outer sep=0pt]%
	\begin{tikzpicture}[scale=\picscale,
	declare function={
		testxonep(\ps,\t)=\a+\ps-\t;
		testxonem(\ps,\t)=\ps-\a+\t; 
		bl(\x)=\ct+\at-\e/2-1/2*(sqrt(\lam*\lam*pow(\x+\hae+\at,2)+\e*\e)-\e+\lam*(\x+\hae+\at));
		br(\x)=\ct+\at-\e/2-1/2*(sqrt(\lam*\lam*pow(\x-\hae-\at,2)+\e*\e)-\e-\lam*(\x-\hae-\at));
		bc(\x)=\ct+sqrt(\lam*\lam*\x*\x+\e*\e)-\e;
		qbl(\qx)=\qct+\qat-\qe/2-1/2*(sqrt(\qlam*\qlam*pow(\qx+\qhae+\qat,2)+\qe*\qe)-\qe+\qlam*(\qx+\qhae+\qat));
		qbr(\qx)=\qct+\qat-\qe/2-1/2*(sqrt(\qlam*\qlam*pow(\qx-\qhae-\qat,2)+\qe*\qe)-\qe-\qlam*(\qx-\qhae-\qat));
		qbc(\qx)=\qct+sqrt(\qlam*\qlam*\qx*\qx+\qe*\qe)-\qe;
		wbl(\wx)=\wct+\wat-\we/2-1/2*(sqrt(\wlam*\wlam*pow(\wx+\whae+\wat,2)+\we*\we)-\we+\wlam*(\wx+\whae+\wat));
		wbr(\wx)=\wct+\wat-\we/2-1/2*(sqrt(\wlam*\wlam*pow(\wx-\whae-\wat,2)+\we*\we)-\we-\wlam*(\wx-\whae-\wat));
		wbc(\wx)=\wct+sqrt(\wlam*\wlam*\wx*\wx+\we*\we)-\we;
		jbl(\jx)=\jct+\jat-\je/2-1/2*(sqrt(\jlam*\jlam*pow(\jx+\jhae+\jat,2)+\je*\je)-\je+\jlam*(\jx+\jhae+\jat));
		jbr(\jx)=\jct+\jat-\je/2-1/2*(sqrt(\jlam*\jlam*pow(\jx-\jhae-\jat,2)+\je*\je)-\je-\jlam*(\jx-\jhae-\jat));
		jbc(\jx)=\jct+sqrt(\jlam*\jlam*\jx*\jx+\je*\je)-\je;
		rr(\x)=2*(pow(\x,4)/4-pow(\offset*\x,2)/2+pow(\offset,4)/4)+\qttestx;
	},
	 ] 
	\definecolor{tempcolor}{RGB}{250,190,0}
	\definecolor{darkgreen}{RGB}{40,190,40}
	

	
	 
	 \draw[->,gray, thick] [domain=-\at/2-\offset:-\lrange, samples=150]   plot (\x, {qbl(\x+\offset)})  ;
	\draw[gray, thick] [domain=-\at/2-\offset:0-\offset, samples=150] plot (\x, {qbc(\x+\offset)})   ;
%	\draw[->,gray, thick] [domain=\at/2-\offset:\rrange, samples=150]   plot (\x, {qbr(\x+\offset)})   ;
	\draw[gray, thick] [domain=-\offset:-\joffset, samples=150] plot (\x, {\qttestx})   ;
	\draw[gray, thick, densely dashed] [domain=-\offset:-\joffset, samples=150] plot (\x, {rr(\x)})   ;
	
	
	 \draw[->,blue, thick] [domain=-\at/2-\offset:-\lrange, samples=150]   plot (\x, {wbl(\x+\offset)})  ;
	 \draw[blue, thick] [domain=-\at/2-\offset:0-\offset, samples=150] plot (\x, {wbc(\x+\offset)})   ;
	 \draw[blue, thick] [domain=-\offset:-\joffset, samples=150] plot (\x, {\wttestx})   ;
	 \draw[blue, thick, densely dashed] [domain=-\offset:-\joffset, samples=150] plot (\x, {rr(\x)+\wttestx-\qttestx})   ;
	 
	 \draw[->,blue, thick] [domain=\at/2+\offset:\lrange, samples=150]   plot (\x, {wbl(-\x+\offset)})  ;
	\draw[blue, thick] [domain=\at/2+\offset:\offset, samples=150] plot (\x, {wbc(-\x+\offset)})   ;

 %   \draw[->,gray, thick] [domain=-\at/2-\joffset:-\lrange, samples=150]   plot (\x, {jbl(\x+\joffset)})  ;
	\draw[gray, thick] [domain=-\joffset:\at/2-\joffset, samples=150] plot (\x, {jbc(\x+\joffset)})   ;
	\draw[->,gray, thick] [domain=\at/2-\joffset:\rrange, samples=150]   plot (\x, {jbr(\x+\joffset)})   ;

	  \node[scale=\textscale]  at (0,\qttestx-0.23) {$S_{n,i}$}; 
	  \node[scale=\textscale]  at (0,\wttestx-0.23) {$S_{n,m}$}; 

	
	\draw[<->] (-\lrange, \h) node[left, scale=\textscale] {$S_0$} -- (\rrange, \h) node[right, scale=\textscale] {$S_0$};
	\draw[<->] (-\lrange, \a) node[left, scale=\textscale] {$S$} -- (\rrange, \a) node[right, scale=\textscale] {$S$};
				  
	\draw[->, shorten <= 5pt,  shorten >= 1pt] (\psione,\h)  node[above right, scale=\textscale]{$z_L$}-- (\psione,\a) ;
	\draw[->, shorten <= 5pt,  shorten >= 1pt] (\jpsione,\h)  node[above right, scale=\textscale]{$z_R$}-- (\jpsione,\a) ;
	
	
	\draw[dashed, tempcolor,  ultra thick](\phstartx,\tbeg) node[below left=-2,scale=\textscale]{}--(\psione,\tone) node[above, pos=0.3, rotate=45,scale=0.7,black] {} node[below, pos=0.3, rotate=45,scale=0.7,black] {};
	\draw[dashed, tempcolor,  ultra thick](\psione,\tone)--(\xendz,\a);
	
		\draw[dashed, tempcolor,  ultra thick](\qphstartx,\tbeg) node[below left=-2,scale=\textscale]{}--(\psione,\qtone) node[above, pos=0.3, rotate=45,scale=0.7,black] {} node[below, pos=0.3, rotate=45,scale=0.7,black] {};
	\draw[dashed, tempcolor,  ultra thick](\psione,\qtone)--(\qxendz,\a);
	
			\draw[dashed, tempcolor,  ultra thick](-\qphstartx,\tbeg) node[below left=-2,scale=\textscale]{}--(-\psione,\qtone) node[above, pos=0.3, rotate=45,scale=0.7,black] {} node[below, pos=0.3, rotate=45,scale=0.7,black] {};
	\draw[dashed, tempcolor,  ultra thick](-\psione,\qtone)--(-\qxendz,\a);
	
		\draw[dashed, tempcolor,  ultra thick](-\phstartx,\tbeg) node[below left=-2,scale=\textscale]{}--(-\psione,\tone) node[above, pos=0.3, rotate=45,scale=0.7,black] {} node[below, pos=0.3, rotate=45,scale=0.7,black] {};
	\draw[dashed, tempcolor,  ultra thick](\jpsione,\tone)--(-\xendz,\a);



	
	\draw[->] (\timex,\md-\tlen/2) --  (\timex,\md+\tlen/2) node[midway,right, scale=\textscale]{time}; 
	 

	\draw[dotted](\psione,\qttestx)--({testxonep(\psione,\qttestx)},\a);
	\draw[dotted](\psione,\qttestx)--({testxonem(\psione,\qttestx)},\a);
	\draw[dotted](\jpsione,\jttestx)--({testxonep(\jpsione,\jttestx)},\a);
	\draw[dotted](\jpsione,\jttestx)--({testxonem(\jpsione,\jttestx)},\a);

	\draw (\psione,\qttestx) node[ scoresquare, fill=gray]  {} node [black,below=6,right,scale=\textscale] {$t_i$};
    \draw (\jpsione,\jttestx) node[ scoresquare, fill=gray]  {} node [black,below=6,right,scale=\textscale] {$t_i$};
\draw (\psione,\wttestx) node[ scoresquare, fill=gray]  {} node [black,below=6,right,scale=\textscale] {$t_m$};
    \draw (\jpsione,\wttestx) node[ scoresquare, fill=gray]  {} node [black,below=6,right,scale=\textscale] {$t_m$};



	
	\draw [black,fill](\xendz,\a) circle [radius=\circsize] node [black,above=9,right=-4,scale=\textscale] {$\gamma_i^{(\mathcal{A}_L)}$}; 
	\draw [black,fill](-\xendz,\a) circle [radius=\circsize] node [black,above=9,right=-4,scale=\textscale] {$\gamma_i^{(\mathcal{A}_R)}$}; 
	\draw [black,fill](\qxendz,\a) circle [radius=\circsize] node [black,above=9,right=-4,scale=\textscale] {$\gamma_{m,+}^{(\mathcal{A}_L)}$}; 
	\draw [black,fill](-\qxendz,\a) circle [radius=\circsize] node [black,above=9,right=-4,scale=\textscale] {$\gamma_{m,+}^{(\mathcal{A}_R)}$}; 
	
	%\draw [black,fill] (\xendz,\a) circle [radius=\circsize] node [black,above,scale=\textscale] {$\gamma_L$}; 
	\end{tikzpicture}% pic 1
	
	\vspace*{2px}
	\caption{Depicts a Bell-type experiment where the state of some photons $\gamma_i^{(\mathcal{A}_L)}$ and $\gamma_i^{(\mathcal{A}_R)}$ on the spacelike hypersurface $S$ determines the choice of measurement parameters of the left wing and right wing of the experiment respectively, and some photons $\gamma_{m,+}^{(\mathcal{A}_L)}$ and $\gamma_{m,+}^{(\mathcal{A}_R)}$ on the spacelike hypersurface $S$ determine the measurement outcome of the experiment on the left wing and the right wing respectively. The dashed lines on the spacelike hypersurfaces $S_{n,m}$ and $S_{n,i}$ indicate other choices for the spacelike hypersurfaces, but they still lead to the same probability being calculated.   }
	\label{bellsolution}
	\end{figure}
There is a left wing of the experiment located in the vicinity of $z_L$, and a right wing of the experiment located in the vicinity of $z_R$. Shortly before time $t_i$, photons interact with a Stern-Gerlach apparatus on the left wing and a Stern-Gerlach apparatus on the right wing, and some of these photons eventually intersect the spacelike hypersurface $S$ so that there are subregions $S_{\mathcal{A}_L}$ and $S_{\mathcal{A}_R}$ of $S$ such that if the notional measurement of the mass-energy density corresponds to simultaneous $\hat{T}_S$-eigenstates $\ket*{\gamma_i^{(\mathcal{A}_L)}}$ and $\ket*{\gamma_i^{(\mathcal{A}_R)}}$ respectively on these subregions, then this will be sufficient to determine the measurement parameters of the apparatuses on the left wing and the right wing of the experiment respectively. 

Now in order to consider whether PI holds, we will need to adapt Kent's sequences of spacelike hypersurfaces so that they can be used to calculate conditional expectation values for observables that depend on two spacetime locations $y_L=(t_i, z_L)$ and $y_R=(t_i,z_R)$.  We therefore require that sequences of spacelike hypersurfaces $S_{n,i}$ are chosen so that they all contain the spacetime locations $y_L$ and $y_R$, and that in the limit, $\lim_{n\rightarrow\infty}S_{n,i}$ contains as much of $S^1(y_L)$ and $S^1(y_R)$ as possible, where as usual, $S^1(y)$ denotes the subset of $S$ lying outside the light cone of $y$. Ultimately, this limit (unlike the limit of Kent's spacelike hypersurfaces) will not contain the whole of $S^1(y_L)$ or $S^1(y_R)$, but only serves to guarantee that we use as much of the information in $S$ as possible in calculating the expectation values of observables at $y_L$ and $y_R$. There will be some degree of freedom in what we choose for the spacelike hypersurface between $y_L$ and $y_R$ as depicted by the dashed line in figure \ref{bellsolution}. However, such freedom will have no effect on the probabilities calculated, because under the assumption that the spacelike hypersurface is very far into the future, there will be no choice of spacelike hypersurface in this region that would give us more information in $S$ to condition on. Also, we recall that the stress-energy operators of the form $\hat{T}^{\mu\nu}(y)$ in the Tomonaga-Schwinger formulation of relativistic quantum physics are defined so that they are invariant under any perturbation of the spacelike hypersurface (so long as the hypersurface continues to contain $y$), so under the assumption that all physical observables will be ultimately expressible in terms of the stress-energy operators, the arbitrary choice of the spacelike hypersurfaces in regions that can't intersect with $S$ will have no effect of the probabilities calculated. 

On the spacelike hypersurface $S_{n,i}$, we assume that $n$ is sufficiently large that enough of the subregions $S_{\mathcal{A}_L}$ and $S_{\mathcal{A}_R}$ are contained within $S_{n,i}$ so that the simultaneous $\hat{T}_S$-eigenstates $\ket*{\gamma_i^{(\mathcal{A}_L)}}$ and $\ket*{\gamma_i^{(\mathcal{A}_R)}}$ restricted to $S_{\mathcal{A}_L}\cap S_{n,i}$ and $S_{\mathcal{A}_R}\cap S_{n,i}$ are still able to determine the choice of measurement axes for the left and right wings of the experiment respectively. In order to avoid introducing too much extra notation, we will shrink the subregions $S_{\mathcal{A_L}}$ and $S_{\mathcal{A_R}}$ so that they are contained within $S_{n,i}$ for sufficiently large $n$, but we only shrink them slightly so that the mass-energy density measurement on them is still sufficient to determine the choice of measurement axes for the left and right wings of the experiment.\footnote{For more realistic models, we wouldn't expect the mass-energy density measurement on $S_{n,i}$ to determine the choice of measurement axes with 100\% certainty, since there will be a degree of overlap of the different $\ket*{\gamma_i^{(\mathcal{A}_L)}}$ for different measurement choices (and likewise for the different $\ket*{\gamma_i^{(\mathcal{A}_R)}}$). But this overlap will get smaller and smaller the more that photons interacting with the apparatus intersect $S_{n,i}$, and so the certainty of which measurement is being made will approach 100\% as long as there is sufficient enough time from the time the measurement parameters are chosen to time $t_i$ and as long as $n$ is large enough so that there are enough photon interactions with the apparatus that intersect $S_{n,i}$. Nevertheless, the fact that we never reach 100\% certainty should not worry us too much in the context of Kent's theory, since it just means that Kent's $\ev*{\hat{T}^{\mu\nu}(y)}_{\tau_S}$-beables will be perturbed by a very small amount in the vicinity of the apparatus caused by the very small amount of overlap between the the different $\ket*{\gamma_i^{(\mathcal{A}_L)}}$ for different measurement choices. }   

Let us now assume that the axis of orientation of the right wing Stern-Gerlach apparatus makes an angle $\theta$ with the axis of the left wing apparatus. We also assume that there are two particles that together form a Bell-state \begin{equation}\label{bellstatePI}
	\frac{1}{\sqrt{2}}(\ket*{\uvbp{s}}_L\ket*{\uvbm{s}}_R-\ket*{\uvbm{s}}_L\ket*{\uvbp{s}}_R).
\end{equation}
We saw  in footnote \ref{bellstate2pf} on page \pageref{bellstate2pf} that a Bell state does not depend on the orientation of $\uvb{s}$, so without loss of generality, we can suppose that the $\ket*{\uvbp{s}}_L$ and $\ket*{\uvbm{s}}_L$ are pointer states for the apparatus on the left-wing of the experiment. This means there will be a ready state $\ket{a}_L$  as well as two states $\ket{a+}_L$ and $\ket{a-}_L$ of the left wing apparatus such that 
$$\ket*{\uvbpm{s}}_L\ket{a}_L\rightarrow\ket*{\uvbpm{s}}_L\ket{a\pm}_L.$$

As for the right wing of the experiment, we let  $\ket*{\bm{\hat{s}_\theta+}}_R$ and $\ket*{\bm{\hat{s}_\theta-}}_R$ be pointer states for the apparatus so that there is a ready state $\ket{a}_R$  as well as two states $\ket{a_\theta+}_R$ and $\ket{a_\theta-}_R$ of the right wing apparatus such that 
$$\ket*{\bm{\hat{s}}_\theta\pm}_R\ket{a}_R\rightarrow\ket*{\bm{\hat{s}}_\theta\pm}_R\ket{a_\theta\pm}_R.$$
In a manner similar to equation (\ref{Psinidecomp}), we can express $\ket*{\Psi_{n,i}}=U_{S_{n,i},S_0}\ket*{\Psi_0}$ as a superposition
\begin{equation}\label{bellstatePI2}
	\ket{\Psi_{n,i}}= \frac{b}{\sqrt{2}}\big(\ket*{\uvbp{s}}_L\ket*{\uvbm{s}}_R-\ket*{\uvbm{s}}_L\ket*{\uvbp{s}}_R\big)\ket{a}_L\ket{a}_R\ket*{\gamma_i^{(\mathcal{A}_L)}}\ket*{\gamma_i^{(\mathcal{A}_R)}}\ket*{\xi_{n,i}}+\cdots.
\end{equation}
where $\ket*{\xi_{n,i}}$ corresponds to the state of the subregion of $S_{n,i}$ not determined by $\ket*{\uvbpm{s}}_L\ket*{\uvbmp{s}}_R$, $\ket{a}_L$, $\ket{a}_R$, $\ket*{\gamma_i^{(\mathcal{A}_L)}}$ or $\ket*{\gamma_i^{(\mathcal{A}_R)}}$.
As in equations (\ref{spintrans1}) and (\ref{spintrans2}), we have
\begin{align*}
\ket*{\uvbp{s}}_R&= \alpha_\theta\ket*{\bm{\hat{s}_\theta+}}_R+\beta_\theta \ket*{\bm{\hat{s}_\theta-}}_R,\\
\ket*{\uvbm{s}}_R&= \alpha_\theta\ket*{\bm{\hat{s}_\theta-}}_R-\beta_\theta \ket*{\bm{\hat{s}_\theta+}}_R,
\end{align*}
where $\alpha_\theta=\cos(\theta/2)$, and $\beta_\theta=\sin(\theta/2).$
Substituting this into (\ref{bellstatePI2}), we can express the state of the spacelike hypersurface $S_{n,i}$ that goes through the two particles at spacetime locations $y_L$ and $y_R$ as
\begin{equation}\label{bellstatePI3}
	\begin{split}
	\ket{\Psi_{n,i}}&=\frac{b}{\sqrt{2}}\big(\alpha_\theta\ket*{\uvbp{s}}_L\ket*{\bm{\hat{s}_\theta-}}_R
	-\beta_\theta\ket*{\uvbp{s}}_L\ket*{\bm{\hat{s}_\theta+}}_R-\alpha_\theta\ket*{\uvbm{s}}_L\ket*{\bm{\hat{s}_\theta+}}_R\\
	&\quad
	-\beta_\theta\ket*{\uvbm{s}}_L\ket*{\bm{\hat{s}_\theta-}}_R\big)\ket{a}_L\ket{a}_R\ket*{\gamma_i^{(\mathcal{A}_L)}}\ket*{\gamma_i^{(\mathcal{A}_R)}}\ket*{\xi_{n,i}}+\cdots.
	\end{split}
\end{equation}
We now let $\pi_{n,i}$ be the projection as defined in equation \ref{tauprojection} that corresponds to the measurement outcome $\tau_S(x)$ on $S_{n,i}\cap S$. If we apply $\pi_{n,i}$ to $\ket*{\Psi_{n,i}}$ as we did in (\ref{piphi}) then we will get the approximation
\begin{equation}\label{piphiPI}
	\begin{split}
		\pi_{n,i}\ket{\Psi_{n,i}}&\approx\frac{b}{\sqrt{2}}\big(\alpha_\theta\ket*{\uvbp{s}}_L\ket*{\bm{\hat{s}_\theta-}}_R
		-\beta_\theta\ket*{\uvbp{s}}_L\ket*{\bm{\hat{s}_\theta+}}_R-\alpha_\theta\ket*{\uvbm{s}}_L\ket*{\bm{\hat{s}_\theta+}}_R\\
		&\quad
		-\beta_\theta\ket*{\uvbm{s}}_L\ket*{\bm{\hat{s}_\theta-}}_R\big)\ket{a}_L\ket{a}_R\ket*{\gamma_i^{(\mathcal{A}_L)}}\ket*{\gamma_i^{(\mathcal{A}_R)}}\ket*{\xi_{n,i}},
		\end{split}
\end{equation}
and the larger $n$ is, the closer (\ref{piphiPI}) will come to being an equality, though in the case of our toy model where we treat photons as point particles, we can expect (\ref{piphiPI}) to become an equality for sufficiently large $n$.



Now in the previous section, we calculated Kent's conditional expectation value of $[s_f]$ and argued that this would give the probability that the measurement outcome of the system $\mathcal{S}$ would be $\ket*{s_f}$ given a particular mass-energy density measurement on $S^1(y_i)$. In the situation at hand in which we wish to know the probability of two measurements, we need to consider conditional expectation values of observables such as  $[\bm{\hat{s}+}]_L[\bm{\hat{s}_\theta+}]_R$ where the observable $[\uvbp{s}]_L=\ket{\uvbp{s}}_L\prescript{}{L}{\bra{\uvbp{s}}}$ depends on spacetime location $y_L$, and where the observable $[\bm{\hat{s}_\theta+}]_R=\ket{\bm{\hat{s}_\theta+}}_R\prescript{}{R}{\bra{\bm{\hat{s}_\theta+}}}$ depends on spacetime location $y_R.$ Since we are choosing the sequence of spacelike hypersurfaces $S_{n,i}$ so that both $y_L$ and $y_R$ belong to $S_{n,i}$, and since any two observables for locations that are spacelike separated commute, we can easily see what the eigenvalues for  $[\bm{\hat{s}+}]_L[\bm{\hat{s}_\theta+}]_R$ must be: they are 1 and 0, where the eigenvalue of $1$ corresponds to all the states of $S_{n,i}$ in which the particle about to be measured by the left wing apparatus is in the $\ket*{\bm{\hat{s}+}}_L$-state and in which the particle about to be measured by the right wing apparatus is in the $\ket*{\bm{\hat{s}_\theta+}}_R$-state, and where the eigenvalue of $0$ corresponds to all the states of $S_{n,i}$ in which either the particle about to be measured by the left wing apparatus is in a pointer state of the apparatus that is not the $\ket*{\bm{\hat{s}+}}_L$-state or the particle about to be measured by the right wing apparatus is a poitner state of the apparatus that is not the $\ket*{\bm{\hat{s}_\theta+}}_R$-state. It therefore follows from the definition of expectation that given the mass-energy density measurement on the subregion $S_{\mathcal{A}_L}$ is $\ket*{\gamma_i^{(\mathcal{A}_L)}}$ and the mass-energy density measurement on the subregion $S_{\mathcal{A}_R}$ is $\ket*{\gamma_i^{(\mathcal{A}_R)}}$, the probability that the left wing will be measured to be in state  $\ket*{\bm{\hat{s}+}}_L$ and that the right wing will be measured to be in $\ket*{\bm{\hat{s}_\theta+}}_R$ will be
\begin{equation}\label{slsrev}
	\begin{split}
	\ev*{[\bm{\hat{s}+}]_L[\bm{\hat{s}_\theta+}]_R}_{\tau_S}
	&=\lim_{n\rightarrow\infty}\frac{\ev*{\pi_{n,i}[\bm{\hat{s}+}]_L[\bm{\hat{s}_\theta+}]_R}{\Psi_{n,i}}}{\ev*{\pi_{n,i}}{\Psi_{n,i}}}\\
	&=\frac{\prescript{}{R}{\bra*{\bm{\hat{s}_\theta+}}}\prescript{}{L}{}\ev*{\overline{\frac{b}{\sqrt{2}}\beta_{\theta}}[\bm{\hat{s}+}]\prescript{}{L}{}[\bm{\hat{s}_\theta+}]\prescript{}{R}{}\frac{b}{\sqrt{2}}\beta_{\theta}}{\hat{s}+}_L\ket*{\bm{\hat{s}_\theta+}}_R}{|b|^2}\\
	&=\frac{|\beta_\theta|^2}{2}=\frac{1}{2}\sin^2(\theta/2),
	\end{split}	
\end{equation}
where we have used (\ref{piphiPI}), and this is the same as the probability that standard quantum mechanics predicts as given in equation (\ref{bellsin}). We therefore see that the mass-energy density measurement on $S$ allows us to determine the state of the particles and the apparatus before the particles are measured in an EPR-Bohm type experiement, but the adaption I've made to Kent's model so that it can compute probabilities of the measurement outcomes of this experiement produces the same probabilities as standard quanutm mechanics, and since PI hold's in standard quantum mechanics, it must also hold Kent's adapted model as well.\label{kentpiend}



\section{Beables and Time}
In previous sections I've tried to show that Kent's theory is a one world theory which makes the same predictions as standard quantum mechanics and is consistent with special relatively (subject to a minor alteration which allows us to attribute PI to Kent's theory). There are however a number of issues that might still make people reluctant to take Kent's theory seriously. For instance, it may strike many people as wildly speculative to suggest that the current state of reality is specified in terms of expectation values of stress-momentum operators conditioned on some fictional measurement made in the far distant future. Also, many people, myself included, do not find determinism philosophically attractive, yet on the face of it, Kent's theory does seem to be deterministic. It also looks like Kent's theory relies on there being backwards in time causality, an idea which to many people will seem just as absurd as the many worlds interpretation. In this final section, I will discuss these concerns and how they might be addressed.

To begin, with let's consider the criticism that Kent's theory is too wildly speculative for anyone to take seriously. In response to this criticism, I think the best way to see Kent's theory is not as a claim of how physical reality must be, but more like a thought experiment that opens up the logical space of how physical reality might be if one accepts special relativity and standard quantum mechanics. For instance, the Colbeck-Renner theorem might lead one to conclude that there are no interesting hidden variables theories that make the same predictions as quantum theory and satisfy PI. However, as I've tried to show in section \ref{colbeckrennerthm}, the information additional to the quantum state that is contained in a distant future mass-energy density measurement is not constrained by the underlying assumptions of Colbeck, Renner, et al., and hence their conclusion about the redundancy of hidden variables does not apply to Kent's theory. 

Another assumption that is often made about hidden variables theories, but which Kent's theory calls into question is the assumption that a hidden variables theory requires there to be new laws of physics beyond standard quantum mechanics.  Maudlin prefers to speak of \emph{additional variables theories}\index{additional variables theories} rather than of hidden variables theories: an addionional variables theory is a theory in which there is more to physical reality than a single quantum state describing the universe. However, Maudlin goes on to claim that if one adopts  an additional variables theory, one must not only specify what the additional variables are, but one must also state the laws governing them.\footnote{see \cite[9]{MAUDLINT1995Tmp} } It is as though Maudlin can only imagine the additional variables to be dynamical quantities like particle positions that need laws of motion to describe how they evolve overtime. Now Kent's theory is an additional variables theory according to Maudlin's criterion. However, just because Kent's theory is an additional variable theory, it doesn't follow that Kent is proposing some radically new physical theory which specifies new laws of motion: standard quantum physics will do. Thus, Kent's theory does need the Born Rule in order to specify the probability with which the mass-energy density measurement $\tau_S$ is selected on the distant future spacelike hypersurface $S$, but the Born Rule is just a part of standard quantum physics. However, no new physics is required to describe the additional variables (i.e. the values of $\tau_S$ over $S$)  of Kent's theory since the mass-energy density over $S$ has just as much right to be described by a quantum state as the initial state  of the universe $\ket*{\Psi_0}$ has. Also, once the mass-energy density $\tau_S$ on the hypersurface $S$ has been selected, $\tau_S$ doesn't change, and so it makes no sense to ask by what laws the mass-energy density evolves on this hypersurface. So insofar as Kent's additional variables don't require any new physics to describe them, his theory is far less speculative than many other extensions to standard quantum mechanics. 

Nevertheless, the manner in which one might use the additional variables of Kent's theory is something one could speculate about, and it is far from obvious that Kent's proposal is the only way or the most natural way of using these additional variables. In other words, it is not obvious that expectation values of stress-energy tensors conditioned on a future mass-energy density measurement is the most natural choice of beables determining the state of physical reality.  

As mentioned on page \pageref{beabledef}, Bell introduced the term beable due to his dissatisfaction with standard quantum physics which is only a theory of observables -- a satisfactory theory shouldn't just tell us how a physical system appears to be, but it should also tell us how the physical system actually is. In other words, a satisfactory physical theory should describe beables which encapsulate the physical system's state of actuality and which can account for why a system appears to be the way it is. 

Now in Kent's theory, there are two kinds of beables. Firstly, there are the beables corresponding to the mass-energy density measurement on $S$. The mass-energy density measurement $\tau_S$ tells is how each spacetime location of $S$ actually is. Secondly, there are the beables for all the spacetime locations prior to $S$. According to Kent, for a spacetime location $y$ prior to $S$, the conditional expectation value  $\ev*{\hat{T}^{\mu\nu}(y)}_{\tau_S}$ for all the different combinations of $\mu$ and $\nu$ tells us how the state of physical reality at spacetime location $y$ actually is. 

Now it seems that one can accept the first kind of beable in Kent's theory without accepting the second kind. In some situations, the definite values of $\tau_S(x)$ on $S$ will give rise to $\hat{T}^{\mu\nu}(y)$-eigenstates at $y$, in which case the conditional expectation $\ev*{\hat{T}^{\mu\nu}(y)}_{\tau_S}$ will be identical to a definite value for $T^{\mu\nu}(y)$ as normally understood in standard quantum theory. But there will inevitably be situations in which the definite values of $\tau_S(x)$ on $S$ will not give rise to  $\hat{T}^{\mu\nu}(y)$-eigenstates at $y$. In other words, in the notation defined in section \ref{LorentzInvarianceSection} on page \pageref{tauprojection}, we will inevitably find that the state $\pi_n\ket{\Psi_n}$ at $y$ is in a superposition of eigenstates of $\hat{T}^{\mu\nu}(y)$ for some choice of $\mu$ and $\nu$. But in that case, it seems rather dubious to claim that the expectation value $\ev*{\hat{T}^{\mu\nu}(y)}_{\tau_S}$ is the true state of reality and hence the beable at $y$. As an analogy, it seems a bit like saying that if the throw of a six-sided dice was described quantum mechanically, then the dice could yield a beable of 3.5 for its outcome since 3.5 is the expectation value for the throw of a six-sided dice. In Kent's theory, there would of course nearly always be sufficient information in $\tau_S$ on the spacelike hypersurface $S$  to determine that a real dice yielded an integer outcome between 1 and 6.  But it is still the case that the information in $\tau_S$ outside the light cone of $y$ will be insufficient to determine all possible measurable quantities at $y$ to have definite values, and so it seems unnecessary to insist that Kent's expectation values of all the observables corresponding to these measurable quantities give the state of physical reality at $y$. 

It might be more reasonable just to say that there is no fact of the matter about the definite value of some measurable quantities in cases where the information in $\tau_S$ is insufficient to determine them.  In the context of Kent's theory, one could still suppose that there were beables corresponding to the mass-energy density $\tau_S(x)$ on $S$, and that some definite facts about physical reality flowed from the definite facts about $S$. But there could also be degrees of indefiniteness about physical reality. This would occur whenever the information in $\tau_S(x)$ was insufficient to determine whether the state $\pi_n\ket{\Psi_n}$ was an eigenstate of some observable. If light were to interact with the location $y$ in a different way, then this might be able to settle the question of which eigenstate $\pi_n\ket{\Psi_n}$ was in, but this definite outcome would then result in $y$ being indefinite with respect to other observables. But even though there would inevitably be many physical quantities of a system that lacked definiteness, we could typically expect the state $\pi_n\ket{\Psi_n}$ to be very nearly an eigenstate for these indefinite physical quantities. For instance, there might be real numbers $t^{\mu\nu}(y)$ for all $\mu, \nu$ such that 
\begin{equation}\label{tapproxmunuy}
\hat{T}^{\mu\nu}(y)\pi_n\ket{\Psi_n}\approx t^{\mu\nu}(y)\pi_n\ket{\Psi_n}.
\end{equation}
For some values of $\mu$ and $\nu$, we might even obtain equality in (\ref{tapproxmunuy}), but it is not going to be possible to obtain equality in (\ref{tapproxmunuy}) for every value of $\mu$ and $\nu$ -- there must be cases in which $\hat{T}^{\mu\nu}(y)\pi_n\ket{\Psi_n}$ and $t^{\mu\nu}(y)\pi_n\ket{\Psi_n}$ are not quite parallel, for otherwise all the $\hat{T}^{\mu\nu}(y)$  acting on $\pi_n\ket{\Psi_n}$ would commute, and this is not possible. 

The suggestion that there are degrees of indefiniteness to measurable quantities is not going to appeal to everyone, especially people who are seeking a perfect mathematical account of physical reality. But in a context in which we use the information of $\tau_S$ to calculate the state $\pi_n\ket{\Psi_n}$ of a hypersurface $S_n$, the degrees of indefiniteness are going to be very small, so for instance, we don't need to worry about whether a cat could be in a superposition of dead and alive states. The values of $t^{\mu\nu}(y)$ in the vicinity of a cat for which (\ref{tapproxmunuy}) is a very good approximation are going to correspond either to the cat being dead or the cat being alive -- these values won't correspond to the cat being both dead and alive.

Now if one is unwilling to accept Kent's proposal that the expectation values $\ev*{\hat{T}^{\mu\nu}(y)}_{\tau_S}$ are beables, there is still the question of whether there are any better alternatives. In answering this question, we can perhaps draw inspiration from Maudlin's views on entanglement where he says ``The physical state of a complex whole cannot always be reduced to those of its parts, or to those of its parts together with their spatiotemporal relations \ldots. The result of the most intensive scientific investigations in history is a theory that contains an ineliminable holism.''\footnote{See \cite[56]{Maudlin2}.}  

With a view to defending monism, Schaffer also argues that entangled systems constitute irreducible wholes.\footnote{See \cite{SchafferJonathan2010MTPo}.} Schaffer's arguement relies on the principle that ``the basic entities must be \emph{complete}\index{completeness of basic entities}, in the sense of providing a blueprint for reality. More precisely, a plurality of entities is complete if and only if duplicating all these entities, while preserving their fundamental relations, metaphysically suffices to duplicate the cosmos and its contents.''\footnote{\cite[39]{SchafferJonathan2010MTPo}} In the case of entangled systems, duplicating the particles of the system and their spatiotemperal relations will not be sufficient to duplicate the system and its content. Supplementing the particles with entanglement relations doesn't help either in our efforts to duplicate the system. This is because an entangled system will typically have intrinsic properties such as spin which are independent of the number of particles in a system. For instance, both a complex system like a silver atom and a simple system like an electron have an identical spin of 1/2. But if the spin of an entangled system is a certain kind of entanglement relation between the system's component parts, then it wouldn't be possible to say that a complex system and a simple system had the same spin. Schaffer thus concludes that an entangled system is a fundamental unit, and that the basic entities in any complete description of the cosmos cannot be components of entangled systems.\footnote{\cite[54]{SchafferJonathan2010MTPo}}  

Schaffer also argues that in the absence of any principle that promotes disentanglement, there will only be one entangled system for the whole cosmos. This is because according to our current understanding of physics, the universe began with a Big Bang which would have resulted in every component of the universe getting entangled with every other component.\footnote{\cite[52]{SchafferJonathan2010MTPo}}  

Now we can apply much of what Maudlin and Schaffer say about entanglement to posit alternative beables to the ones Kent suggests without having to embrace Schaffer's monism. The alternative I'm suggesting is to take the beables to be the states of entangled subsystems of $S_n$ that make up the components of $\pi_n\ket*{\Psi_n}.$ In other words, if we can express $\pi_n\ket*{\Psi_n}$ as a product 
\begin{equation}\label{beablesprod}
\pi_n\ket*{\Psi_n}=b\prod_k \ket*{\Psi_{n,k}}
\end{equation}
where the states $\ket*{\Psi_{n,k}}$ cannot be further decomposed into products of states, and where the regions $U_{n,k}$ that these states describe are disjoint subregions of $S_n$ with $S_n=\bigcup_k U_{n,k}$, then the states $\ket*{\Psi_{n,k}}$ will be the beables of the cosmos.

In making the beables relative to a spacelike hypersurface, I am making explicit an assumption that is implicit in Schaffer's definition of completeness. The cosmos that can be duplicated by duplicating all the basic entities is duplicated at a particular time, or more generally on a particular spacelike hypersurface. It doesn't seem any more problematic to consider all the beables on a particular spacelike hypersurface than it does to consider all the beables at a particular time. But if we want to avoid monism and maximize\footnote{I will discuss below why we would want to maximize the number of beables.} the number of beables in a spacelike region  $U$, then $U$ must be embedded in a hypersurface $S_n$ that intersects as much of $S$ as possible. If we were just to consider the state $\ket*{\Psi_n}$ of $S_n$, then as Schaffer suggests, we have good reason to expect there to be one entangled system over the whole of $S_n$. However, if we deem the mass-energy on $S\cap S_n$ to be given by $\tau_S$, then this will correspond to applying the projection $\pi_n$ to $\ket*{\Psi_n}$, and as indicated by  the transition from equation (\ref{Psinidecomp}) to equation (\ref{piphi}), $\pi_n\ket*{\Psi_n}$ can be approximated as a product of disentangled states. The possibility that the decomposition (\ref{beablesprod}) might only be approximate rather than exact could be a slight worry, but I'm assuming that the error would be so small as not to make any discernible difference to what any intelligent beings living in the cosmos might observe. 

There is also the question of why we might want to choose a spacelike hypersurface which maximizes the number of beables. The reason for wanting to do this is that it allows us to conceive of physical reality in a way that is maximally analyzable. When we can express the state $\ket*{\Psi_n}$ as a product of states $\ket*{\Psi_{n,k}}$ as in (\ref{beablesprod}), then we can consider the properties of the spacelike region $U_{n,k}$ that $\ket*{\Psi_{n,k}}$ describes independently of the properties of  spacelike regions $U_{n,k'}$ that the $\ket*{\Psi_{n,k'}}$-states describe for $k'\neq k$. To see why this is so, suppose $\hat{O}_k$ is an observable that corresponds to the statement $o_k$ that a measurable property of $U_{n,k}$ lies within a certain range,\footnote{i.e. $\hat{O}_k$ is a Hermitian operator acting on the Hilbert space of states for $U_{n,k}$ such that the eigenvalues of $\hat{O}_k$ are either $1$ or $0$, where the eigenstates with eigenvalue $1$ corresponding to states of $U_{n,k}$ for which the statement $O_k$ is true, and  where the eigenstates with eigenvalue $0$ corresponding to states of $U_{n,k}$ for which the statement $O_k$ is false, that is, the measurable property of $U_{n,k}$ lies within some other range.} and likewise, suppose $\hat{O}_{k'}$ is an observable that corresponds to the statement $o_{k'}$ that a measurable property of $U_{n,k'}$ lies within a certain range. Then if we write $P(q)$ for the probability $q$ is true, where $q$ is either the statement $o_k$, $o_{k'}$, or $o_k\, \&\, o_{k'}$, then
\begin{equation}
\begin{split}
P(o_k\, \&\, o_{k'})&=\frac{\ev*{\pi_n\hat{O}_k\hat{O}_{k'}}{\Psi_n}}{\ev*{\pi_n}{\Psi_n}}=\bra*{\Psi_{n,k'}}\ev*{\hat{O}_k\hat{O}_{k'}}{\Psi_{n,k}}\ket*{\Psi_{n,k'}}\\
&=\ev*{\hat{O}_k}{\Psi_{n,k}}\ev*{\hat{O}_{k'}}{\Psi_{n,k'}}=P(o_k)P(o_{k'}).
\end{split}
\end{equation}
Thus, the properties of $U_{n,k}$ and $U_{n,k'}$ will be statistically independent of one another.


Another issue that might be of concern to some people (though not to others) is that Kent's theory is deterministic. In other words, given an initial state $\ket*{\Psi_0}$ of $S_0$ and a final mass-energy density measurement $\tau_S$ on $S$, the stress energy tensors for every spacetime location between $S_0$ and $S$ is completely determined according to Kent's theory. There is however a way in which we could reintroduce some indeterminism into Kent's theory if one so desired. For Kent's theory says nothing about how the final mass-energy density measurement $\tau_S$ on $S$ is selected apart from the requirement that it is selected with a probability given by the Born Rule. So if we were to consider a local spacelike region $U$ between $S_0$ and $S$, its current state will be determined by the energy-density measurement on $S$ outside of the light cone of $U$ together with $\ket*{\Psi_0}$, but given this energy-density measurement outside the light cone of $U$, there are still going to be many possible energy-density measurements within the light cone of $U$ consistent with the Born Rule, and hence many possible futures for $U$. So in the sense that there are many possible futures for $U$ given its current state, Kent's theory is not deterministic. 

This raises the question of whether there is a temporal ordering to the measurement that is made on $S$. Clearly, this temporal ordering, if there is one, is not going to be as simple as saying measurements within the lightcone of $U$ are later than measurements outside the light cone of $U$, for such an ordering would be dependent on where $U$ was located. However, if we consider a toy model in which photons of light are treated as point particles and in which the light detected on $S$ can always be traced back to the object prior $S$ off which the light reflected, then we should beable to discern a temporal ordering to the mass-energy density information specified on $S$. For suppose a subregion $S_1$ of $S$ is able to determine the state of a system $\mathcal{A}$ located in a spatial region $R$ at time $t_1$ due to some photons that are reflected from $\mathcal{A}$ at this time. This means that there will be a set of states $\{\ket*{\gamma^{(1)}_1}, \ket*{\gamma^{(1)}_2}, \ldots\}$ of $S_1$, and a set of states $\{\ket*{\psi^{(1)}_1}, \ket*{\psi^{(1)}_2}, \ldots\}$ of $\mathcal{A}$ such that $\mathcal{A}$ is in state $\ket*{\psi^{(1)}_i}$ if and only if $S_1$ is in state $\ket*{\gamma^{(1)}_i}$. The probability that $S_1$ is in state $\ket*{\gamma^{(1)}_i}$ and hence the probability $\mathcal{A}$ is in state $\ket*{\psi^{(1)}_i}$ will be $\ev*{[\gamma^{(1)}_i]}{\Psi_S}$ where $[\gamma^{(1)}_i]=\dyad*{\gamma^{(1)}_i}$ and $\ket*{\Psi_S}=U_{SS_0}\ket*{\Psi_0}$ as defined on page \pageref{SchwingerUnitaryOP}. We now suppose that at $t_2>t_1$ more photons are reflected from the system $\mathcal{A}$, and that $S_2$ is the subregion of $S$ where these photons can be detected. We also suppose that if $\mathcal{A}$ is in state $\ket*{\psi^{(1)}_i}$ at time $t_1$, then at time $t_2$ its state must belong to a set of states $\{\ket*{\psi^{(2)}_{i1}}, \ket*{\psi^{(2)}_{i2}},\ldots\}$, and we also assume that light reflecting off $\mathcal{A}$ when it is in state $\ket*{\psi^{(2)}_{ij}}$ will result in the subregion $S_2$ being in state $\ket*{\gamma^{(2)}_{ij}}$, and that $\ket*{\gamma^{(2)}_{ij}}$ is orthogonal to $\ket*{\gamma^{(2)}_{i'j'}}$ when either $i\neq i'$ or $j\neq j'$. The probability that $\mathcal{A}$ will be found to be in state   $\ket*{\psi^{(2)}_{ij}}$ at time $t_2$ given that it was in state $\ket*{\psi^{(1)}_{i}}$ at time $t_1$ will therefore be $\frac{\ev*{[\gamma^{(2)}_{ij}]}{\Psi_S}}{\ev*{[\gamma^{(1)}_{i}]}{\Psi_S}}.$ We can thus work out that the state of $\ket*{\Psi_S}$ will take the form
\begin{equation}\label{PsiStimeordering}
\ket*{\Psi_S}=\sum_{i}\lambda^{(1)}_i\ket*{\gamma^{(1)}_i}\sum_{j}\lambda^{(2)}_{ij}\ket*{\gamma^{(2)}_{ij}}\ket*{\Xi_{ij}}
\end{equation}
where $|\lambda^{(1)}_i|^2= \ev*{[\gamma^{(1)}_i]}{\Psi_S}$,  $|\lambda^{(2)}_{ij}|^2= \frac{\ev*{[\gamma^{(2)}_{ij}]}{\Psi_S}}{\ev*{[\gamma^{(1)}_{i}]}{\Psi_S}}$, and where $\ket*{\Xi_{ij}}$ is the state that $S\setminus(S_1\cup S_2)$ must be in given that $\mathcal{A}$ is in states  $\ket*{\psi^{(1)}_{i}}$ and $\ket*{\psi^{(2)}_{ij}}$ at times $t_1$ and $t_2$ respectively. 

Examining (\ref{PsiStimeordering}), we see that if $S_2$ is in the state $\ket*{\gamma^{(2)}_{ij}}$ then $S_1$ must be in the state $\ket*{\gamma^{(1)}_{i}}$, but the converse will not in general be true. We thus find that there is an asymmetry between how the components of $\ket*{\Psi_S}$ relate to one another, and this asymmetry corresponds to a temporal ordering of the states of $\mathcal{A}$. In other words if a state $\ket{\gamma}$ on a subregion of $S$ is correlated with a state $\ket{\psi}$, and a state $\ket{\gamma'}$ on a subregion of $S$ is correlated with a state $\ket{\psi'}$, then 
\begin{equation}\label{timeordering}
\big((\ket{\gamma'}\Rightarrow\ket{\gamma})\,\& \,(\ket{\gamma}\not\Rightarrow\ket{\gamma'})\big) \Longrightarrow \ket{\psi'} \text{ occurs after }\ket{\psi}.
\end{equation}
So even though the spacelike hypersurface $S$ is timeless so to speak, we could give it a time like structure by saying that $\ket*{\gamma'}$ occurs after $\ket*{\gamma}$ when $\big((\ket{\gamma'}\Rightarrow\ket{\gamma})\,\& \,(\ket{\gamma}\not\Rightarrow\ket{\gamma'})\big)$. Granted, this criterion will only give a partial ordering of the states of regions of $S$, so there will be many situations when it would be neither the case that  $\ket{\gamma}$ occurs after $\ket{\gamma'}$ nor $\ket{\gamma'}$ occurs after $\ket{\gamma}.$ Nevertheless, the energy-density measurement on $S$ reveals that both $\ket{\gamma'}$ and $\ket{\gamma}$ are realized, then there will be a state of a subregion of $S$ that occurs after both of these states, namely $\ket{\gamma}\ket{\gamma'}$.