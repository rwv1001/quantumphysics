\section{Beables and Time}
In previous sections I've tried to show that Kent's theory is a one world theory which makes the same predictions as standard quantum mechanics and is consistent with special relatively (subject to a minor alteration which allows us to attribute PI to Kent's theory). There are however a number of issues that might still make people reluctant to take Kent's theory seriously. For instance, it may strike many people as wildly speculative to suggest that the current state of reality is specified in terms of expectation values of stress-momentum operators conditioned on some fictional measurement made in the far distant future. Also, many people, myself included, do not find determinism philosophically attractive, yet on the face of it, Kent's theory does seem to be deterministic. It also looks like Kent's theory relies on there being backwards in time causality, an idea which to many people will seem just as absurd as the many worlds interpretation. In this final section, I will discuss these concerns and how they might be addressed.

To begin, with let's consider the criticism that Kent's theory is too wildly speculative for anyone to take seriously. In response to this criticism, I think the best way to see Kent's theory is not as a claim of how physical reality must be, but more like a thought experiment that opens up the logical space of how physical reality might be if one accepts special relativity and standard quantum mechanics. For instance, the Colbeck-Renner theorem might lead one to conclude that there are no interesting hidden variables theories that make the same predictions as quantum theory and satisfy PI. However, as I've tried to show in section \ref{colbeckrennerthm}, the information additional to the quantum state that is contained in a distant future mass-energy density measurement is not constrained by the underlying assumptions of Colbeck, Renner, et al., and hence their conclusion about the redundancy of hidden variables does not apply to Kent's theory. 

Another assumption that is often made about hidden variables theories, but which Kent's theory calls into question is the assumption that a hidden variables theory requires there to be new laws of physics beyond standard quantum mechanics.  Maudlin prefers to speak of \emph{additional variables theories}\index{additional variables theories} rather than of hidden variables theories: an addionional variables theory is a theory in which there is more to physical reality than a single quantum state describing the universe. However, Maudlin goes on to claim that if one adopts  an additional variables theory, one must not only specify what the additional variables are, but one must also state the laws governing them.\footnote{see \cite[9]{MAUDLINT1995Tmp} } It is as though Maudlin can only imagine the additional variables to be dynamical quantities like particle positions that need laws of motion to describe how they evolve overtime. Now Kent's theory is an additional variables theory according to Maudlin's criterion. However, just because Kent's theory is an additional variable theory, it doesn't follow that Kent is proposing some radically new physical theory which specifies new laws of motion: standard quantum physics will do. Thus, Kent's theory does need the Born Rule in order to specify the probability with which the mass-energy density measurement $\tau_S$ is selected on the distant future spacelike hypersurface $S$, but the Born Rule is just a part of standard quantum physics. However, no new physics is required to describe the additional variables (i.e. the values of $\tau_S$ over $S$)  of Kent's theory since the mass-energy density over $S$ has just as much right to be described by a quantum state as the initial state  of the universe $\ket*{\Psi_0}$ has. Also, once the mass-energy density $\tau_S$ on the hypersurface $S$ has been selected, $\tau_S$ doesn't change, and so it makes no sense to ask by what laws the mass-energy density evolves on this hypersurface. So insofar as Kent's additional variables don't require any new physics to describe them, his theory is far less speculative than many other extensions to standard quantum mechanics. 

Nevertheless, the manner in which one might use the additional variables of Kent's theory is something one could speculate about, and it is far from obvious that Kent's proposal is the only way or the most natural way of using these additional variables. In other words, it is not obvious that expectation values of stress-energy tensors conditioned on a future mass-energy density measurement is the most natural choice of beables determining the state of physical reality.  

As mentioned on page \pageref{beabledef}, Bell introduced the term beable due to his dissatisfaction with standard quantum physics which is only a theory of observables -- a satisfactory theory shouldn't just tell us how a physical system appears to be, but it should also tell us how the physical system actually is. In other words, a satisfactory physical theory should describe beables which encapsulate the physical system's state of actuality and which can account for why a system appears to be the way it is. 

Now in Kent's theory, there are two kinds of beables. Firstly, there are the beables corresponding to the mass-energy density measurement on $S$. The mass-energy density measurement $\tau_S$ tells is how each spacetime location of $S$ actually is. Secondly, there are the beables for all the spacetime locations prior to $S$. According to Kent, for a spacetime location $y$ prior to $S$, the conditional expectation value  $\ev*{\hat{T}^{\mu\nu}(y)}_{\tau_S}$ for all the different combinations of $\mu$ and $\nu$ tells us how the state of physical reality at spacetime location $y$ actually is. 

Now it seems that one can accept the first kind of beable in Kent's theory without accepting the second kind. In some situations, the definite values of $\tau_S(x)$ on $S$ will give rise to $\hat{T}^{\mu\nu}(y)$-eigenstates at $y$, in which case the conditional expectation $\ev*{\hat{T}^{\mu\nu}(y)}_{\tau_S}$ will be identical to a definite value for $T^{\mu\nu}(y)$ as normally understood in standard quantum theory. But there will inevitably be situations in which the definite values of $\tau_S(x)$ on $S$ will not give rise to  $\hat{T}^{\mu\nu}(y)$-eigenstates at $y$. In other words, in the notation defined in section \ref{LorentzInvarianceSection} on page \pageref{tauprojection}, we will inevitably find that the state $\pi_n\ket{\Psi_n}$ at $y$ is in a superposition of eigenstates of $\hat{T}^{\mu\nu}(y)$ for some choice of $\mu$ and $\nu$. But in that case, it seems rather dubious to claim that the expectation value $\ev*{\hat{T}^{\mu\nu}(y)}_{\tau_S}$ is the true state of reality and hence the beable at $y$. As an analogy, it seems a bit like saying that if the throw of a six-sided dice was described quantum mechanically, then the dice could yield a beable of 3.5 for its outcome since 3.5 is the expectation value for the throw of a six-sided dice. In Kent's theory, there would of course nearly always be sufficient information in $\tau_S$ on the spacelike hypersurface $S$  to determine that a real dice yielded an integer outcome between 1 and 6.  But it is still the case that the information in $\tau_S$ outside the light cone of $y$ will be insufficient to determine all possible measurable quantities at $y$ to have definite values, and so it seems unnecessary to insist that Kent's expectation values of all the observables corresponding to these measurable quantities give the state of physical reality at $y$. 

It might be more reasonable just to say that there is no fact of the matter about the definite value of some measurable quantities in cases where the information in $\tau_S$ is insufficient to determine them.  In the context of Kent's theory, one could still suppose that there were beables corresponding to the mass-energy density $\tau_S(x)$ on $S$, and that some definite facts about physical reality flowed from the definite facts about $S$. But there could also be degrees of indefiniteness about physical reality. This would occur whenever the information in $\tau_S(x)$ was insufficient to determine whether the state $\pi_n\ket{\Psi_n}$ was an eigenstate of some observable. If light were to interact with the location $y$ in a different way, then this might be able to settle the question of which eigenstate $\pi_n\ket{\Psi_n}$ was in, but this definite outcome would then result in $y$ being indefinite with respect to other observables. But even though there would inevitably be many physical quantities of a system that lacked definiteness, we could typically expect the state $\pi_n\ket{\Psi_n}$ to be very nearly an eigenstate for these indefinite physical quantities. For instance, there might be real numbers $t^{\mu\nu}(y)$ for all $\mu, \nu$ such that 
\begin{equation}\label{tapproxmunuy}
\hat{T}^{\mu\nu}(y)\pi_n\ket{\Psi_n}\approx t^{\mu\nu}(y)\pi_n\ket{\Psi_n}.
\end{equation}
For some values of $\mu$ and $\nu$, we might even obtain equality in (\ref{tapproxmunuy}), but it is not going to be possible to obtain equality in (\ref{tapproxmunuy}) for every value of $\mu$ and $\nu$ -- there must be cases in which $\hat{T}^{\mu\nu}(y)\pi_n\ket{\Psi_n}$ and $t^{\mu\nu}(y)\pi_n\ket{\Psi_n}$ are not quite parallel, for otherwise all the $\hat{T}^{\mu\nu}(y)$  acting on $\pi_n\ket{\Psi_n}$ would commute, and this is not possible. 

The suggestion that there are degrees of indefiniteness to measurable quantities is not going to appeal to everyone, especially people who are seeking a perfect mathematical account of physical reality. But in a context in which we use the information of $\tau_S$ to calculate the state $\pi_n\ket{\Psi_n}$ of a hypersurface $S_n$, the degrees of indefiniteness are going to be very small, so for instance, we don't need to worry about whether a cat could be in a superposition of dead and alive states. The values of $t^{\mu\nu}(y)$ in the vicinity of a cat for which (\ref{tapproxmunuy}) is a very good approximation are going to correspond either to the cat being dead or the cat being alive -- these values won't correspond to the cat being both dead and alive.

If one is unwilling to accept Kent's proposal that the expectation values $\ev*{\hat{T}^{\mu\nu}(y)}_{\tau_S}$ are beables, there is still the question of whether there are any better alternatives. In answering this question, we can perhaps draw inspiration from Maudlin's views on entanglement where he says ``The physical state of a complex whole cannot always be reduced to those of its parts, or to those of its parts together with their spatiotemporal relations \ldots. The result of the most intensive scientific investigations in history is a theory that contains an ineliminable holism.''\footnote{See \cite[56]{Maudlin2}.}  With a view to defending monism, Schaffer takes also argues that entangled systems constitute irreducible wholes.\footnote{See \cite{SchafferJonathan2010MTPo}.} Schaffer's arguement relies on the principle that ``the basic entities must be \emph{complete}\index{completeness of basic entities}, in the sense of providing a blueprint for reality. More precisely, a plurality of entities is complete if and only if duplicating all these entities, while preserving their fundamental relations, metaphysically suffices to duplicate the cosmos and its contents.''\footnote{\cite[39]{SchafferJonathan2010MTPo}} In the case of entangled systems, duplicating the particles of the system and their spatiotemperal relations will not be sufficient to duplicate the system and its content. Supplementing the particles with entanglement relations doesn't help either in our efforts to duplicate the system. This is because an entangled system will typically have intrinsic properties such as spin which are independent of the number of particles in a system. For instance, both a complex system like a silver atom and a simple system like an electron have an identical spin of 1/2. But if the spin of an entangled system is a certain kind of entanglement relation between the system's component parts, then it wouldn't be possible to say that a complex and simple system had the same spin. Schaffer thus concludes that an entangled system is a fundamental unit, and thus the basic entities in any complete description of the cosmos cannot be components of entangled systems.\footnote{\cite[54]{SchafferJonathan2010MTPo}}  Schaffer also argues that in the absence of any principle that promotes disentanglement, there will only be one entangled system for the whole cosmos since our current understanding of physics suggests that the universe began with a Big Bang which would have resulted in every component of the universe getting entangled with every other component.

Now we can apply much of what Maudlin and Schaffer say about entanglement to posit alternative beables to the ones Kent suggests without having to embrace monism. The alternative I'm suggesting is to take the beables to be the entangled subsystems of $S_n$ whose states are components of $\pi_n\ket*{\Psi_n}.$ In other words, if we can express $\pi_n\ket*{\Psi_n}$ as a product 
\begin{equation}\label{beablesprod}
\pi_n\ket*{\Psi_n}=b\prod_k \ket*{\Psi_{n,k}}
\end{equation}
where the states $\ket*{\Psi_{n,k}}$ cannot be further decomposed into products of states, then the states $\ket*{\Psi_{n,k}}$ will be the beables.

In making the beables relative to a spacelike hypersurface, I am making explicit an assumption that is implicit in Schaffer's definition of completeness. The cosmos that can be duplicated by duplicating all the basic entities is duplicated at a particular time, or more generally on a spacelike hypersurface. It doesn't seem any more problematic to consider all the beables at a particular spacelike hypersurface than it is to consider all the beables at a particular time. But if we want to avoid monism and maximize the number of beables in a spacelike $U$ region, then $U$ must be embedded in a hypersurface $S_n$ that intersects as much of $S$ as possible. If we were just to consider the state $\ket*{\Psi_n}$ of $S_n$, then as Schaffer suggests, we might only expect there to be one entangled system over the whole of $S_n$. However, if we deem the mass-energy on $S\cup S_n$ to be given by $\tau_S$, then this will correspond to applying the projection $\pi_n$ to $\ket*{\Psi_n}$, and as indicated by  the transition from equation (\ref{Psinidecomp}) to equation (\ref{piphi}), $\pi_n\ket*{\Psi_n}$ can be approximated as a product of disentangled states. The possibility that the decomposition (\ref{beablesprod}) might only be approximate rather than exact could be a slight worry, but I'm assuming that the error would be so small as not to make any discernible difference to what any intelligent beings living in the cosmos might observe. 

Another issue that might be of concern to some people (though not to others) is that Kent's theory is deterministic -- given an initial state $\ket*{\Psi_0}$ of $S_0$ and a final mass-energy density measurement $\tau_S$ on $S$, the stress energy tensors for every spacetime location between $S_0$ and $S$ is completely determined according to Kent's theory. There is however a way in which we could reintroduce some indeterminism into Kent's theory if one so desired.  For if we consider a local spacelike region $U$ between $S_0$ and $S$, then given the *****************************